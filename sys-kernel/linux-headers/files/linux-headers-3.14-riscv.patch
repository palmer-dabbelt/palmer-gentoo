commit 6f2d95f5b9aa060edb83ddc58a3020add1f0ca76
Author: Albert Ou <a_ou@eecs.berkeley.edu>
Date:   Tue Sep 16 15:28:31 2014 -0700

    RISC-V Port

diff --git a/arch/riscv/.gitignore b/arch/riscv/.gitignore
new file mode 100644
index 0000000..376d06e
--- /dev/null
+++ b/arch/riscv/.gitignore
@@ -0,0 +1,35 @@
+# Now un-ignore all files.
+!*
+
+# But then re-ignore the files listed in the Linux .gitignore
+# Normal rules
+#
+.*
+*.o
+*.o.*
+*.a
+*.s
+*.ko
+*.so
+*.so.dbg
+*.mod.c
+*.i
+*.lst
+*.symtypes
+*.order
+modules.builtin
+*.elf
+*.bin
+*.gz
+*.bz2
+*.lzma
+*.xz
+*.lzo
+*.patch
+*.gcno
+
+include/generated
+kernel/vmlinux.lds
+
+# Then reinclude .gitignore.
+!.gitignore
diff --git a/arch/riscv/Kconfig b/arch/riscv/Kconfig
new file mode 100644
index 0000000..6527936
--- /dev/null
+++ b/arch/riscv/Kconfig
@@ -0,0 +1,236 @@
+#
+# For a description of the syntax of this configuration file,
+# see Documentation/kbuild/kconfig-language.txt.
+#
+
+config RISCV
+	def_bool y
+	select ARCH_WANT_FRAME_POINTERS
+	select CLONE_BACKWARDS
+	select GENERIC_STRNCPY_FROM_USER
+	select GENERIC_STRNLEN_USER
+	select GENERIC_ATOMIC64 if !64BIT || !RV_ATOMIC
+	select RV_ATOMIC if SMP
+	select RV_SYSRISCV_ATOMIC if !RV_ATOMIC
+
+config MMU
+	def_bool y
+
+config HAS_DMA
+	def_bool n
+
+config STACKTRACE_SUPPORT
+	def_bool y
+
+menu "Platform type"
+
+config NR_CPUS
+	int "Number of cores"
+	range 1 1024
+	default "1"
+	depends on SMP
+
+choice
+	prompt "CPU selection"
+	default CPU_RV_ROCKET
+
+config CPU_RV_ROCKET
+	bool "Rocket"
+	select CPU_SUPPORTS_64BIT_KERNEL
+
+config CPU_RV_GENERIC
+	bool "Generic RISC-V"
+	select CPU_SUPPORTS_32BIT_KERNEL
+	select CPU_SUPPORTS_64BIT_KERNEL
+
+endchoice
+
+config CPU_SUPPORTS_32BIT_KERNEL
+	bool
+config CPU_SUPPORTS_64BIT_KERNEL
+	bool
+
+config RV_ATOMIC
+	bool "Use atomic memory instructions (RV32A or RV64A)"
+	default y
+
+config RV_SYSRISCV_ATOMIC
+	bool "Include support for atomic operation syscalls"
+	default n
+	help
+	  If atomic memory instructions are present, i.e.,
+	  CONFIG_RV_ATOMIC, this includes support for the syscall that
+	  provides atomic accesses.  This is only useful to run
+	  binaries that require atomic access but were compiled with
+	  -mno-atomic.
+
+	  If CONFIG_RV_ATOMIC is unset, this option is mandatory.
+
+menuconfig HTIF
+	bool "HTIF"
+	default y
+	help
+	  Host-Target Interface
+if HTIF
+
+config HTIF_CONSOLE
+	tristate "HTIF console support"
+	default y
+
+config HTIF_BLK_DEV
+	tristate "HTIF block device support"
+	depends on BLOCK
+	default y
+
+config HTIF_RFB
+	tristate "HTIF remote framebuffer"
+	depends on FB
+	select FB_CFB_FILLRECT
+	select FB_CFB_COPYAREA
+	select FB_CFB_IMAGEBLIT
+	default y
+
+endif # HTIF
+
+endmenu
+
+menu "Kernel type"
+
+choice
+	prompt "Kernel code model"
+	default 64BIT
+
+config 32BIT
+	bool "32-bit kernel"
+	depends on CPU_SUPPORTS_32BIT_KERNEL
+	help
+	  Select this option to build a 32-bit kernel.
+
+config 64BIT
+	bool "64-bit kernel"
+	depends on CPU_SUPPORTS_64BIT_KERNEL
+	help
+	  Select this option to build a 64-bit kernel.
+
+endchoice
+
+source "mm/Kconfig"
+
+source "kernel/Kconfig.preempt"
+
+source "kernel/Kconfig.hz"
+
+endmenu
+
+source "init/Kconfig"
+
+menu "Executable file formats"
+
+source "fs/Kconfig.binfmt"
+
+endmenu
+
+source "net/Kconfig"
+
+source "drivers/Kconfig"
+
+source "fs/Kconfig"
+
+menu "Kernel hacking"
+
+config CMDLINE_BOOL
+	bool "Built-in kernel command line"
+	default n
+	help
+	  For most platforms, it is firmware or second stage bootloader
+	  that by default specifies the kernel command line options.
+	  However, it might be necessary or advantageous to either override
+	  the default kernel command line or add a few extra options to it.
+	  For such cases, this option allows hardcoding command line options
+	  directly into the kernel.
+
+	  For that, choose 'Y' here and fill in the extra boot parameters
+	  in CONFIG_CMDLINE.
+
+	  The built-in options will be concatenated to the default command
+	  line if CMDLINE_OVERRIDE is set to 'N'. Otherwise, the default
+	  command line will be ignored and replaced by the built-in string.
+
+config CMDLINE
+	string "Built-in kernel command string"
+	depends on CMDLINE_BOOL
+	default ""
+	help
+	  Supply command-line options at build time by entering them here.
+
+config CMDLINE_OVERRIDE
+	bool "Built-in command line overrides bootloader arguments"
+	default n
+	depends on CMDLINE_BOOL
+	help
+	  Set this option to 'Y' to have the kernel ignore the bootloader
+	  or firmware command line.  Instead, the built-in command line
+	  will be used exclusively.
+
+config EARLY_PRINTK
+	bool "Early printk"
+	depends on HTIF
+	default n
+	help
+	  This option enables special console drivers which allow the kernel
+	  to print messages very early in the bootup process.
+
+	  This is useful for kernel debugging when your machine crashes very
+	  early before the console code is initialized. For normal operation
+	  it is not recommended because it looks ugly and doesn't cooperate
+	  with klogd/syslogd or the X server. You should normally N here,
+	  unless you want to debug such a crash.
+
+
+source "lib/Kconfig.debug"
+
+config CMDLINE_BOOL
+	bool 
+endmenu
+
+source "crypto/Kconfig"
+
+source "lib/Kconfig"
+
+config GENERIC_HWEIGHT
+	def_bool y
+
+config RWSEM_GENERIC_SPINLOCK
+	def_bool y
+
+config GENERIC_CALIBRATE_DELAY
+	def_bool y
+
+config GENERIC_BUG
+	def_bool y
+	depends on BUG
+
+config HAVE_MEMBLOCK_NODE_MAP
+	def_bool y
+
+config HAVE_MEMBLOCK
+	def_bool y
+
+config GENERIC_CLOCKEVENTS
+	def_bool y
+
+config HAVE_GENERIC_HARDIRQS
+	def_bool y
+
+config GENERIC_IRQ_SHOW
+	def_bool y
+
+config GENERIC_CSUM
+	def_bool y
+
+config NLATTR
+	def_bool y
+
+config ARCH_WANT_FRAME_POINTERS
+	def_bool y
+
diff --git a/arch/riscv/Makefile b/arch/riscv/Makefile
new file mode 100644
index 0000000..09cb4b9
--- /dev/null
+++ b/arch/riscv/Makefile
@@ -0,0 +1,48 @@
+# BK Id: %F% %I% %G% %U% %#%
+#
+# This file is included by the global makefile so that you can add your own
+# architecture-specific flags and dependencies. Remember to do have actions
+# for "archclean" and "archdep" for cleaning up and making dependencies for
+# this architecture
+#
+# This file is subject to the terms and conditions of the GNU General Public
+# License.  See the file "COPYING" in the main directory of this archive
+# for more details.
+#
+# Copyright (C) 1994 by Linus Torvalds
+# Modifications for the RISC-V architecture:
+# Quan Nguyen <quannguyen@eecs.berkeley.edu>
+# Albert Ou <a_ou@eecs.berkeley.edu>
+#
+# Based on:
+# arch/score/Makefile
+
+LDFLAGS         :=
+OBJCOPYFLAGS    := -O binary
+LDFLAGS_vmlinux :=
+
+export BITS
+ifeq ($(CONFIG_64BIT),y)
+	BITS := 64
+	KBUILD_CFLAGS += -m64
+else
+	BITS := 32
+	KBUILD_CFLAGS += -m32
+endif
+
+ifeq ($(CONFIG_RV_ATOMIC),)
+KBUILD_CFLAGS += -mno-atomic
+endif
+
+KBUILD_CFLAGS += -Wall
+KBUILD_CFLAGS += -fno-section-anchors
+
+head-y := arch/riscv/kernel/head_$(BITS).o
+
+core-y += arch/riscv/kernel/ arch/riscv/mm/
+
+libs-y += arch/riscv/lib/
+
+drivers-$(CONFIG_HTIF) += arch/riscv/htif/
+
+all: vmlinux
diff --git a/arch/riscv/defconfig b/arch/riscv/defconfig
new file mode 100644
index 0000000..0ef3143
--- /dev/null
+++ b/arch/riscv/defconfig
@@ -0,0 +1,915 @@
+#
+# Automatically generated file; DO NOT EDIT.
+# Linux/riscv 3.14.15 Kernel Configuration
+#
+CONFIG_RISCV=y
+CONFIG_MMU=y
+# CONFIG_HAS_DMA is not set
+CONFIG_STACKTRACE_SUPPORT=y
+
+#
+# Platform type
+#
+CONFIG_CPU_RV_ROCKET=y
+# CONFIG_CPU_RV_GENERIC is not set
+CONFIG_CPU_SUPPORTS_64BIT_KERNEL=y
+CONFIG_HTIF=y
+CONFIG_HTIF_CONSOLE=y
+CONFIG_HTIF_BLK_DEV=y
+CONFIG_HTIF_RFB=y
+
+#
+# Kernel type
+#
+CONFIG_64BIT=y
+CONFIG_FLATMEM=y
+CONFIG_FLAT_NODE_MEM_MAP=y
+CONFIG_HAVE_MEMBLOCK=y
+CONFIG_HAVE_MEMBLOCK_NODE_MAP=y
+# CONFIG_HAVE_BOOTMEM_INFO_NODE is not set
+CONFIG_PAGEFLAGS_EXTENDED=y
+CONFIG_SPLIT_PTLOCK_CPUS=4
+# CONFIG_COMPACTION is not set
+CONFIG_PHYS_ADDR_T_64BIT=y
+CONFIG_ZONE_DMA_FLAG=0
+# CONFIG_KSM is not set
+CONFIG_DEFAULT_MMAP_MIN_ADDR=4096
+# CONFIG_CROSS_MEMORY_ATTACH is not set
+CONFIG_NEED_PER_CPU_KM=y
+# CONFIG_CLEANCACHE is not set
+# CONFIG_FRONTSWAP is not set
+# CONFIG_CMA is not set
+# CONFIG_ZBUD is not set
+# CONFIG_ZSMALLOC is not set
+CONFIG_PREEMPT_NONE=y
+# CONFIG_PREEMPT_VOLUNTARY is not set
+# CONFIG_PREEMPT is not set
+CONFIG_HZ_100=y
+# CONFIG_HZ_250 is not set
+# CONFIG_HZ_300 is not set
+# CONFIG_HZ_1000 is not set
+CONFIG_HZ=100
+# CONFIG_SCHED_HRTICK is not set
+CONFIG_DEFCONFIG_LIST="/lib/modules/$UNAME_RELEASE/.config"
+CONFIG_IRQ_WORK=y
+
+#
+# General setup
+#
+CONFIG_BROKEN_ON_SMP=y
+CONFIG_INIT_ENV_ARG_LIMIT=32
+CONFIG_CROSS_COMPILE="riscv-linux-"
+# CONFIG_COMPILE_TEST is not set
+CONFIG_LOCALVERSION=""
+CONFIG_LOCALVERSION_AUTO=y
+CONFIG_DEFAULT_HOSTNAME="ucbvax"
+CONFIG_SWAP=y
+# CONFIG_SYSVIPC is not set
+# CONFIG_POSIX_MQUEUE is not set
+# CONFIG_FHANDLE is not set
+# CONFIG_AUDIT is not set
+
+#
+# IRQ subsystem
+#
+CONFIG_GENERIC_IRQ_SHOW=y
+CONFIG_GENERIC_CLOCKEVENTS=y
+CONFIG_GENERIC_CLOCKEVENTS_BUILD=y
+
+#
+# Timers subsystem
+#
+CONFIG_HZ_PERIODIC=y
+# CONFIG_NO_HZ_IDLE is not set
+# CONFIG_NO_HZ is not set
+# CONFIG_HIGH_RES_TIMERS is not set
+
+#
+# CPU/Task time and stats accounting
+#
+CONFIG_TICK_CPU_ACCOUNTING=y
+# CONFIG_BSD_PROCESS_ACCT is not set
+# CONFIG_TASKSTATS is not set
+
+#
+# RCU Subsystem
+#
+CONFIG_TINY_RCU=y
+# CONFIG_PREEMPT_RCU is not set
+# CONFIG_RCU_STALL_COMMON is not set
+# CONFIG_TREE_RCU_TRACE is not set
+# CONFIG_IKCONFIG is not set
+CONFIG_LOG_BUF_SHIFT=17
+# CONFIG_CGROUPS is not set
+# CONFIG_CHECKPOINT_RESTORE is not set
+CONFIG_NAMESPACES=y
+CONFIG_UTS_NS=y
+# CONFIG_USER_NS is not set
+CONFIG_PID_NS=y
+CONFIG_NET_NS=y
+# CONFIG_SCHED_AUTOGROUP is not set
+# CONFIG_RELAY is not set
+# CONFIG_BLK_DEV_INITRD is not set
+# CONFIG_CC_OPTIMIZE_FOR_SIZE is not set
+CONFIG_SYSCTL=y
+CONFIG_ANON_INODES=y
+CONFIG_EXPERT=y
+# CONFIG_SYSCTL_SYSCALL is not set
+CONFIG_KALLSYMS=y
+# CONFIG_KALLSYMS_ALL is not set
+CONFIG_PRINTK=y
+CONFIG_BUG=y
+CONFIG_ELF_CORE=y
+CONFIG_BASE_FULL=y
+CONFIG_FUTEX=y
+CONFIG_EPOLL=y
+CONFIG_SIGNALFD=y
+CONFIG_TIMERFD=y
+CONFIG_EVENTFD=y
+CONFIG_SHMEM=y
+CONFIG_AIO=y
+CONFIG_EMBEDDED=y
+
+#
+# Kernel Performance Events And Counters
+#
+CONFIG_VM_EVENT_COUNTERS=y
+CONFIG_COMPAT_BRK=y
+# CONFIG_SLAB is not set
+CONFIG_SLUB=y
+# CONFIG_SLOB is not set
+# CONFIG_PROFILING is not set
+CONFIG_HAVE_64BIT_ALIGNED_ACCESS=y
+# CONFIG_CC_STACKPROTECTOR is not set
+CONFIG_HAVE_VIRT_CPU_ACCOUNTING_GEN=y
+CONFIG_CLONE_BACKWARDS=y
+
+#
+# GCOV-based kernel profiling
+#
+# CONFIG_HAVE_GENERIC_DMA_COHERENT is not set
+CONFIG_RT_MUTEXES=y
+CONFIG_BASE_SMALL=0
+# CONFIG_MODULES is not set
+CONFIG_BLOCK=y
+# CONFIG_BLK_DEV_BSG is not set
+# CONFIG_BLK_DEV_BSGLIB is not set
+# CONFIG_BLK_DEV_INTEGRITY is not set
+# CONFIG_BLK_CMDLINE_PARSER is not set
+
+#
+# Partition Types
+#
+CONFIG_PARTITION_ADVANCED=y
+# CONFIG_ACORN_PARTITION is not set
+# CONFIG_AIX_PARTITION is not set
+# CONFIG_OSF_PARTITION is not set
+# CONFIG_AMIGA_PARTITION is not set
+# CONFIG_ATARI_PARTITION is not set
+# CONFIG_MAC_PARTITION is not set
+CONFIG_MSDOS_PARTITION=y
+# CONFIG_BSD_DISKLABEL is not set
+# CONFIG_MINIX_SUBPARTITION is not set
+# CONFIG_SOLARIS_X86_PARTITION is not set
+# CONFIG_UNIXWARE_DISKLABEL is not set
+# CONFIG_LDM_PARTITION is not set
+# CONFIG_SGI_PARTITION is not set
+# CONFIG_ULTRIX_PARTITION is not set
+# CONFIG_SUN_PARTITION is not set
+# CONFIG_KARMA_PARTITION is not set
+# CONFIG_EFI_PARTITION is not set
+# CONFIG_SYSV68_PARTITION is not set
+# CONFIG_CMDLINE_PARTITION is not set
+
+#
+# IO Schedulers
+#
+CONFIG_IOSCHED_NOOP=y
+# CONFIG_IOSCHED_DEADLINE is not set
+CONFIG_IOSCHED_CFQ=y
+CONFIG_DEFAULT_CFQ=y
+# CONFIG_DEFAULT_NOOP is not set
+CONFIG_DEFAULT_IOSCHED="cfq"
+CONFIG_INLINE_SPIN_UNLOCK_IRQ=y
+CONFIG_INLINE_READ_UNLOCK=y
+CONFIG_INLINE_READ_UNLOCK_IRQ=y
+CONFIG_INLINE_WRITE_UNLOCK=y
+CONFIG_INLINE_WRITE_UNLOCK_IRQ=y
+
+#
+# Executable file formats
+#
+CONFIG_BINFMT_ELF=y
+CONFIG_CORE_DUMP_DEFAULT_ELF_HEADERS=y
+CONFIG_BINFMT_SCRIPT=y
+# CONFIG_HAVE_AOUT is not set
+# CONFIG_BINFMT_MISC is not set
+CONFIG_COREDUMP=y
+CONFIG_NET=y
+
+#
+# Networking options
+#
+# CONFIG_PACKET is not set
+CONFIG_UNIX=y
+# CONFIG_UNIX_DIAG is not set
+# CONFIG_XFRM_USER is not set
+# CONFIG_NET_KEY is not set
+CONFIG_INET=y
+# CONFIG_IP_MULTICAST is not set
+# CONFIG_IP_ADVANCED_ROUTER is not set
+# CONFIG_IP_PNP is not set
+# CONFIG_NET_IPIP is not set
+# CONFIG_NET_IPGRE_DEMUX is not set
+# CONFIG_NET_IP_TUNNEL is not set
+# CONFIG_SYN_COOKIES is not set
+# CONFIG_INET_AH is not set
+# CONFIG_INET_ESP is not set
+# CONFIG_INET_IPCOMP is not set
+# CONFIG_INET_XFRM_TUNNEL is not set
+# CONFIG_INET_TUNNEL is not set
+# CONFIG_INET_XFRM_MODE_TRANSPORT is not set
+# CONFIG_INET_XFRM_MODE_TUNNEL is not set
+# CONFIG_INET_XFRM_MODE_BEET is not set
+# CONFIG_INET_LRO is not set
+# CONFIG_INET_DIAG is not set
+# CONFIG_TCP_CONG_ADVANCED is not set
+CONFIG_TCP_CONG_CUBIC=y
+CONFIG_DEFAULT_TCP_CONG="cubic"
+# CONFIG_TCP_MD5SIG is not set
+# CONFIG_IPV6 is not set
+# CONFIG_NETWORK_SECMARK is not set
+# CONFIG_NETWORK_PHY_TIMESTAMPING is not set
+# CONFIG_NETFILTER is not set
+# CONFIG_IP_DCCP is not set
+# CONFIG_IP_SCTP is not set
+# CONFIG_RDS is not set
+# CONFIG_TIPC is not set
+# CONFIG_ATM is not set
+# CONFIG_L2TP is not set
+# CONFIG_BRIDGE is not set
+# CONFIG_VLAN_8021Q is not set
+# CONFIG_DECNET is not set
+# CONFIG_LLC2 is not set
+# CONFIG_IPX is not set
+# CONFIG_ATALK is not set
+# CONFIG_X25 is not set
+# CONFIG_LAPB is not set
+# CONFIG_PHONET is not set
+# CONFIG_IEEE802154 is not set
+# CONFIG_NET_SCHED is not set
+# CONFIG_DCB is not set
+# CONFIG_BATMAN_ADV is not set
+# CONFIG_OPENVSWITCH is not set
+# CONFIG_VSOCKETS is not set
+# CONFIG_NETLINK_MMAP is not set
+# CONFIG_NETLINK_DIAG is not set
+# CONFIG_NET_MPLS_GSO is not set
+# CONFIG_HSR is not set
+CONFIG_NET_RX_BUSY_POLL=y
+
+#
+# Network testing
+#
+# CONFIG_NET_PKTGEN is not set
+# CONFIG_HAMRADIO is not set
+# CONFIG_CAN is not set
+# CONFIG_IRDA is not set
+# CONFIG_BT is not set
+# CONFIG_AF_RXRPC is not set
+# CONFIG_WIRELESS is not set
+# CONFIG_WIMAX is not set
+# CONFIG_RFKILL is not set
+# CONFIG_NET_9P is not set
+# CONFIG_CAIF is not set
+# CONFIG_CEPH_LIB is not set
+# CONFIG_NFC is not set
+
+#
+# Device Drivers
+#
+
+#
+# Generic Driver Options
+#
+CONFIG_UEVENT_HELPER_PATH=""
+CONFIG_DEVTMPFS=y
+CONFIG_DEVTMPFS_MOUNT=y
+CONFIG_STANDALONE=y
+CONFIG_PREVENT_FIRMWARE_BUILD=y
+CONFIG_FW_LOADER=y
+# CONFIG_FIRMWARE_IN_KERNEL is not set
+CONFIG_EXTRA_FIRMWARE=""
+CONFIG_FW_LOADER_USER_HELPER=y
+# CONFIG_DEBUG_DRIVER is not set
+# CONFIG_DEBUG_DEVRES is not set
+# CONFIG_SYS_HYPERVISOR is not set
+# CONFIG_GENERIC_CPU_DEVICES is not set
+# CONFIG_DMA_SHARED_BUFFER is not set
+
+#
+# Bus devices
+#
+# CONFIG_CONNECTOR is not set
+# CONFIG_MTD is not set
+# CONFIG_PARPORT is not set
+# CONFIG_BLK_DEV is not set
+
+#
+# Misc devices
+#
+# CONFIG_SENSORS_LIS3LV02D is not set
+# CONFIG_DUMMY_IRQ is not set
+# CONFIG_ATMEL_SSC is not set
+# CONFIG_ENCLOSURE_SERVICES is not set
+# CONFIG_SRAM is not set
+# CONFIG_C2PORT is not set
+
+#
+# EEPROM support
+#
+# CONFIG_EEPROM_93CX6 is not set
+
+#
+# Texas Instruments shared transport line discipline
+#
+
+#
+# Altera FPGA firmware download module
+#
+
+#
+# Intel MIC Host Driver
+#
+
+#
+# Intel MIC Card Driver
+#
+
+#
+# SCSI device support
+#
+CONFIG_SCSI_MOD=y
+# CONFIG_RAID_ATTRS is not set
+# CONFIG_SCSI is not set
+# CONFIG_SCSI_DMA is not set
+# CONFIG_SCSI_NETLINK is not set
+# CONFIG_ATA is not set
+# CONFIG_MD is not set
+# CONFIG_NETDEVICES is not set
+
+#
+# Input device support
+#
+CONFIG_INPUT=y
+# CONFIG_INPUT_FF_MEMLESS is not set
+# CONFIG_INPUT_POLLDEV is not set
+# CONFIG_INPUT_SPARSEKMAP is not set
+# CONFIG_INPUT_MATRIXKMAP is not set
+
+#
+# Userland interfaces
+#
+# CONFIG_INPUT_MOUSEDEV is not set
+# CONFIG_INPUT_JOYDEV is not set
+# CONFIG_INPUT_EVDEV is not set
+# CONFIG_INPUT_EVBUG is not set
+
+#
+# Input Device Drivers
+#
+# CONFIG_INPUT_KEYBOARD is not set
+# CONFIG_INPUT_MOUSE is not set
+# CONFIG_INPUT_JOYSTICK is not set
+# CONFIG_INPUT_TABLET is not set
+# CONFIG_INPUT_TOUCHSCREEN is not set
+# CONFIG_INPUT_MISC is not set
+
+#
+# Hardware I/O ports
+#
+CONFIG_SERIO=y
+CONFIG_SERIO_SERPORT=y
+# CONFIG_SERIO_LIBPS2 is not set
+# CONFIG_SERIO_RAW is not set
+# CONFIG_SERIO_ALTERA_PS2 is not set
+# CONFIG_SERIO_PS2MULT is not set
+# CONFIG_SERIO_ARC_PS2 is not set
+# CONFIG_GAMEPORT is not set
+
+#
+# Character devices
+#
+CONFIG_TTY=y
+# CONFIG_VT is not set
+CONFIG_UNIX98_PTYS=y
+# CONFIG_DEVPTS_MULTIPLE_INSTANCES is not set
+CONFIG_LEGACY_PTYS=y
+CONFIG_LEGACY_PTY_COUNT=256
+# CONFIG_SERIAL_NONSTANDARD is not set
+# CONFIG_N_GSM is not set
+# CONFIG_TRACE_SINK is not set
+CONFIG_DEVKMEM=y
+
+#
+# Serial drivers
+#
+# CONFIG_SERIAL_8250 is not set
+
+#
+# Non-8250 serial port support
+#
+# CONFIG_SERIAL_SCCNXP is not set
+# CONFIG_SERIAL_TIMBERDALE is not set
+# CONFIG_SERIAL_ALTERA_JTAGUART is not set
+# CONFIG_SERIAL_ALTERA_UART is not set
+# CONFIG_SERIAL_ARC is not set
+# CONFIG_SERIAL_FSL_LPUART is not set
+# CONFIG_TTY_PRINTK is not set
+# CONFIG_IPMI_HANDLER is not set
+# CONFIG_HW_RANDOM is not set
+# CONFIG_RTC is not set
+# CONFIG_GEN_RTC is not set
+# CONFIG_R3964 is not set
+
+#
+# PCMCIA character devices
+#
+# CONFIG_RAW_DRIVER is not set
+# CONFIG_TCG_TPM is not set
+# CONFIG_I2C is not set
+# CONFIG_SPI is not set
+# CONFIG_HSI is not set
+
+#
+# PPS support
+#
+# CONFIG_PPS is not set
+
+#
+# PPS generators support
+#
+
+#
+# PTP clock support
+#
+# CONFIG_PTP_1588_CLOCK is not set
+
+#
+# Enable PHYLIB and NETWORK_PHY_TIMESTAMPING to see the additional clocks.
+#
+# CONFIG_W1 is not set
+# CONFIG_POWER_SUPPLY is not set
+# CONFIG_POWER_AVS is not set
+# CONFIG_HWMON is not set
+# CONFIG_THERMAL is not set
+# CONFIG_WATCHDOG is not set
+
+#
+# Multifunction device drivers
+#
+# CONFIG_MFD_CORE is not set
+# CONFIG_MFD_CROS_EC is not set
+# CONFIG_HTC_PASIC3 is not set
+# CONFIG_MFD_KEMPLD is not set
+# CONFIG_MFD_SM501 is not set
+# CONFIG_ABX500_CORE is not set
+# CONFIG_MFD_SYSCON is not set
+# CONFIG_MFD_TI_AM335X_TSCADC is not set
+# CONFIG_MFD_TMIO is not set
+# CONFIG_REGULATOR is not set
+# CONFIG_MEDIA_SUPPORT is not set
+
+#
+# Graphics support
+#
+# CONFIG_VGASTATE is not set
+# CONFIG_VIDEO_OUTPUT_CONTROL is not set
+CONFIG_FB=y
+# CONFIG_FIRMWARE_EDID is not set
+# CONFIG_FB_DDC is not set
+# CONFIG_FB_BOOT_VESA_SUPPORT is not set
+CONFIG_FB_CFB_FILLRECT=y
+CONFIG_FB_CFB_COPYAREA=y
+CONFIG_FB_CFB_IMAGEBLIT=y
+# CONFIG_FB_CFB_REV_PIXELS_IN_BYTE is not set
+# CONFIG_FB_SYS_FILLRECT is not set
+# CONFIG_FB_SYS_COPYAREA is not set
+# CONFIG_FB_SYS_IMAGEBLIT is not set
+# CONFIG_FB_FOREIGN_ENDIAN is not set
+# CONFIG_FB_SYS_FOPS is not set
+# CONFIG_FB_SVGALIB is not set
+# CONFIG_FB_MACMODES is not set
+# CONFIG_FB_BACKLIGHT is not set
+# CONFIG_FB_MODE_HELPERS is not set
+# CONFIG_FB_TILEBLITTING is not set
+
+#
+# Frame buffer hardware drivers
+#
+# CONFIG_FB_OPENCORES is not set
+# CONFIG_FB_S1D13XXX is not set
+# CONFIG_FB_VIRTUAL is not set
+# CONFIG_FB_METRONOME is not set
+# CONFIG_FB_BROADSHEET is not set
+# CONFIG_FB_AUO_K190X is not set
+# CONFIG_FB_SIMPLE is not set
+# CONFIG_EXYNOS_VIDEO is not set
+# CONFIG_BACKLIGHT_LCD_SUPPORT is not set
+# CONFIG_LOGO is not set
+# CONFIG_SOUND is not set
+
+#
+# HID support
+#
+CONFIG_HID=y
+# CONFIG_HIDRAW is not set
+# CONFIG_UHID is not set
+CONFIG_HID_GENERIC=y
+
+#
+# Special HID drivers
+#
+# CONFIG_HID_A4TECH is not set
+# CONFIG_HID_ACRUX is not set
+# CONFIG_HID_APPLE is not set
+# CONFIG_HID_AUREAL is not set
+# CONFIG_HID_BELKIN is not set
+# CONFIG_HID_CHERRY is not set
+# CONFIG_HID_CHICONY is not set
+# CONFIG_HID_CYPRESS is not set
+# CONFIG_HID_DRAGONRISE is not set
+# CONFIG_HID_EMS_FF is not set
+# CONFIG_HID_ELECOM is not set
+# CONFIG_HID_EZKEY is not set
+# CONFIG_HID_KEYTOUCH is not set
+# CONFIG_HID_KYE is not set
+# CONFIG_HID_UCLOGIC is not set
+# CONFIG_HID_WALTOP is not set
+# CONFIG_HID_GYRATION is not set
+# CONFIG_HID_ICADE is not set
+# CONFIG_HID_TWINHAN is not set
+# CONFIG_HID_KENSINGTON is not set
+# CONFIG_HID_LCPOWER is not set
+# CONFIG_HID_LENOVO_TPKBD is not set
+# CONFIG_HID_LOGITECH is not set
+# CONFIG_HID_MAGICMOUSE is not set
+# CONFIG_HID_MICROSOFT is not set
+# CONFIG_HID_MONTEREY is not set
+# CONFIG_HID_MULTITOUCH is not set
+# CONFIG_HID_ORTEK is not set
+# CONFIG_HID_PANTHERLORD is not set
+# CONFIG_HID_PETALYNX is not set
+# CONFIG_HID_PICOLCD is not set
+# CONFIG_HID_PRIMAX is not set
+# CONFIG_HID_SAITEK is not set
+# CONFIG_HID_SAMSUNG is not set
+# CONFIG_HID_SPEEDLINK is not set
+# CONFIG_HID_STEELSERIES is not set
+# CONFIG_HID_SUNPLUS is not set
+# CONFIG_HID_GREENASIA is not set
+# CONFIG_HID_SMARTJOYPLUS is not set
+# CONFIG_HID_TIVO is not set
+# CONFIG_HID_TOPSEED is not set
+# CONFIG_HID_THRUSTMASTER is not set
+# CONFIG_HID_XINMO is not set
+# CONFIG_HID_ZEROPLUS is not set
+# CONFIG_HID_ZYDACRON is not set
+# CONFIG_HID_SENSOR_HUB is not set
+CONFIG_USB_OHCI_LITTLE_ENDIAN=y
+# CONFIG_USB_SUPPORT is not set
+# CONFIG_MMC is not set
+# CONFIG_MEMSTICK is not set
+# CONFIG_NEW_LEDS is not set
+# CONFIG_ACCESSIBILITY is not set
+# CONFIG_RTC_CLASS is not set
+# CONFIG_AUXDISPLAY is not set
+# CONFIG_UIO is not set
+# CONFIG_VIRT_DRIVERS is not set
+
+#
+# Virtio drivers
+#
+# CONFIG_VIRTIO_MMIO is not set
+
+#
+# Microsoft Hyper-V guest support
+#
+# CONFIG_STAGING is not set
+
+#
+# Hardware Spinlock drivers
+#
+# CONFIG_MAILBOX is not set
+# CONFIG_IOMMU_SUPPORT is not set
+
+#
+# Remoteproc drivers
+#
+
+#
+# Rpmsg drivers
+#
+# CONFIG_PM_DEVFREQ is not set
+# CONFIG_EXTCON is not set
+# CONFIG_MEMORY is not set
+# CONFIG_IIO is not set
+# CONFIG_PWM is not set
+# CONFIG_IPACK_BUS is not set
+# CONFIG_RESET_CONTROLLER is not set
+# CONFIG_FMC is not set
+
+#
+# PHY Subsystem
+#
+# CONFIG_GENERIC_PHY is not set
+# CONFIG_PHY_EXYNOS_MIPI_VIDEO is not set
+# CONFIG_POWERCAP is not set
+
+#
+# File systems
+#
+CONFIG_EXT2_FS=y
+# CONFIG_EXT2_FS_XATTR is not set
+# CONFIG_EXT2_FS_XIP is not set
+# CONFIG_EXT3_FS is not set
+# CONFIG_EXT4_FS is not set
+# CONFIG_REISERFS_FS is not set
+# CONFIG_JFS_FS is not set
+# CONFIG_XFS_FS is not set
+# CONFIG_GFS2_FS is not set
+# CONFIG_BTRFS_FS is not set
+# CONFIG_NILFS2_FS is not set
+# CONFIG_FS_POSIX_ACL is not set
+# CONFIG_FILE_LOCKING is not set
+# CONFIG_FSNOTIFY is not set
+# CONFIG_DNOTIFY is not set
+# CONFIG_INOTIFY_USER is not set
+# CONFIG_FANOTIFY is not set
+# CONFIG_QUOTA is not set
+# CONFIG_QUOTACTL is not set
+# CONFIG_AUTOFS4_FS is not set
+# CONFIG_FUSE_FS is not set
+
+#
+# Caches
+#
+# CONFIG_FSCACHE is not set
+
+#
+# CD-ROM/DVD Filesystems
+#
+# CONFIG_ISO9660_FS is not set
+# CONFIG_UDF_FS is not set
+
+#
+# DOS/FAT/NT Filesystems
+#
+# CONFIG_MSDOS_FS is not set
+# CONFIG_VFAT_FS is not set
+# CONFIG_NTFS_FS is not set
+
+#
+# Pseudo filesystems
+#
+CONFIG_PROC_FS=y
+# CONFIG_PROC_KCORE is not set
+CONFIG_PROC_SYSCTL=y
+# CONFIG_PROC_PAGE_MONITOR is not set
+# CONFIG_SYSFS is not set
+CONFIG_TMPFS=y
+# CONFIG_TMPFS_POSIX_ACL is not set
+# CONFIG_TMPFS_XATTR is not set
+# CONFIG_HUGETLB_PAGE is not set
+# CONFIG_CONFIGFS_FS is not set
+# CONFIG_MISC_FILESYSTEMS is not set
+# CONFIG_NETWORK_FILESYSTEMS is not set
+# CONFIG_NLS is not set
+
+#
+# Kernel hacking
+#
+CONFIG_CMDLINE_BOOL=y
+CONFIG_CMDLINE="root=/dev/htifbd0 debug"
+CONFIG_CMDLINE_OVERRIDE=y
+# CONFIG_EARLY_PRINTK is not set
+
+#
+# printk and dmesg options
+#
+CONFIG_PRINTK_TIME=y
+CONFIG_DEFAULT_MESSAGE_LOGLEVEL=4
+# CONFIG_BOOT_PRINTK_DELAY is not set
+
+#
+# Compile-time checks and compiler options
+#
+# CONFIG_DEBUG_INFO is not set
+CONFIG_ENABLE_WARN_DEPRECATED=y
+CONFIG_ENABLE_MUST_CHECK=y
+CONFIG_FRAME_WARN=2048
+# CONFIG_STRIP_ASM_SYMS is not set
+# CONFIG_READABLE_ASM is not set
+# CONFIG_UNUSED_SYMBOLS is not set
+# CONFIG_DEBUG_FS is not set
+# CONFIG_HEADERS_CHECK is not set
+CONFIG_DEBUG_SECTION_MISMATCH=y
+CONFIG_ARCH_WANT_FRAME_POINTERS=y
+# CONFIG_FRAME_POINTER is not set
+# CONFIG_DEBUG_FORCE_WEAK_PER_CPU is not set
+# CONFIG_MAGIC_SYSRQ is not set
+CONFIG_DEBUG_KERNEL=y
+
+#
+# Memory Debugging
+#
+# CONFIG_DEBUG_PAGEALLOC is not set
+# CONFIG_DEBUG_OBJECTS is not set
+# CONFIG_DEBUG_STACK_USAGE is not set
+# CONFIG_DEBUG_VM is not set
+# CONFIG_DEBUG_MEMORY_INIT is not set
+# CONFIG_DEBUG_SHIRQ is not set
+
+#
+# Debug Lockups and Hangs
+#
+# CONFIG_LOCKUP_DETECTOR is not set
+# CONFIG_DETECT_HUNG_TASK is not set
+# CONFIG_PANIC_ON_OOPS is not set
+CONFIG_PANIC_ON_OOPS_VALUE=0
+CONFIG_PANIC_TIMEOUT=0
+CONFIG_SCHED_DEBUG=y
+# CONFIG_SCHEDSTATS is not set
+# CONFIG_TIMER_STATS is not set
+
+#
+# Lock Debugging (spinlocks, mutexes, etc...)
+#
+# CONFIG_DEBUG_RT_MUTEXES is not set
+# CONFIG_RT_MUTEX_TESTER is not set
+# CONFIG_DEBUG_SPINLOCK is not set
+# CONFIG_DEBUG_MUTEXES is not set
+# CONFIG_DEBUG_ATOMIC_SLEEP is not set
+# CONFIG_DEBUG_LOCKING_API_SELFTESTS is not set
+# CONFIG_DEBUG_KOBJECT is not set
+CONFIG_DEBUG_BUGVERBOSE=y
+# CONFIG_DEBUG_WRITECOUNT is not set
+# CONFIG_DEBUG_LIST is not set
+# CONFIG_DEBUG_SG is not set
+# CONFIG_DEBUG_NOTIFIERS is not set
+# CONFIG_DEBUG_CREDENTIALS is not set
+
+#
+# RCU Debugging
+#
+# CONFIG_SPARSE_RCU_POINTER is not set
+# CONFIG_RCU_TORTURE_TEST is not set
+# CONFIG_RCU_TRACE is not set
+# CONFIG_DEBUG_BLOCK_EXT_DEVT is not set
+# CONFIG_NOTIFIER_ERROR_INJECTION is not set
+# CONFIG_FAULT_INJECTION is not set
+
+#
+# Runtime Testing
+#
+# CONFIG_TEST_LIST_SORT is not set
+# CONFIG_BACKTRACE_SELF_TEST is not set
+# CONFIG_RBTREE_TEST is not set
+# CONFIG_ATOMIC64_SELFTEST is not set
+# CONFIG_TEST_STRING_HELPERS is not set
+# CONFIG_TEST_KSTRTOX is not set
+# CONFIG_SAMPLES is not set
+CONFIG_CRYPTO=y
+
+#
+# Crypto core or helper
+#
+CONFIG_CRYPTO_ALGAPI=y
+CONFIG_CRYPTO_ALGAPI2=y
+# CONFIG_CRYPTO_MANAGER is not set
+# CONFIG_CRYPTO_MANAGER2 is not set
+# CONFIG_CRYPTO_USER is not set
+# CONFIG_CRYPTO_GF128MUL is not set
+# CONFIG_CRYPTO_NULL is not set
+# CONFIG_CRYPTO_CRYPTD is not set
+# CONFIG_CRYPTO_AUTHENC is not set
+
+#
+# Authenticated Encryption with Associated Data
+#
+# CONFIG_CRYPTO_CCM is not set
+# CONFIG_CRYPTO_GCM is not set
+# CONFIG_CRYPTO_SEQIV is not set
+
+#
+# Block modes
+#
+# CONFIG_CRYPTO_CBC is not set
+# CONFIG_CRYPTO_CTR is not set
+# CONFIG_CRYPTO_CTS is not set
+# CONFIG_CRYPTO_ECB is not set
+# CONFIG_CRYPTO_LRW is not set
+# CONFIG_CRYPTO_PCBC is not set
+# CONFIG_CRYPTO_XTS is not set
+
+#
+# Hash modes
+#
+# CONFIG_CRYPTO_CMAC is not set
+# CONFIG_CRYPTO_HMAC is not set
+# CONFIG_CRYPTO_XCBC is not set
+# CONFIG_CRYPTO_VMAC is not set
+
+#
+# Digest
+#
+# CONFIG_CRYPTO_CRC32C is not set
+# CONFIG_CRYPTO_CRC32 is not set
+# CONFIG_CRYPTO_CRCT10DIF is not set
+# CONFIG_CRYPTO_GHASH is not set
+# CONFIG_CRYPTO_MD4 is not set
+# CONFIG_CRYPTO_MD5 is not set
+# CONFIG_CRYPTO_MICHAEL_MIC is not set
+# CONFIG_CRYPTO_RMD128 is not set
+# CONFIG_CRYPTO_RMD160 is not set
+# CONFIG_CRYPTO_RMD256 is not set
+# CONFIG_CRYPTO_RMD320 is not set
+# CONFIG_CRYPTO_SHA1 is not set
+# CONFIG_CRYPTO_SHA256 is not set
+# CONFIG_CRYPTO_SHA512 is not set
+# CONFIG_CRYPTO_TGR192 is not set
+# CONFIG_CRYPTO_WP512 is not set
+
+#
+# Ciphers
+#
+CONFIG_CRYPTO_AES=y
+# CONFIG_CRYPTO_ANUBIS is not set
+# CONFIG_CRYPTO_ARC4 is not set
+# CONFIG_CRYPTO_BLOWFISH is not set
+# CONFIG_CRYPTO_CAMELLIA is not set
+# CONFIG_CRYPTO_CAST5 is not set
+# CONFIG_CRYPTO_CAST6 is not set
+# CONFIG_CRYPTO_DES is not set
+# CONFIG_CRYPTO_FCRYPT is not set
+# CONFIG_CRYPTO_KHAZAD is not set
+# CONFIG_CRYPTO_SALSA20 is not set
+# CONFIG_CRYPTO_SEED is not set
+# CONFIG_CRYPTO_SERPENT is not set
+# CONFIG_CRYPTO_TEA is not set
+# CONFIG_CRYPTO_TWOFISH is not set
+
+#
+# Compression
+#
+# CONFIG_CRYPTO_DEFLATE is not set
+# CONFIG_CRYPTO_ZLIB is not set
+# CONFIG_CRYPTO_LZO is not set
+# CONFIG_CRYPTO_LZ4 is not set
+# CONFIG_CRYPTO_LZ4HC is not set
+
+#
+# Random Number Generation
+#
+# CONFIG_CRYPTO_ANSI_CPRNG is not set
+# CONFIG_CRYPTO_USER_API_HASH is not set
+# CONFIG_CRYPTO_USER_API_SKCIPHER is not set
+# CONFIG_CRYPTO_HW is not set
+# CONFIG_BINARY_PRINTF is not set
+
+#
+# Library routines
+#
+CONFIG_BITREVERSE=y
+CONFIG_GENERIC_STRNCPY_FROM_USER=y
+CONFIG_GENERIC_STRNLEN_USER=y
+CONFIG_GENERIC_NET_UTILS=y
+CONFIG_GENERIC_IO=y
+# CONFIG_CRC_CCITT is not set
+# CONFIG_CRC16 is not set
+# CONFIG_CRC_T10DIF is not set
+# CONFIG_CRC_ITU_T is not set
+CONFIG_CRC32=y
+# CONFIG_CRC32_SELFTEST is not set
+CONFIG_CRC32_SLICEBY8=y
+# CONFIG_CRC32_SLICEBY4 is not set
+# CONFIG_CRC32_SARWATE is not set
+# CONFIG_CRC32_BIT is not set
+# CONFIG_CRC7 is not set
+# CONFIG_LIBCRC32C is not set
+# CONFIG_CRC8 is not set
+# CONFIG_RANDOM32_SELFTEST is not set
+# CONFIG_XZ_DEC is not set
+# CONFIG_XZ_DEC_BCJ is not set
+CONFIG_HAS_IOMEM=y
+CONFIG_HAS_IOPORT=y
+CONFIG_NLATTR=y
+# CONFIG_AVERAGE is not set
+# CONFIG_CORDIC is not set
+# CONFIG_DDR is not set
+CONFIG_GENERIC_HWEIGHT=y
+CONFIG_RWSEM_GENERIC_SPINLOCK=y
+CONFIG_GENERIC_CALIBRATE_DELAY=y
+CONFIG_GENERIC_BUG=y
+CONFIG_HAVE_GENERIC_HARDIRQS=y
+CONFIG_GENERIC_CSUM=y
diff --git a/arch/riscv/htif/Makefile b/arch/riscv/htif/Makefile
new file mode 100644
index 0000000..6be5bdb
--- /dev/null
+++ b/arch/riscv/htif/Makefile
@@ -0,0 +1,4 @@
+obj-y				+= htif.o
+obj-$(CONFIG_HTIF_CONSOLE)	+= htifcons.o
+obj-$(CONFIG_HTIF_BLK_DEV)	+= htifbd.o
+obj-$(CONFIG_HTIF_RFB)		+= htifrfb.o
diff --git a/arch/riscv/htif/htif.c b/arch/riscv/htif/htif.c
new file mode 100644
index 0000000..a6341df
--- /dev/null
+++ b/arch/riscv/htif/htif.c
@@ -0,0 +1,122 @@
+#include <linux/kernel.h>
+#include <linux/device.h>
+#include <linux/slab.h>
+#include <linux/export.h>
+
+#include <asm/page.h>
+#include <asm/barrier.h>
+#include <asm/htif.h>
+
+
+struct device htif_bus = {
+	.init_name = "htif",
+};
+
+static int htif_bus_match(struct device *dev, struct device_driver *drv)
+{
+	return !strcmp(to_htif_dev(dev)->type, to_htif_driver(drv)->type);
+}
+
+struct bus_type htif_bus_type = {
+	.name = "htif",
+	.match = htif_bus_match,
+};
+
+int htif_register_driver(struct htif_driver *drv)
+{
+	drv->driver.bus = &htif_bus_type;
+	return driver_register(&drv->driver);
+}
+EXPORT_SYMBOL(htif_register_driver);
+
+void htif_unregister_driver(struct htif_driver *drv)
+{
+	drv->driver.bus = &htif_bus_type;
+	driver_unregister(&drv->driver);
+}
+EXPORT_SYMBOL(htif_unregister_driver);
+
+
+static void htif_dev_release(struct device *dev)
+{
+	kfree(to_htif_dev(dev));
+}
+
+static int htif_dev_register(struct htif_dev *dev)
+{
+	dev->dev.parent = &htif_bus;
+	dev->dev.bus = &htif_bus_type;
+	dev->dev.release = &htif_dev_release;
+	dev_set_name(&dev->dev, "htif%u", dev->minor);
+	return device_register(&dev->dev);
+}
+
+static inline void htif_dev_add(unsigned int minor, const char *id, size_t len)
+{
+	struct htif_dev *dev;
+	char *s;
+	size_t n;
+
+	/* Parse identity string */
+	s = strnchr(id, len, ' ');
+	if (s == id)
+		return;
+	n = (s != NULL) ? (s - id) : len;
+	s = kmalloc(len + 1, GFP_KERNEL);
+	if (s == NULL)
+		return;
+	memcpy(s, id, len);
+	s[len] = '\0';
+	if (n < len)
+		s[n++] = '\0';
+
+	dev = kzalloc(sizeof(struct htif_dev), GFP_KERNEL);
+	if (dev == NULL)
+		goto err_dev_alloc;
+	dev->minor = minor;
+	dev->type = s;
+	dev->spec = s + n;
+	if (htif_dev_register(dev))
+		goto err_dev_reg;
+	return;
+
+err_dev_reg:
+	put_device(&dev->dev);
+err_dev_alloc:
+	kfree(s);
+	return;
+}
+
+static int htif_bus_enumerate(void)
+{
+	char buf[64] __attribute__((aligned(64)));
+	unsigned int minor;
+
+	for (minor = 0; minor < HTIF_NR_DEV; minor++) {
+		mb();
+		htif_tohost(minor, HTIF_CMD_IDENTITY, (__pa(buf) << 8) | 0xFF);
+		htif_fromhost();
+		mb();
+
+		if (buf[0] != '\0')
+			htif_dev_add(minor, buf, strnlen(buf, sizeof(buf)));
+	}
+	return 0;
+}
+
+static int __init htif_bus_init(void)
+{
+	int ret;
+	ret = bus_register(&htif_bus_type);
+	if (ret)
+		return ret;
+	ret = device_register(&htif_bus);
+	if (ret) {
+		bus_unregister(&htif_bus_type);
+		return ret;
+	}
+	htif_bus_enumerate();
+	return 0;
+}
+early_initcall(htif_bus_init);
+
diff --git a/arch/riscv/htif/htifbd.c b/arch/riscv/htif/htifbd.c
new file mode 100644
index 0000000..f3cad12
--- /dev/null
+++ b/arch/riscv/htif/htifbd.c
@@ -0,0 +1,216 @@
+#include <linux/init.h>
+#include <linux/fs.h>
+#include <linux/blkdev.h>
+#include <linux/genhd.h>
+#include <linux/hdreg.h>
+#include <linux/spinlock.h>
+#include <linux/module.h>
+
+#include <asm/htif.h>
+
+#define DRIVER_NAME "htifbd"
+
+#define SECTOR_SIZE_SHIFT	(9)
+#define SECTOR_SIZE		(1UL << SECTOR_SIZE_SHIFT)
+
+struct htifbd_dev {
+	size_t size;		/* size in bytes */
+	spinlock_t lock;
+	struct gendisk *gd;
+	struct htif_dev *dev;
+};
+
+static int htifbd_open(struct block_device *bd, fmode_t mode)
+{
+	return 0;
+}
+
+static void htifbd_release(struct gendisk *gd, fmode_t mode)
+{
+}
+
+static int htifbd_ioctl(struct block_device *bd, fmode_t mode,
+	unsigned int cmd, unsigned long arg)
+{
+	struct hd_geometry geo;
+	struct htifbd_dev *dev;
+
+	dev = bd->bd_disk->private_data;
+	switch (cmd) {
+	case HDIO_GETGEO:
+		geo.cylinders = (dev->size >> 6);
+		geo.heads = 4;
+		geo.sectors = 16;
+		if (copy_to_user((void __user *)arg, &geo, sizeof(geo)))
+			return -EFAULT;
+		return 0;
+	}
+
+	return -ENOTTY;
+}
+
+static void htifbd_transfer(struct htifbd_dev *dev, unsigned long sector,
+	unsigned long nsect, char *buf, int direction)
+{
+	/* HTIF disk address packet */
+	volatile struct htifbd_dap {
+		unsigned long address;
+		unsigned long offset;	/* offset in bytes */
+		unsigned long length;	/* length in bytes */
+		unsigned long tag;
+	} req;
+	unsigned long offset, length;
+	unsigned long htif_cmd;
+
+	offset = (sector << SECTOR_SIZE_SHIFT);
+	length = (nsect << SECTOR_SIZE_SHIFT);
+
+	if ((offset + length) > dev->size) {
+		pr_notice(DRIVER_NAME "out-of-bounds access to %s with"
+			"offset=%lx length=%lx\n",
+			dev->gd->disk_name, offset, length);
+		return;
+	}
+
+	req.address = (unsigned long)__pa(buf);
+	req.offset = offset;
+	req.length = length;
+	req.tag = 0;
+
+	if (direction == READ) {
+		htif_cmd = HTIF_CMD_READ;
+	} else if (direction == WRITE) {
+		htif_cmd = HTIF_CMD_WRITE;
+	} else {
+		return;
+	}
+
+	mb();
+	htif_tohost(dev->dev->minor, htif_cmd, __pa(&req));
+	htif_fromhost();
+	mb();
+}
+
+static void htifbd_request(struct request_queue *q)
+{
+	struct request *req;
+
+	req = blk_fetch_request(q);
+	while (req != NULL) {
+		struct htifbd_dev *dev;
+
+		dev = req->rq_disk->private_data;
+		if (req->cmd_type != REQ_TYPE_FS) {
+			pr_notice(DRIVER_NAME ": ignoring non-fs request for %s\n",
+				req->rq_disk->disk_name);
+			__blk_end_request_all(req, -EIO);
+			continue;
+		}
+
+		htifbd_transfer(dev, blk_rq_pos(req), blk_rq_cur_sectors(req),
+			req->buffer, rq_data_dir(req));
+		if (!__blk_end_request_cur(req, 0)) {
+			req = blk_fetch_request(q);
+		}
+	}
+}
+
+static const struct block_device_operations htifbd_ops = {
+	.owner = THIS_MODULE,
+	.open = htifbd_open,
+	.release = htifbd_release,
+	.ioctl = htifbd_ioctl,
+};
+
+static int htifbd_major;
+
+static int htifbd_probe(struct device *dev)
+{
+	static unsigned int htifbd_nr = 0;
+	static const char size_str[] = "size=";
+
+	struct htif_dev *htif_dev;
+	struct htifbd_dev *htifbd_dev;
+	struct gendisk *gd;
+	unsigned long size;
+
+	htif_dev = to_htif_dev(dev);
+	pr_info(DRIVER_NAME ": detected disk with ID %u\n", htif_dev->minor);
+
+	if (unlikely(strncmp(htif_dev->spec, size_str, sizeof(size_str) - 1)
+		|| kstrtoul(htif_dev->spec + sizeof(size_str) - 1, 10, &size))) {
+		pr_err(DRIVER_NAME ": unable to determine size of disk %u\n",
+			htif_dev->minor);
+		goto err_out;
+	}
+	if (unlikely(size & (SECTOR_SIZE - 1))) {
+		pr_warn(DRIVER_NAME ": size of disk %u not a multiple of sector size\n",
+			htif_dev->minor);
+	}
+
+	htifbd_dev = kzalloc(sizeof(struct htifbd_dev), GFP_KERNEL);
+	if (unlikely(htifbd_dev == NULL))
+		goto err_out;
+	htifbd_dev->size = size;
+	htifbd_dev->dev = htif_dev;
+
+	gd = alloc_disk(1);
+	if (unlikely(gd == NULL))
+		goto err_gd_alloc;
+
+	spin_lock_init(&htifbd_dev->lock);
+	gd->queue = blk_init_queue(htifbd_request, &htifbd_dev->lock);
+	if (unlikely(gd->queue == NULL))
+		goto err_queue_init;
+
+	gd->major = htifbd_major;
+	gd->minors = 1;
+	gd->first_minor = 0;
+	gd->fops = &htifbd_ops;
+	gd->private_data = htifbd_dev;
+	set_capacity(gd, size >> SECTOR_SIZE_SHIFT);
+	snprintf(gd->disk_name, DISK_NAME_LEN - 1, "htifbd%u", htifbd_nr++);
+	pr_info(DRIVER_NAME ": adding %s\n", gd->disk_name);
+
+	htifbd_dev->gd = gd;
+	add_disk(gd);
+	return 0;
+
+err_queue_init:
+	put_disk(gd);
+err_gd_alloc:
+	kfree(htifbd_dev);
+err_out:
+	return -ENODEV;
+}
+
+
+static struct htif_driver htifbd_driver = {
+	.type = "disk",
+	.driver = {
+		.name = DRIVER_NAME,
+		.owner = THIS_MODULE,
+		.probe = htifbd_probe,
+	},
+};
+
+static int __init htifbd_init(void)
+{
+	int ret;
+	ret = register_blkdev(0, DRIVER_NAME);
+	if (unlikely(ret < 0))
+		return ret;
+	htifbd_major = ret;
+	ret = htif_register_driver(&htifbd_driver);
+	if (unlikely(ret)) {
+		unregister_blkdev(0, DRIVER_NAME);
+		return ret;
+	}
+	return 0;
+}
+
+/* Normally, this would be module_init, but that initcall would happen
+ * earlier than the registration of the I/O elevators.  You would have
+ * to place this in drivers/block, but I'd rather not...
+ */
+late_initcall(htifbd_init);
diff --git a/arch/riscv/htif/htifcons.c b/arch/riscv/htif/htifcons.c
new file mode 100644
index 0000000..6dcc31f
--- /dev/null
+++ b/arch/riscv/htif/htifcons.c
@@ -0,0 +1,325 @@
+#include <linux/init.h>
+#include <linux/console.h>
+#include <linux/tty.h>
+#include <linux/tty_flip.h>
+#include <linux/tty_driver.h>
+#include <linux/interrupt.h>
+#include <linux/irq.h>
+#include <linux/spinlock.h>
+#include <linux/slab.h>
+
+#include <asm/htif.h>
+
+#define DRIVER_NAME "htifcons"
+
+#define HTIF_NR_TTY		(1)
+#define HTIF_DEV_CONSOLE	(1U)
+
+struct htifcons_port {
+	struct tty_port port;
+	struct htif_dev *dev;
+	unsigned int index;
+};
+
+static struct htifcons_port *htifcons_table[HTIF_NR_TTY];
+static DEFINE_SPINLOCK(htifcons_table_lock);
+
+static int htifcons_port_add(struct htifcons_port *port)
+{
+	unsigned int index;
+	int ret;
+
+	ret = -EBUSY;
+	spin_lock(&htifcons_table_lock);
+	for (index = 0; index < HTIF_NR_TTY; index++) {
+		if (htifcons_table[index] == NULL) {
+			htifcons_table[index] = port;
+			port->index = index;
+			ret = 0;
+			break;
+		}
+	}
+	spin_unlock(&htifcons_table_lock);
+	return ret;
+}
+
+static void htifcons_port_remove(struct htifcons_port *port)
+{
+//	BUG_ON(htifcons_port[port->index] != port);
+	spin_lock(&htifcons_table_lock);
+	htifcons_table[port->index] = NULL;
+	spin_unlock(&htifcons_table_lock);
+}
+
+static struct htifcons_port *htifcons_port_get(unsigned int index)
+{
+	struct htifcons_port *port;
+
+	if (index >= HTIF_NR_TTY)
+		return NULL;
+	spin_lock(&htifcons_table_lock);
+	port = htifcons_table[index];
+	if (port)
+		tty_port_get(&port->port);
+	spin_unlock(&htifcons_table_lock);
+
+	return port;
+}
+
+static void htifcons_port_put(struct htifcons_port *port)
+{
+	tty_port_put(&port->port);
+}
+
+
+static void htifcons_write(unsigned int id, const char *buf,
+	unsigned int count)
+{
+	for (; count > 0; count--) {
+		unsigned char ch;
+		ch = *buf++;
+		if (unlikely(ch == '\n'))
+			htif_tohost(id, HTIF_CMD_WRITE, '\r');
+		htif_tohost(id, HTIF_CMD_WRITE, ch);
+	}
+}
+
+
+static int htif_tty_open(struct tty_struct *tty, struct file *filp)
+{
+	struct htifcons_port *port;
+	port = tty->driver_data;
+	if (unlikely(port == NULL))
+		return -ENODEV;
+	return tty_port_open(&port->port, tty, filp);
+}
+
+static void htif_tty_close(struct tty_struct *tty, struct file *filp)
+{
+	struct htifcons_port *port;
+	port = tty->driver_data;
+	tty_port_close(&port->port, tty, filp);
+}
+
+static int htif_tty_write(struct tty_struct *tty,
+	const unsigned char *buf, int count)
+{
+	struct htifcons_port *port;
+	port = tty->driver_data;
+	htifcons_write(port->dev->minor, buf, count);
+	return count;
+}
+
+static int htif_tty_write_room(struct tty_struct *tty)
+{
+	return 64;
+}
+
+/**
+ * htif_tty_install - install method
+ * @driver: the driver in use (htif_tty_driver)
+ * @tty: the tty being bound
+ *
+ * Look up and bind the tty and the driver together.
+ * Initialize any needed private data (i.e., the termios).
+ */
+static int htif_tty_install(struct tty_driver *driver, struct tty_struct *tty)
+{
+	struct htifcons_port *port;
+	int ret;
+
+	port = htifcons_port_get(tty->index);
+	ret = tty_standard_install(driver, tty);
+	if (unlikely(ret)) {
+		htifcons_port_put(port);
+	} else {
+		tty->driver_data = port;
+	}
+	return ret;
+}
+
+static void htifcons_port_destruct(struct tty_port *port)
+{
+	kfree(container_of(port, struct htifcons_port, port));
+}
+
+static const struct tty_port_operations htifcons_port_ops = {
+	.destruct = htifcons_port_destruct,
+};
+
+static const struct tty_operations htif_tty_ops = {
+	.open = htif_tty_open,
+	.close = htif_tty_close,
+	.write = htif_tty_write,
+	.write_room = htif_tty_write_room,
+	.install = htif_tty_install,
+};
+
+static struct tty_driver *htif_tty_driver;
+
+
+static void htif_console_write(struct console *con,
+		const char *buf, unsigned int count)
+{
+	/* FIXME: Device ID should not be hard-coded. */
+	htifcons_write(HTIF_DEV_CONSOLE, buf, count);
+}
+
+static struct tty_driver *htif_console_device(struct console *con,
+	int *index)
+{
+	*index = con->index;
+	return htif_tty_driver;
+}
+
+static struct console htif_console = {
+	.name	= "htifcons",
+	.write	= htif_console_write,
+	.device = htif_console_device,
+	.flags	= CON_PRINTBUFFER,
+	.index	= -1
+};
+
+static int __init htif_console_init(void)
+{
+	register_console(&htif_console);
+	return 0;
+}
+console_initcall(htif_console_init);
+
+
+static irqreturn_t htif_input_isr(int irq, void *dev_id)
+{
+	unsigned long data;
+	unsigned int index, id;
+
+	data = htif_fromhost();
+	if (unlikely(!data))
+		return IRQ_NONE;
+	id = (data >> HTIF_DEV_SHIFT);
+
+	for (index = 0; index < HTIF_NR_TTY; index++) {
+		struct htifcons_port *p;
+		p = htifcons_table[index];
+		if (p != NULL && p->dev->minor == id) {
+			struct tty_port *port;
+			port = &(p->port);
+
+			tty_insert_flip_char(port, data, TTY_NORMAL);
+			tty_flip_buffer_push(port);
+
+			/* Send next request for character */
+			htif_tohost(id, HTIF_CMD_READ, 0);
+			return IRQ_HANDLED;
+		}
+	}
+	return IRQ_NONE;
+}
+
+
+static int htifcons_probe(struct device *dev)
+{
+	static int irq_requested = 0;
+
+	struct htif_dev *htif_dev;
+	struct htifcons_port *port;
+	int ret;
+
+	htif_dev = to_htif_dev(dev);
+	pr_info(DRIVER_NAME ": detected console with ID %u\n", htif_dev->minor);
+
+	port = kzalloc(sizeof(struct htifcons_port), GFP_KERNEL);
+	if (port == NULL)
+		return -ENOMEM;
+	tty_port_init(&port->port);
+	port->port.ops = &htifcons_port_ops;
+	port->dev = htif_dev;
+
+	ret = htifcons_port_add(port);
+	if (unlikely(ret))
+		goto err_port_add;
+
+	dev = tty_port_register_device(&port->port, htif_tty_driver, port->index, dev);
+	if (unlikely(IS_ERR(dev))) {
+		ret = PTR_ERR(dev);
+		goto err_port_reg;
+	}
+
+	if (!irq_requested) {
+		/* Send next request for character */
+		htif_tohost(htif_dev->minor, HTIF_CMD_READ, 0);
+		ret = request_irq(IRQ_HOST, htif_input_isr, 0, "htif_input", NULL);
+		if (ret) {
+			pr_err(DRIVER_NAME ": failed to request irq: %d\n", ret);
+			goto err_isr_req;
+		}
+		irq_requested = 1;
+	}
+	return 0;
+
+err_isr_req:
+	tty_unregister_device(htif_tty_driver, port->index);
+err_port_reg:
+	htifcons_port_remove(port);
+err_port_add:
+	kfree(port);
+	return ret;
+}
+
+static struct htif_driver htifcons_driver = {
+	.type = "bcd",
+	.driver = {
+		.name = DRIVER_NAME,
+		.owner = THIS_MODULE,
+		.probe = htifcons_probe,
+	},
+};
+
+
+static int __init htifcons_init(void)
+{
+	int ret;
+
+	htif_tty_driver = alloc_tty_driver(HTIF_NR_TTY);
+	if (unlikely(htif_tty_driver == NULL))
+		return -ENOMEM;
+
+	htif_tty_driver->driver_name = "htif_tty";
+	htif_tty_driver->name = "ttyHTIF";
+	htif_tty_driver->type = TTY_DRIVER_TYPE_SYSTEM;
+	htif_tty_driver->subtype = SYSTEM_TYPE_TTY;
+	htif_tty_driver->major = 0; /* dynamically allocated */
+	htif_tty_driver->minor_start = 0;
+	htif_tty_driver->init_termios = tty_std_termios;
+	htif_tty_driver->flags = TTY_DRIVER_REAL_RAW;
+	tty_set_operations(htif_tty_driver, &htif_tty_ops);
+
+	ret = tty_register_driver(htif_tty_driver);
+	if (unlikely(ret)) {
+		pr_err(DRIVER_NAME ": registering tty driver failed: %d\n", ret);
+		goto err_tty_reg;
+	}
+
+	ret = htif_register_driver(&htifcons_driver);
+	if (unlikely(ret)) {
+		pr_err(DRIVER_NAME ": registering htif driver failed: %d\n", ret);
+		goto err_htif_reg;
+	}
+	return 0;
+
+err_htif_reg:
+	tty_unregister_driver(htif_tty_driver);
+err_tty_reg:
+	put_tty_driver(htif_tty_driver);
+	return ret;
+}
+
+static void __exit htifcons_exit(void)
+{
+	htif_unregister_driver(&htifcons_driver);
+	tty_unregister_driver(htif_tty_driver);
+	put_tty_driver(htif_tty_driver);
+}
+
+postcore_initcall(htifcons_init);
+module_exit(htifcons_exit);
diff --git a/arch/riscv/htif/htifrfb.c b/arch/riscv/htif/htifrfb.c
new file mode 100644
index 0000000..cd01555
--- /dev/null
+++ b/arch/riscv/htif/htifrfb.c
@@ -0,0 +1,135 @@
+#include <linux/kernel.h>
+#include <linux/fb.h>
+
+#include <asm/htif.h>
+
+#define DRIVER_NAME "htifrfb"
+
+#define RFB_XRES	(1024UL)
+#define RFB_YRES	(768UL)
+#define RFB_DEPTH	(24UL)
+#define RFB_BPP		(32UL)
+
+#define RFB_ROW_LEN	((RFB_XRES * RFB_BPP) >> 3)
+#define RFB_WORD_MASK	((BITS_PER_LONG >> 3) - 1)
+#define RFB_LINE_LEN	((RFB_ROW_LEN + RFB_WORD_MASK) & (~RFB_WORD_MASK))
+#define RFB_MEM_SIZE	(RFB_LINE_LEN * RFB_YRES)
+#define RFB_BUF_ORDER	(9)
+
+static void htifrfb_destroy(struct fb_info *info)
+{
+	if (info->screen_base)
+		free_pages((unsigned long)(info->screen_base), RFB_BUF_ORDER);
+	framebuffer_release(info);
+}
+
+static struct fb_ops htifrfb_ops = {
+	.owner		= THIS_MODULE,
+	.fb_destroy     = htifrfb_destroy,
+	.fb_fillrect	= cfb_fillrect,
+	.fb_copyarea	= cfb_copyarea,
+	.fb_imageblit	= cfb_imageblit,
+};
+
+static struct fb_var_screeninfo htifrfb_var = {
+	.xres		= RFB_XRES,
+	.yres		= RFB_YRES,
+	.bits_per_pixel	= RFB_BPP,
+	.red = {
+		.offset	= 16,
+		.length	= 8,
+	},
+	.green = {
+		.offset	= 8,
+		.length	= 8,
+	},
+	.blue = {
+		.offset	= 0,
+		.length	= 8,
+	},
+	.transp = {
+		.offset	= 24,
+		.length	= 8,
+	},
+	.activate	= FB_ACTIVATE_NOW,
+	.height		= -1,
+	.width		= -1,
+};
+
+static struct fb_fix_screeninfo htifrfb_fix = {
+	.id		= "HTIF RFB",
+	.smem_len	= RFB_MEM_SIZE,
+	.type		= FB_TYPE_PACKED_PIXELS,
+	.visual		= FB_VISUAL_TRUECOLOR,
+	.line_length	= RFB_LINE_LEN,
+	.accel		= FB_ACCEL_NONE,
+};
+
+static int htifrfb_probe(struct device *dev)
+{
+	struct htif_dev *htif_dev;
+	struct fb_info *info;
+	unsigned long flags;
+	int ret;
+
+	htif_dev = to_htif_dev(dev);
+	pr_info(DRIVER_NAME ": detected framebuffer at ID %u\n", htif_dev->minor);
+
+	info = framebuffer_alloc(0, dev);
+	if (unlikely(info == NULL))
+		return -ENOMEM;
+
+	ret = fb_alloc_cmap(&info->cmap, 256, 0);
+	if (unlikely(ret))
+		goto err_alloc_cmap;
+
+	info->screen_base = (char *)__get_free_pages(GFP_KERNEL, RFB_BUF_ORDER);
+	if (unlikely(info->screen_base == NULL))
+		goto err_alloc_buf;
+
+	info->flags = FBINFO_DEFAULT;
+	info->fbops = &htifrfb_ops;
+	info->var = htifrfb_var;
+	info->fix = htifrfb_fix;
+	info->fix.smem_start = __pa(info->screen_base);
+
+	ret = register_framebuffer(info);
+	if (unlikely(ret))
+		goto err_reg_fb;
+
+	/* FIXME: The HTIF acknowledgement from the host never appears to be
+	   received if the wait is disturbed by an interrupt; consequently,
+	   htif_fromhost() spins indefinitely. */
+	local_irq_save(flags);
+	htif_tohost(htif_dev->minor, 0, (RFB_BPP << 32) | (RFB_YRES << 16) | RFB_XRES);
+	htif_fromhost();
+	htif_tohost(htif_dev->minor, 1, info->fix.smem_start);
+	htif_fromhost();
+	local_irq_restore(flags);
+
+	return 0;
+
+err_reg_fb:
+	free_pages((unsigned long)(info->screen_base), RFB_BUF_ORDER);
+err_alloc_buf:
+	fb_dealloc_cmap(&info->cmap);
+err_alloc_cmap:
+	framebuffer_release(info);
+	return ret;
+}
+
+static struct htif_driver htifrfb_driver = {
+	.type = "rfb",
+	.driver = {
+		.name = DRIVER_NAME,
+		.owner = THIS_MODULE,
+		.probe = htifrfb_probe,
+	},
+};
+
+static int __init riscvfb_init(void)
+{
+	return htif_register_driver(&htifrfb_driver);
+}
+module_init(riscvfb_init);
+
diff --git a/arch/riscv/include/asm/Kbuild b/arch/riscv/include/asm/Kbuild
new file mode 100644
index 0000000..8f21030
--- /dev/null
+++ b/arch/riscv/include/asm/Kbuild
@@ -0,0 +1,70 @@
+include include/asm-generic/Kbuild.asm
+
+generic-y += auxvec.h
+generic-y += bitopts.h
+generic-y += bug.h
+generic-y += bugs.h
+generic-y += cacheflush.h
+generic-y += checksum.h
+generic-y += cputime.h
+generic-y += delay.h
+generic-y += device.h
+generic-y += div64.h
+generic-y += dma.h
+generic-y += emergency-restart.h
+generic-y += errno.h
+generic-y += exec.h
+generic-y += fb.h
+generic-y += fcntl.h
+generic-y += ftrace.h
+generic-y += futex.h
+generic-y += hardirq.h
+generic-y += hash.h
+generic-y += hw_irq.h
+generic-y += ioctl.h
+generic-y += ioctls.h
+generic-y += ipcbuf.h
+generic-y += irq_regs.h
+generic-y += kdebug.h
+generic-y += kmap_types.h
+generic-y += linkage.h
+generic-y += local.h
+generic-y += mman.h
+generic-y += module.h
+generic-y += msgbuf.h
+generic-y += mutex.h
+generic-y += param.h
+generic-y += pci.h
+generic-y += percpu.h
+generic-y += poll.h
+generic-y += posix_types.h
+generic-y += preempt.h
+generic-y += resource.h
+generic-y += rwsem.h
+generic-y += scatterlist.h
+generic-y += sections.h
+generic-y += segment.h
+generic-y += sembuf.h
+generic-y += shmbuf.h
+generic-y += shmparam.h
+generic-y += siginfo.h
+generic-y += signal.h
+generic-y += socket.h
+generic-y += sockios.h
+generic-y += stat.h
+generic-y += statfs.h
+generic-y += swab.h
+generic-y += switch_to.h
+generic-y += termbits.h
+generic-y += termios.h
+generic-y += topology.h
+generic-y += trace_clock.h
+generic-y += types.h
+generic-y += ucontext.h
+generic-y += unaligned.h
+generic-y += vmlinux.lds.h
+
+header-y += asm-offsets.h
+header-y += csr.h
+header-y += user.h
+header-y += vdso.h
diff --git a/arch/riscv/include/asm/asm-offsets.h b/arch/riscv/include/asm/asm-offsets.h
new file mode 100644
index 0000000..d370ee3
--- /dev/null
+++ b/arch/riscv/include/asm/asm-offsets.h
@@ -0,0 +1 @@
+#include <generated/asm-offsets.h>
diff --git a/arch/riscv/include/asm/atomic.h b/arch/riscv/include/asm/atomic.h
new file mode 100644
index 0000000..1f8d535
--- /dev/null
+++ b/arch/riscv/include/asm/atomic.h
@@ -0,0 +1,286 @@
+#ifndef _ASM_RISCV_ATOMIC_H
+#define _ASM_RISCV_ATOMIC_H
+
+#ifdef CONFIG_RV_ATOMIC
+
+#include <asm/cmpxchg.h>
+#include <asm/barrier.h>
+
+#define ATOMIC_INIT(i)	{ (i) }
+
+/**
+ * atomic_read - read atomic variable
+ * @v: pointer of type atomic_t
+ *
+ * Atomically reads the value of @v.
+ */
+static inline int atomic_read(const atomic_t *v)
+{
+	return *((volatile int *)(&(v->counter)));
+}
+
+/**
+ * atomic_set - set atomic variable
+ * @v: pointer of type atomic_t
+ * @i: required value
+ *
+ * Atomically sets the value of @v to @i.
+ */
+static inline void atomic_set(atomic_t *v, int i)
+{
+	__asm__ __volatile__ (
+		"amoswap.w zero, %0, 0(%1)"
+		:
+		: "r" (i), "r" (&(v->counter))
+		: "memory");
+}
+
+/**
+ * atomic_add - add integer to atomic variable
+ * @i: integer value to add
+ * @v: pointer of type atomic_t
+ *
+ * Atomically adds @i to @v.
+ */
+static inline void atomic_add(int i, atomic_t *v)
+{
+	__asm__ __volatile__ (
+		"amoadd.w zero, %0, 0(%1)"
+		:
+		: "r" (i), "r" (&(v->counter))
+		: "memory");
+}
+
+/**
+ * atomic_sub - subtract integer from atomic variable
+ * @i: integer value to subtract
+ * @v: pointer of type atomic_t
+ *
+ * Atomically subtracts @i from @v.
+ */
+static inline void atomic_sub(int i, atomic_t *v)
+{
+	atomic_add(-i, v);
+}
+
+/**
+ * atomic_add_return - add integer to atomic variable
+ * @i: integer value to add
+ * @v: pointer of type atomic_t
+ *
+ * Atomically adds @i to @v and returns the result
+ */
+static inline int atomic_add_return(int i, atomic_t *v)
+{
+	register int c;
+	__asm__ __volatile__ (
+		"amoadd.w %0, %1, 0(%2)"
+		: "=r" (c)
+		: "r" (i), "r" (&(v->counter))
+		: "memory");
+	return (c + i);
+}
+
+/**
+ * atomic_sub_return - subtract integer from atomic variable
+ * @i: integer value to subtract
+ * @v: pointer of type atomic_t
+ *
+ * Atomically subtracts @i from @v and returns the result
+ */
+static inline int atomic_sub_return(int i, atomic_t *v)
+{
+	return atomic_add_return(-i, v);
+}
+
+/**
+ * atomic_inc - increment atomic variable
+ * @v: pointer of type atomic_t
+ *
+ * Atomically increments @v by 1.
+ */
+static inline void atomic_inc(atomic_t *v)
+{
+	atomic_add(1, v);
+}
+
+/**
+ * atomic_dec - decrement atomic variable
+ * @v: pointer of type atomic_t
+ *
+ * Atomically decrements @v by 1.
+ */
+static inline void atomic_dec(atomic_t *v)
+{
+	atomic_add(-1, v);
+}
+
+static inline int atomic_inc_return(atomic_t *v)
+{
+	return atomic_add_return(1, v);
+}
+
+static inline int atomic_dec_return(atomic_t *v)
+{
+	return atomic_sub_return(1, v);
+}
+
+/**
+ * atomic_sub_and_test - subtract value from variable and test result
+ * @i: integer value to subtract
+ * @v: pointer of type atomic_t
+ *
+ * Atomically subtracts @i from @v and returns
+ * true if the result is zero, or false for all
+ * other cases.
+ */
+static inline int atomic_sub_and_test(int i, atomic_t *v)
+{
+	return (atomic_sub_return(i, v) == 0);
+}
+
+/**
+ * atomic_inc_and_test - increment and test
+ * @v: pointer of type atomic_t
+ *
+ * Atomically increments @v by 1
+ * and returns true if the result is zero, or false for all
+ * other cases.
+ */
+static inline int atomic_inc_and_test(atomic_t *v)
+{
+	return (atomic_inc_return(v) == 0);
+}
+
+/**
+ * atomic_dec_and_test - decrement and test
+ * @v: pointer of type atomic_t
+ *
+ * Atomically decrements @v by 1 and
+ * returns true if the result is 0, or false for all other
+ * cases.
+ */
+static inline int atomic_dec_and_test(atomic_t *v)
+{
+	return (atomic_dec_return(v) == 0);
+}
+
+/**
+ * atomic_add_negative - add and test if negative
+ * @i: integer value to add
+ * @v: pointer of type atomic_t
+ * 
+ * Atomically adds @i to @v and returns true
+ * if the result is negative, or false when
+ * result is greater than or equal to zero.
+ */
+static inline int atomic_add_negative(int i, atomic_t *v)
+{
+	return (atomic_add_return(i, v) < 0);
+}
+
+
+static inline int atomic_xchg(atomic_t *v, int n)
+{
+	register int c;
+	__asm__ __volatile__ (
+		"amoswap.w %0, %1, 0(%2)"
+		: "=r" (c)
+		: "r" (n), "r" (&(v->counter))
+		: "memory");
+	return c;
+}
+
+static inline int atomic_cmpxchg(atomic_t *v, int o, int n)
+{
+	register int prev, rc;
+	__asm__ __volatile__ (
+	"0:"
+		"lr.w %0, 0(%2)\n"
+		"bne  %0, %3, 1f\n"
+		"sc.w %1, %4, 0(%2)\n"
+		"bnez %1, 0b\n"
+	"1:"
+		: "=&r" (prev), "=&r" (rc)
+		: "r" (&(v->counter)), "r" (o), "r" (n)
+		: "memory");
+	return prev;
+}
+
+/**
+ * __atomic_add_unless - add unless the number is already a given value
+ * @v: pointer of type atomic_t
+ * @a: the amount to add to v...
+ * @u: ...unless v is equal to u.
+ *
+ * Atomically adds @a to @v, so long as @v was not already @u.
+ * Returns the old value of @v.
+ */
+static inline int __atomic_add_unless(atomic_t *v, int a, int u)
+{
+	register int prev, rc;
+	__asm__ __volatile__ (
+	"0:"
+		"lr.w %0, 0(%3)\n"
+		"beq  %0, %4, 1f\n"
+#ifdef CONFIG_64BIT
+		"addw %1, %0, %2\n"
+#else
+		"add  %1, %0, %2\n"
+#endif /* CONFIG_64BIT */
+		"sc.w %1, %1, 0(%3)\n"
+		"bnez %1, 0b\n"
+	"1:"
+		: "=&r" (prev), "=&r" (rc)
+		: "r" (a), "r" (&(v->counter)), "r" (u)
+		: "memory");
+	return prev;
+}
+
+/**
+ * atomic_clear_mask - Atomically clear bits in atomic variable
+ * @mask: Mask of the bits to be cleared
+ * @v: pointer of type atomic_t
+ *
+ * Atomically clears the bits set in @mask from @v
+ */
+static inline void atomic_clear_mask(unsigned int mask, atomic_t *v)
+{
+	__asm__ __volatile__ (
+		"amoand.w zero, %0, 0(%1)"
+		:
+		: "r" (~mask), "r" (&(v->counter))
+		: "memory");
+}
+
+/**
+ * atomic_set_mask - Atomically set bits in atomic variable
+ * @mask: Mask of the bits to be set
+ * @v: pointer of type atomic_t
+ *
+ * Atomically sets the bits set in @mask in @v
+ */
+static inline void atomic_set_mask(unsigned int mask, atomic_t *v)
+{
+	__asm__ __volatile__ (
+		"amoor.w zero, %0, 0(%1)"
+		:
+		: "r" (mask), "r" (&(v->counter))
+		: "memory");
+}
+
+/* Assume that atomic operations are already serializing */
+#define smp_mb__before_atomic_dec()	barrier()
+#define smp_mb__after_atomic_dec()	barrier()
+#define smp_mb__before_atomic_inc()	barrier()
+#define smp_mb__after_atomic_inc()	barrier()
+
+#else /* !CONFIG_RV_ATOMIC */
+
+#include <asm-generic/atomic.h>
+
+#endif /* CONFIG_RV_ATOMIC */
+
+#include <asm/atomic64.h>
+
+#endif /* _ASM_RISCV_ATOMIC_H */
diff --git a/arch/riscv/include/asm/atomic64.h b/arch/riscv/include/asm/atomic64.h
new file mode 100644
index 0000000..2ec7800
--- /dev/null
+++ b/arch/riscv/include/asm/atomic64.h
@@ -0,0 +1,277 @@
+#ifndef _ASM_RISCV_ATOMIC64_H
+#define _ASM_RISCV_ATOMIC64_H
+
+#ifdef CONFIG_GENERIC_ATOMIC64
+#include <asm-generic/atomic64.h>
+#else /* !CONFIG_GENERIC_ATOMIC64 */
+
+#include <linux/types.h>
+
+#define ATOMIC64_INIT(i)	{ (i) }
+
+/**
+ * atomic64_read - read atomic64 variable
+ * @v: pointer of type atomic64_t
+ *
+ * Atomically reads the value of @v.
+ */
+static inline s64 atomic64_read(const atomic64_t *v)
+{
+	return *((volatile long *)(&(v->counter)));
+}
+
+/**
+ * atomic64_set - set atomic64 variable
+ * @v: pointer to type atomic64_t
+ * @i: required value
+ *
+ * Atomically sets the value of @v to @i.
+ */
+static inline void atomic64_set(atomic64_t *v, s64 i)
+{
+	__asm__ __volatile__ (
+		"amoswap.d zero, %0, 0(%1)"
+		:
+		: "r" (i), "r" (&(v->counter))
+		: "memory");
+}
+
+/**
+ * atomic64_add - add integer to atomic64 variable
+ * @i: integer value to add
+ * @v: pointer to type atomic64_t
+ *
+ * Atomically adds @i to @v.
+ */
+static inline void atomic64_add(s64 a, atomic64_t *v)
+{
+	__asm__ __volatile__ (
+		"amoadd.d zero, %0, 0(%1)"
+		:
+		: "r" (a), "r" (&(v->counter))
+		: "memory");
+}
+
+/**
+ * atomic64_sub - subtract the atomic64 variable
+ * @i: integer value to subtract
+ * @v: pointer to type atomic64_t
+ *
+ * Atomically subtracts @i from @v.
+ */
+static inline void atomic64_sub(s64 a, atomic64_t *v)
+{
+	atomic64_add(-a, v);
+}
+
+/**
+ * atomic64_add_return - add and return
+ * @i: integer value to add
+ * @v: pointer to type atomic64_t
+ *
+ * Atomically adds @i to @v and returns @i + @v
+ */
+static inline s64 atomic64_add_return(s64 a, atomic64_t *v)
+{
+	register s64 c;
+	__asm__ __volatile__ (
+		"amoadd.d %0, %1, 0(%2)"
+		: "=r" (c)
+		: "r" (a), "r" (&(v->counter))
+		: "memory");
+	return (c + a);
+}
+
+static inline s64 atomic64_sub_return(s64 a, atomic64_t *v)
+{
+	return atomic64_add_return(-a, v);
+}
+
+/**
+ * atomic64_inc - increment atomic64 variable
+ * @v: pointer to type atomic64_t
+ *
+ * Atomically increments @v by 1.
+ */
+static inline void atomic64_inc(atomic64_t *v)
+{
+	atomic64_add(1L, v);
+}
+
+/**
+ * atomic64_dec - decrement atomic64 variable
+ * @v: pointer to type atomic64_t
+ *
+ * Atomically decrements @v by 1.
+ */
+static inline void atomic64_dec(atomic64_t *v)
+{
+	atomic64_add(-1L, v);
+}
+
+static inline s64 atomic64_inc_return(atomic64_t *v)
+{
+	return atomic64_add_return(1L, v);
+}
+
+static inline s64 atomic64_dec_return(atomic64_t *v)
+{
+	return atomic64_add_return(-1L, v);
+}
+
+/**
+ * atomic64_inc_and_test - increment and test
+ * @v: pointer to type atomic64_t
+ *
+ * Atomically increments @v by 1
+ * and returns true if the result is zero, or false for all
+ * other cases.
+ */
+static inline int atomic64_inc_and_test(atomic64_t *v)
+{
+	return (atomic64_inc_return(v) == 0);
+}
+
+/**
+ * atomic64_dec_and_test - decrement and test
+ * @v: pointer to type atomic64_t
+ *
+ * Atomically decrements @v by 1 and
+ * returns true if the result is 0, or false for all other
+ * cases.
+ */
+static inline int atomic64_dec_and_test(atomic64_t *v)
+{
+	return (atomic64_dec_return(v) == 0);
+}
+
+/**
+ * atomic64_sub_and_test - subtract value from variable and test result
+ * @a: integer value to subtract
+ * @v: pointer to type atomic64_t
+ *
+ * Atomically subtracts @a from @v and returns
+ * true if the result is zero, or false for all
+ * other cases.
+ */
+static inline int atomic64_sub_and_test(s64 a, atomic64_t *v)
+{
+	return (atomic64_sub_return(a, v) == 0);
+}
+
+/**
+ * atomic64_add_negative - add and test if negative
+ * @a: integer value to add
+ * @v: pointer to type atomic64_t
+ *
+ * Atomically adds @a to @v and returns true
+ * if the result is negative, or false when
+ * result is greater than or equal to zero.
+ */
+static inline int atomic64_add_negative(s64 a, atomic64_t *v)
+{
+	return (atomic64_add_return(a, v) < 0);
+}
+
+
+static inline s64 atomic64_xchg(atomic64_t *v, s64 n)
+{
+	register s64 c;
+	__asm__ __volatile__ (
+		"amoswap.d %0, %1, 0(%2)"
+		: "=r" (c)
+		: "r" (n), "r" (&(v->counter))
+		: "memory");
+	return c;
+}
+
+static inline s64 atomic64_cmpxchg(atomic64_t *v, s64 o, s64 n)
+{
+	register s64 prev, rc;
+	__asm__ __volatile__ (
+	"0:"
+		"lr.d %0, 0(%2)\n"
+		"bne  %0, %3, 1f\n"
+		"sc.d %1, %4, 0(%2)\n"
+		"bnez %1, 0b\n"
+	"1:"
+		: "=&r" (prev), "=&r" (rc)
+		: "r" (&(v->counter)), "r" (o), "r" (n)
+		: "memory");
+	return prev;
+}
+
+/*
+ * atomic64_dec_if_positive - decrement by 1 if old value positive
+ * @v: pointer of type atomic_t
+ *
+ * The function returns the old value of *v minus 1, even if
+ * the atomic variable, v, was not decremented.
+ */
+static inline s64 atomic64_dec_if_positive(atomic64_t *v)
+{
+	register s64 prev, rc;
+	__asm__ __volatile__ (
+	"0:"
+		"lr.d %0, 0(%2)\n"
+		"add  %0, %0, -1\n"
+		"bltz %0, 1f\n"
+		"sc.w %1, %0, 0(%2)\n"
+		"bnez %1, 0b\n"
+	"1:"
+		: "=&r" (prev), "=r" (rc)
+		: "r" (&(v->counter))
+		: "memory");
+	return prev;
+}
+
+/**
+ * atomic64_add_unless - add unless the number is a given value
+ * @v: pointer of type atomic64_t
+ * @a: the amount to add to v...
+ * @u: ...unless v is equal to u.
+ *
+ * Atomically adds @a to @v, so long as it was not @u.
+ * Returns true if the addition occurred and false otherwise.
+ */
+static inline int atomic64_add_unless(atomic64_t *v, s64 a, s64 u)
+{
+	register s64 tmp;
+	register int rc = 1;
+
+	__asm__ __volatile__ (
+	"0:"
+		"lr.d %0, 0(%3)\n"
+		"beq  %0, %4, 1f\n"
+		"add  %0, %0, %2\n"
+		"sc.d %1, %0, 0(%3)\n"
+		"bnez %1, 0b\n"
+	"1:"
+		: "=&r" (tmp), "=&r" (rc)
+		: "r" (a), "r" (&(v->counter)), "r" (u)
+		: "memory");
+	return !rc;
+}
+
+static inline int atomic64_inc_not_zero(atomic64_t *v)
+{
+	register s64 tmp;
+	register int rc = 1;
+
+	__asm__ __volatile__ (
+	"0:"
+		"lr.d %0, 0(%2)\n"
+		"beqz %0, 1f\n"
+		"add  %0, %0, 1\n"
+		"sc.d %1, %0, 0(%2)\n"
+		"bnez %1, 0b\n"
+	"1:"
+		: "=&r" (tmp), "=&r" (rc)
+		: "r" (&(v->counter))
+		: "memory");
+	return !rc;
+}
+
+#endif /* CONFIG_GENERIC_ATOMIC64 */
+
+#endif /* _ASM_RISCV_ATOMIC64_H */
diff --git a/arch/riscv/include/asm/barrier.h b/arch/riscv/include/asm/barrier.h
new file mode 100644
index 0000000..f583eec
--- /dev/null
+++ b/arch/riscv/include/asm/barrier.h
@@ -0,0 +1,30 @@
+#ifndef _ASM_RISCV_BARRIER_H
+#define _ASM_RISCV_BARRIER_H
+
+#ifndef __ASSEMBLY__
+
+#define nop()	__asm__ __volatile__ ("nop")
+
+#define mb()	__asm__ __volatile__ ("fence" : : : "memory")
+#define rmb()	mb()
+#define wmb()	mb()
+
+#ifdef CONFIG_SMP
+#define smp_mb()	mb()
+#define smp_rmb()	rmb()
+#define smp_wmb()	wmb()
+#else
+#define smp_mb()	barrier()
+#define smp_rmb()	barrier()
+#define smp_wmb()	barrier()
+#endif /* CONFIG_SMP */
+
+#define set_mb(var, value)  do { var = value;  mb(); } while (0)
+#define set_wmb(var, value) do { var = value; wmb(); } while (0)
+
+#define read_barrier_depends()		do {} while (0)
+#define smp_read_barrier_depends()	do {} while (0)
+
+#endif /* __ASSEMBLY__ */
+
+#endif /* _ASM_RISCV_BARRIER_H */
diff --git a/arch/riscv/include/asm/bitops.h b/arch/riscv/include/asm/bitops.h
new file mode 100644
index 0000000..79b6bc8
--- /dev/null
+++ b/arch/riscv/include/asm/bitops.h
@@ -0,0 +1,285 @@
+#ifndef _ASM_RISCV_BITOPS_H
+#define _ASM_RISCV_BITOPS_H
+
+#ifndef _LINUX_BITOPS_H
+#error "Only <linux/bitops.h> can be included directly"
+#endif /* _LINUX_BITOPS_H */
+
+#ifdef __KERNEL__
+
+#include <linux/compiler.h>
+#include <linux/irqflags.h>
+#include <asm/barrier.h>
+#include <asm/bitsperlong.h>
+
+#ifdef CONFIG_RV_ATOMIC
+
+#define LONG_MASK(nr) (1UL << ((nr) & (BITS_PER_LONG - 1)))
+#ifdef CONFIG_64BIT
+#define LONG_WORD(nr) ((nr) >> 6)
+#else
+#define LONG_WORD(nr) ((nr) >> 5)
+#endif /* CONFIG_64BIT */
+
+#ifndef smp_mb__before_clear_bit
+#define smp_mb__before_clear_bit()  smp_mb()
+#define smp_mb__after_clear_bit()   smp_mb()
+#endif /* smp_mb__before_clear_bit */
+
+/**
+ * __ffs - find first bit in word.
+ * @word: The word to search
+ *
+ * Undefined if no bit exists, so code should check against 0 first.
+ */
+/*
+static __always_inline unsigned long __ffs(unsigned long word)
+{
+	return 0;
+}
+*/
+#include <asm-generic/bitops/__ffs.h>
+
+#include <asm-generic/bitops/ffz.h>
+
+/**
+ * fls - find last (most-significant) bit set
+ * @x: the word to search
+ *
+ * This is defined the same way as ffs.
+ * Note fls(0) = 0, fls(1) = 1, fls(0x80000000) = 32.
+ */
+/*
+static __always_inline int fls(int x)
+{
+	return 0;
+}
+*/
+#include <asm-generic/bitops/fls.h>
+
+/**
+ * __fls - find last (most-significant) set bit in a long word
+ * @word: the word to search
+ *
+ * Undefined if no set bit exists, so code should check against 0 first.
+ */
+/*
+static __always_inline unsigned long __fls(unsigned long word)
+{
+	return 0;
+}
+*/
+#include <asm-generic/bitops/__fls.h>
+
+#include <asm-generic/bitops/fls64.h>
+#include <asm-generic/bitops/find.h>
+#include <asm-generic/bitops/sched.h>
+
+/**
+ * ffs - find first bit set
+ * @x: the word to search
+ *
+ * This is defined the same way as
+ * the libc and compiler builtin ffs routines, therefore
+ * differs in spirit from the above ffz (man ffs).
+ */
+/*
+static __always_inline int ffs(int x)
+{
+	return 0;
+}
+*/
+#include <asm-generic/bitops/ffs.h>
+
+#include <asm-generic/bitops/hweight.h>
+
+/**
+ * test_and_set_bit - Set a bit and return its old value
+ * @nr: Bit to set
+ * @addr: Address to count from
+ *
+ * This operation is atomic and cannot be reordered.
+ * It may be reordered on other architectures than x86.
+ * It also implies a memory barrier.
+ */
+static inline int test_and_set_bit(int nr, volatile unsigned long *addr)
+{
+	unsigned long res;
+	unsigned long mask;
+	volatile unsigned long *p;
+
+	mask = LONG_MASK(nr);
+	p = addr + LONG_WORD(nr);
+
+	__asm__ __volatile__ (
+		"amoor.d %0, %2, 0(%1)"
+		: "=r" (res)
+		: "r" (p), "r" (mask)
+		: "memory");
+
+	return ((res & mask) != 0);
+}
+
+/**
+ * test_and_clear_bit - Clear a bit and return its old value
+ * @nr: Bit to clear
+ * @addr: Address to count from
+ *
+ * This operation is atomic and cannot be reordered.
+ * It can be reordered on other architectures other than x86.
+ * It also implies a memory barrier.
+ */
+static inline int test_and_clear_bit(int nr, volatile unsigned long *addr)
+{
+	unsigned long res;
+	unsigned long mask;
+	volatile unsigned long *p;
+
+	mask = LONG_MASK(nr);
+	p = addr + LONG_WORD(nr);
+
+	__asm__ __volatile__ (
+		"amoand.d %0, %2, 0(%1)"
+		: "=r" (res)
+		: "r" (p), "r" (~mask)
+		: "memory");
+
+	return ((res & mask) != 0);
+}
+
+/**
+ * test_and_change_bit - Change a bit and return its old value
+ * @nr: Bit to change
+ * @addr: Address to count from
+ *
+ * This operation is atomic and cannot be reordered.
+ * It also implies a memory barrier.
+ */
+static inline int test_and_change_bit(int nr, volatile unsigned long *addr)
+{
+	unsigned long res;
+	unsigned long mask;
+	volatile unsigned long *p;
+
+	mask = LONG_MASK(nr);
+	p = addr + LONG_WORD(nr);
+
+	__asm__ __volatile__ (
+		"amoxor.d %0, %2, 0(%1)"
+		: "=r" (res)
+		: "r" (p), "r" (~mask)
+		: "memory");
+
+	return ((res & mask) != 0);
+}
+
+/**
+ * set_bit - Atomically set a bit in memory
+ * @nr: the bit to set
+ * @addr: the address to start counting from
+ *
+ * This function is atomic and may not be reordered.  See __set_bit()
+ * if you do not require the atomic guarantees.
+ *
+ * Note: there are no guarantees that this function will not be reordered
+ * on non x86 architectures, so if you are writing portable code,
+ * make sure not to rely on its reordering guarantees.
+ *
+ * Note that @nr may be almost arbitrarily large; this function is not
+ * restricted to acting on a single-word quantity.
+ */
+static inline void set_bit(int nr, volatile unsigned long *addr)
+{
+	(void)test_and_set_bit(nr, addr);
+}
+
+/**
+ * clear_bit - Clears a bit in memory
+ * @nr: Bit to clear
+ * @addr: Address to start counting from
+ *
+ * clear_bit() is atomic and may not be reordered.  However, it does
+ * not contain a memory barrier, so if it is used for locking purposes,
+ * you should call smp_mb__before_clear_bit() and/or smp_mb__after_clear_bit()
+ * in order to ensure changes are visible on other processors.
+ */
+static inline void clear_bit(int nr, volatile unsigned long *addr)
+{
+	(void)test_and_clear_bit(nr, addr);
+}
+
+/**
+ * change_bit - Toggle a bit in memory
+ * @nr: Bit to change
+ * @addr: Address to start counting from
+ *
+ * change_bit() is atomic and may not be reordered. It may be
+ * reordered on other architectures than x86.
+ * Note that @nr may be almost arbitrarily large; this function is not
+ * restricted to acting on a single-word quantity.
+ */
+static inline void change_bit(int nr, volatile unsigned long *addr)
+{
+	(void)test_and_change_bit(nr, addr);
+}
+
+/**
+ * test_and_set_bit_lock - Set a bit and return its old value, for lock
+ * @nr: Bit to set
+ * @addr: Address to count from
+ *
+ * This operation is atomic and provides acquire barrier semantics.
+ * It can be used to implement bit locks.
+ */
+static inline int test_and_set_bit_lock(
+	unsigned long nr, volatile unsigned long *addr)
+{
+	return test_and_set_bit(nr, addr);
+}
+
+/**
+ * clear_bit_unlock - Clear a bit in memory, for unlock
+ * @nr: the bit to set
+ * @addr: the address to start counting from
+ *
+ * This operation is atomic and provides release barrier semantics.
+ */
+static inline void clear_bit_unlock(
+	unsigned long nr, volatile unsigned long *addr)
+{
+	clear_bit(nr, addr);
+}
+
+/**
+ * __clear_bit_unlock - Clear a bit in memory, for unlock
+ * @nr: the bit to set
+ * @addr: the address to start counting from
+ *
+ * This operation is like clear_bit_unlock, however it is not atomic.
+ * It does provide release barrier semantics so it can be used to unlock
+ * a bit lock, however it would only be used if no other CPU can modify
+ * any bits in the memory until the lock is released (a good example is
+ * if the bit lock itself protects access to the other bits in the word).
+ */
+static inline void __clear_bit_unlock(
+	unsigned long nr, volatile unsigned long *addr)
+{
+	clear_bit(nr, addr);
+}
+
+#undef LONG_MASK
+#undef LONG_WORD
+
+#include <asm-generic/bitops/non-atomic.h>
+#include <asm-generic/bitops/le.h>
+#include <asm-generic/bitops/ext2-atomic.h>
+
+#else /* !CONFIG_RV_ATOMIC */
+
+#include <asm-generic/bitops.h>
+
+#endif /* CONFIG_RV_ATOMIC */
+
+#endif /* __KERNEL__ */
+
+#endif /* _ASM_RISCV_BITOPS_H */
diff --git a/arch/riscv/include/asm/bitsperlong.h b/arch/riscv/include/asm/bitsperlong.h
new file mode 100644
index 0000000..ff4f729
--- /dev/null
+++ b/arch/riscv/include/asm/bitsperlong.h
@@ -0,0 +1,38 @@
+#ifndef __ASM_RISCV_BITS_PER_LONG
+#define __ASM_RISCV_BITS_PER_LONG
+
+/*
+ * There seems to be no way of detecting this automatically from user
+ * space, so 64 bit architectures should override this in their
+ * bitsperlong.h. In particular, an architecture that supports
+ * both 32 and 64 bit user space must not rely on CONFIG_64BIT
+ * to decide it, but rather check a compiler provided macro.
+ */
+#ifndef __BITS_PER_LONG
+#if _RISCV_SIM == _ABI64
+#define __BITS_PER_LONG 64
+#elif _RISCV_SIM == _ABI32
+#define __BITS_PER_LONG 32
+#else
+#error Unknown word length
+#endif
+#endif /* __BITS_PER_LONG */
+
+#ifdef __KERNEL__
+
+#ifdef CONFIG_64BIT
+#define BITS_PER_LONG 64
+#else
+#define BITS_PER_LONG 32
+#endif /* CONFIG_64BIT */
+
+/*
+ * FIXME: The check currently breaks x86-64 build, so it's
+ * temporarily disabled. Please fix x86-64 and reenable
+ */
+#if 0 && BITS_PER_LONG != __BITS_PER_LONG
+#error Inconsistent word size. Check asm/bitsperlong.h
+#endif
+
+#endif /* __KERNEL__ */
+#endif /* __ASM_RISCV_BITS_PER_LONG */
diff --git a/arch/riscv/include/asm/byteorder.h b/arch/riscv/include/asm/byteorder.h
new file mode 100644
index 0000000..994a61a
--- /dev/null
+++ b/arch/riscv/include/asm/byteorder.h
@@ -0,0 +1,12 @@
+#ifndef _ASM_RISCV_BYTEORDER_H
+#define _ASM_RISCV_BYTEORDER_H
+
+#if defined(__RISCVEL__)
+#include <linux/byteorder/little_endian.h>
+#elif defined(__RISCVEB__)
+#include <linux/byteorder/big_endian.h>
+#else
+#error "Unknown endianness"
+#endif
+
+#endif /* _ASM_RISCV_BYTEORDER_H */
diff --git a/arch/riscv/include/asm/cache.h b/arch/riscv/include/asm/cache.h
new file mode 100644
index 0000000..e2e6718
--- /dev/null
+++ b/arch/riscv/include/asm/cache.h
@@ -0,0 +1,12 @@
+#ifndef _ASM_RISCV_CACHE_H
+#define _ASM_RISCV_CACHE_H
+
+#if defined(CONFIG_CPU_RV_ROCKET)
+#define L1_CACHE_SHIFT		6
+#else
+#define L1_CACHE_SHIFT		5
+#endif
+
+#define L1_CACHE_BYTES		(1 << L1_CACHE_SHIFT)
+
+#endif /* _ASM_RISCV_CACHE_H */
diff --git a/arch/riscv/include/asm/cmpxchg.h b/arch/riscv/include/asm/cmpxchg.h
new file mode 100644
index 0000000..7ffc67f
--- /dev/null
+++ b/arch/riscv/include/asm/cmpxchg.h
@@ -0,0 +1,115 @@
+#ifndef _ASM_RISCV_CMPXCHG_H
+#define _ASM_RISCV_CMPXCHG_H
+
+#include <linux/bug.h>
+
+#ifdef CONFIG_RV_ATOMIC
+
+#include <asm/barrier.h>
+
+#define __xchg(new, ptr, size)					\
+({								\
+	__typeof__(ptr) __ptr = (ptr);				\
+	__typeof__(new) __new = (new);				\
+	__typeof__(*(ptr)) __ret;				\
+	switch (size) {						\
+	case 4:							\
+		__asm__ __volatile__ (				\
+			"amoswap.w %0, %1, 0(%2)"		\
+			: "=r" (__ret)				\
+			: "r" (__new), "r" (__ptr)		\
+			: "memory");				\
+		break;						\
+	case 8:							\
+		__asm__ __volatile__ (				\
+			"amoswap.d %0, %1, 0(%2)"		\
+			: "=r" (__ret)				\
+			: "r" (__new), "r" (__ptr)		\
+			: "memory");				\
+		break;						\
+	default:						\
+		BUILD_BUG();					\
+	}							\
+	__ret;							\
+})
+
+#define xchg(ptr, x)    (__xchg((x), (ptr), sizeof(*(ptr))))
+
+
+/*
+ * Atomic compare and exchange.  Compare OLD with MEM, if identical,
+ * store NEW in MEM.  Return the initial value in MEM.  Success is
+ * indicated by comparing RETURN with OLD.
+ */
+#define __cmpxchg(ptr, old, new, size)				\
+({								\
+	__typeof__(ptr) __ptr = (ptr);				\
+	__typeof__(old) __old = (old);				\
+	__typeof__(new) __new = (new);				\
+	__typeof__(*(ptr)) __ret;				\
+	register unsigned int __rc;				\
+	switch (size) {						\
+	case 4:							\
+		__asm__ __volatile__ (				\
+		"0:"						\
+			"lr.w %0, 0(%2)\n"			\
+			"bne  %0, %3, 1f\n"			\
+			"sc.w %1, %4, 0(%2)\n"			\
+			"bnez %1, 0b\n"				\
+		"1:"						\
+			: "=&r" (__ret), "=&r" (__rc)		\
+			: "r" (__ptr), "r" (__old), "r" (__new)	\
+			: "memory");				\
+		break;						\
+	case 8:							\
+		__asm__ __volatile__ (				\
+		"0:"						\
+			"lr.d %0, 0(%2)\n"			\
+			"bne  %0, %3, 1f\n"			\
+			"sc.d %1, %4, 0(%2)\n"			\
+			"bnez %1, 0b\n"				\
+		"1:"						\
+			: "=&r" (__ret), "=&r" (__rc)		\
+			: "r" (__ptr), "r" (__old), "r" (__new)	\
+			: "memory");				\
+		break;						\
+	default:						\
+		BUILD_BUG();					\
+	}							\
+	__ret;							\
+})
+
+#define __cmpxchg_mb(ptr, old, new, size) 			\
+({								\
+	__typeof__(*(ptr)) __ret;				\
+	smp_mb();						\
+	__ret = __cmpxchg((ptr), (old), (new), (size));		\
+	smp_mb();						\
+	__ret;							\
+})
+
+#define cmpxchg(ptr, o, n) \
+	(__cmpxchg_mb((ptr), (o), (n), sizeof(*(ptr))))
+
+#define cmpxchg_local(ptr, o, n) \
+	(__cmpxchg((ptr), (o), (n), sizeof(*(ptr))))
+
+#define cmpxchg64(ptr, o, n)			\
+({						\
+	BUILD_BUG_ON(sizeof(*(ptr)) != 8);	\
+	cmpxchg((ptr), (o), (n));		\
+})
+
+#define cmpxchg64_local(ptr, o, n)		\
+({						\
+	BUILD_BUG_ON(sizeof(*(ptr)) != 8);	\
+	cmpxchg_local((ptr), (o), (n));		\
+})
+
+#else /* !CONFIG_RV_ATOMIC */
+
+#include <asm-generic/cmpxchg.h>
+
+#endif /* CONFIG_RV_ATOMIC */
+
+#endif /* _ASM_RISCV_CMPXCHG_H */
diff --git a/arch/riscv/include/asm/csr.h b/arch/riscv/include/asm/csr.h
new file mode 100644
index 0000000..5042bea
--- /dev/null
+++ b/arch/riscv/include/asm/csr.h
@@ -0,0 +1,125 @@
+#ifndef _ASM_RISCV_CSR_H
+#define _ASM_RISCV_CSR_H
+
+#include <linux/const.h>
+
+/* Status register flags */
+#define SR_S    _AC(0x00000001,UL) /* Supervisor */
+#define SR_PS   _AC(0x00000002,UL) /* Previous supervisor */
+#define SR_EI   _AC(0x00000004,UL) /* Enable interrupts */
+#define SR_PEI  _AC(0x00000008,UL) /* Previous EI */
+#define SR_EF   _AC(0x00000010,UL) /* Enable floating-point */
+#define SR_U64  _AC(0x00000020,UL) /* RV64 user mode */
+#define SR_S64  _AC(0x00000040,UL) /* RV64 supervisor mode */
+#define SR_VM   _AC(0x00000080,UL) /* Enable virtual memory */
+#define SR_IM   _AC(0x00FF0000,UL) /* Interrupt mask */
+#define SR_IP   _AC(0xFF000000,UL) /* Pending interrupts */
+
+#define SR_IM_SHIFT     16
+#define SR_IM_MASK(n)   ((_AC(1,UL)) << ((n) + SR_IM_SHIFT))
+
+#define EXC_INST_MISALIGNED     0
+#define EXC_INST_ACCESS         1
+#define EXC_SYSCALL             6
+#define EXC_LOAD_MISALIGNED     8
+#define EXC_STORE_MISALIGNED    9
+#define EXC_LOAD_ACCESS         10
+#define EXC_STORE_ACCESS        11
+
+#ifndef __ASSEMBLY__
+
+#define CSR_ZIMM(val) \
+	(__builtin_constant_p(val) && ((unsigned long)(val) < 0x20))
+
+#define csr_swap(csr,val)					\
+({								\
+	typeof(val) __v = (val);				\
+	if (CSR_ZIMM(__v)) { 					\
+		__asm__ __volatile__ (				\
+			"csrrw %0, " #csr ", %1"		\
+			: "=r" (__v) : "i" (__v));		\
+	} else {						\
+		__asm__ __volatile__ (				\
+			"csrrw %0, " #csr ", %1"		\
+			: "=r" (__v) : "r" (__v));		\
+	}							\
+	__v;							\
+})
+
+#define csr_read(csr)						\
+({								\
+	register unsigned long __v;				\
+	__asm__ __volatile__ (					\
+		"csrr %0, " #csr : "=r" (__v));			\
+	__v;							\
+})
+
+#define csr_write(csr,val)					\
+({								\
+	typeof(val) __v = (val);				\
+	if (CSR_ZIMM(__v)) {					\
+		__asm__ __volatile__ (				\
+			"csrw " #csr ", %0" : : "i" (__v));	\
+	} else {						\
+		__asm__ __volatile__ (				\
+			"csrw " #csr ", %0" : : "r" (__v));	\
+	}							\
+})
+
+#define csr_read_set(csr,val)					\
+({								\
+	typeof(val) __v = (val);				\
+	if (CSR_ZIMM(val)) {					\
+		__asm__ __volatile__ (				\
+			"csrrs %0, " #csr ", %1"		\
+			: "=r" (__v) : "i" (__v));		\
+	} else {						\
+		__asm__ __volatile__ (				\
+			"csrrs %0, " #csr ", %1"		\
+			: "=r" (__v) : "r" (__v));		\
+	}							\
+	__v;							\
+})
+
+#define csr_set(csr,val)					\
+({								\
+	typeof(val) __v = (val);				\
+	if (CSR_ZIMM(__v)) {					\
+		__asm__ __volatile__ (				\
+			"csrs " #csr ", %0" : : "i" (__v));	\
+	} else {						\
+		__asm__ __volatile__ (				\
+			"csrs " #csr ", %0" : : "r" (__v));	\
+	}							\
+})
+
+#define csr_read_clear(csr,val)					\
+({								\
+	typeof(val) __v = (val);				\
+	if (CSR_ZIMM(__v)) {					\
+		__asm__ __volatile__ (				\
+			"csrrc %0, " #csr ", %1"		\
+			: "=r" (__v) : "i" (__v));		\
+	} else {						\
+		__asm__ __volatile__ (				\
+			"csrrc %0, " #csr ", %1"		\
+			: "=r" (__v) : "r" (__v));		\
+	}							\
+	__v;							\
+})
+
+#define csr_clear(csr,val)					\
+({								\
+	typeof(val) __v = (val);				\
+	if (CSR_ZIMM(__v)) {					\
+		__asm__ __volatile__ (				\
+			"csrc " #csr ", %0" : : "i" (__v));	\
+	} else {						\
+		__asm__ __volatile__ (				\
+			"csrc " #csr ", %0" : : "r" (__v));	\
+	}							\
+})
+
+#endif /* __ASSEMBLY__ */
+
+#endif /* _ASM_RISCV_CSR_H */
diff --git a/arch/riscv/include/asm/current.h b/arch/riscv/include/asm/current.h
new file mode 100644
index 0000000..3944ddb
--- /dev/null
+++ b/arch/riscv/include/asm/current.h
@@ -0,0 +1,15 @@
+#ifndef _ASM_RISCV_CURRENT_H
+#define _ASM_RISCV_CURRENT_H
+
+#include <asm/csr.h>
+
+struct task_struct;
+
+static inline struct task_struct *get_current(void)
+{
+	return (struct task_struct *)(csr_read(sup0));
+}
+
+#define current (get_current())
+
+#endif /* _ASM_RISCV_CURRENT_H */
diff --git a/arch/riscv/include/asm/elf.h b/arch/riscv/include/asm/elf.h
new file mode 100644
index 0000000..f39b7d1
--- /dev/null
+++ b/arch/riscv/include/asm/elf.h
@@ -0,0 +1,114 @@
+#ifndef _ASM_RISCV_ELF_H
+#define _ASM_RISCV_ELF_H
+
+#include <asm/ptrace.h>
+
+/* ELF register definitions */
+typedef unsigned long elf_greg_t;
+
+#define ELF_NGREG (sizeof(struct pt_regs) / sizeof(elf_greg_t))
+typedef elf_greg_t elf_gregset_t[ELF_NGREG];
+
+#define ELF_NFPREG	0
+typedef double elf_fpreg_t;
+typedef elf_fpreg_t elf_fpregset_t[ELF_NFPREG];
+
+
+/* RISC-V relocation types */
+#define R_RISCV_NONE		0
+#define R_RISCV_32		2
+#define R_RISCV_REL32		3
+#define R_RISCV_JAL		4
+#define R_RISCV_HI20		5
+#define R_RISCV_LO12_I		6
+#define R_RISCV_LO12_S		7
+#define R_RISCV_PCREL_LO12_I	8
+#define R_RISCV_PCREL_LO12_S	9
+#define R_RISCV_BRANCH		10
+#define R_RISCV_CALL		11
+#define R_RISCV_PCREL_HI20	12
+#define R_RISCV_CALL_PLT	13
+#define R_RISCV_64		18
+#define R_RISCV_GOT_HI20	22
+#define R_RISCV_GOT_LO12	23
+#define R_RISCV_COPY		24
+#define R_RISCV_JUMP_SLOT	25
+/* TLS relocations */
+#define R_RISCV_TPREL_HI20	30
+#define R_RISCV_TPREL_LO12_I	31
+#define R_RISCV_TPREL_LO12_S	32
+#define R_RISCV_TLS_DTPMOD32	38
+#define R_RISCV_TLS_DTPREL32	39
+#define R_RISCV_TLS_DTPMOD64	40
+#define R_RISCV_TLS_DTPREL64	41
+#define R_RISCV_TLS_GD		42
+#define R_RISCV_TLS_DTPREL_HI16	44
+#define R_RISCV_TLS_DTPREL_LO16	45
+#define R_RISCV_TLS_GOTTPREL	46
+#define R_RISCV_TLS_TPREL32	47
+#define R_RISCV_TLS_TPREL64	48
+#define R_RISCV_TLS_GOT_HI20	51
+#define R_RISCV_TLS_GOT_LO12	52
+#define R_RISCV_TLS_GD_HI20	53
+#define R_RISCV_TLS_GD_LO12	54
+#define R_RISCV_GLOB_DAT	57
+#define R_RISCV_ADD32		58
+#define R_RISCV_ADD64		59
+#define R_RISCV_SUB32		60
+#define R_RISCV_SUB64		61
+
+/* TODO: Move definition into include/uapi/linux/elf-em.h */
+#define EM_RISCV	0xF3
+
+/*
+ * These are used to set parameters in the core dumps.
+ */
+#define ELF_ARCH	EM_RISCV
+#define ELF_CLASS	ELFCLASS64
+#define ELF_DATA	ELFDATA2MSB
+
+/*
+ * This is used to ensure we don't load something for the wrong architecture.
+ */
+#define elf_check_arch(x) ((x)->e_machine == EM_RISCV)
+
+#define CORE_DUMP_USE_REGSET
+#define ELF_EXEC_PAGESIZE	(PAGE_SIZE)
+
+/*
+ * This is the location that an ET_DYN program is loaded if exec'ed.  Typical
+ * use of this is to invoke "./ld.so someprog" to test out a new version of
+ * the loader.  We need to make sure that it is out of the way of the program
+ * that it will "exec", and that there is sufficient room for the brk.
+ */
+#define ELF_ET_DYN_BASE		((TASK_SIZE / 3) * 2)
+
+/*
+ * This yields a mask that user programs can use to figure out what
+ * instruction set this CPU supports.  This could be done in user space,
+ * but it's not easy, and we've already done it here.
+ */
+#define ELF_HWCAP	(0)
+
+/*
+ * This yields a string that ld.so will use to load implementation
+ * specific libraries for optimization.  This is more specific in
+ * intent than poking at uname or /proc/cpuinfo.
+ */
+#define ELF_PLATFORM	(NULL)
+
+#define AT_SYSINFO_EHDR 33
+#define ARCH_DLINFO						\
+do {								\
+	NEW_AUX_ENT(AT_SYSINFO_EHDR,				\
+		(elf_addr_t)current->mm->context.vdso);		\
+} while (0)
+
+
+#define ARCH_HAS_SETUP_ADDITIONAL_PAGES
+struct linux_binprm;
+extern int arch_setup_additional_pages(struct linux_binprm *bprm,
+	int uses_interp);
+
+
+#endif /* _ASM_RISCV_ELF_H */
diff --git a/arch/riscv/include/asm/htif.h b/arch/riscv/include/asm/htif.h
new file mode 100644
index 0000000..d4716d0
--- /dev/null
+++ b/arch/riscv/include/asm/htif.h
@@ -0,0 +1,54 @@
+#ifndef _ASM_RISCV_HTIF_H
+#define _ASM_RISCV_HTIF_H
+
+#include <linux/kernel.h>
+#include <linux/device.h>
+
+#include <asm/csr.h>
+
+#define HTIF_DEV_SHIFT      (56)
+#define HTIF_CMD_SHIFT      (48)
+
+#define HTIF_CMD_READ       (0x00UL)
+#define HTIF_CMD_WRITE      (0x01UL)
+#define HTIF_CMD_IDENTITY   (0xFFUL)
+
+#define HTIF_NR_DEV         (256UL)
+
+static inline void htif_tohost(unsigned long dev,
+	unsigned long cmd, unsigned long data)
+{
+	unsigned long packet;
+	packet = (dev << HTIF_DEV_SHIFT) | (cmd << HTIF_CMD_SHIFT) | data;
+	while (csr_swap(tohost, packet) != 0);
+}
+
+static inline unsigned long htif_fromhost(void)
+{
+	unsigned long data;
+	while ((data = csr_swap(fromhost, 0)) == 0);
+	return data;
+}
+
+extern struct bus_type htif_bus_type;
+
+struct htif_dev {
+	unsigned int minor;
+	const char *type;
+	const char *spec;
+	struct device dev;
+};
+
+#define to_htif_dev(d) container_of(d, struct htif_dev, dev)
+
+struct htif_driver {
+	const char *type;
+	struct device_driver driver;
+};
+
+#define to_htif_driver(d) container_of(d, struct htif_driver, driver)
+
+extern int htif_register_driver(struct htif_driver *drv);
+extern void htif_unregister_driver(struct htif_driver *drv);
+
+#endif /* _ASM_RISCV_HTIF_H */
diff --git a/arch/riscv/include/asm/io.h b/arch/riscv/include/asm/io.h
new file mode 100644
index 0000000..320da98
--- /dev/null
+++ b/arch/riscv/include/asm/io.h
@@ -0,0 +1,61 @@
+#ifndef _ASM_RISCV_IO_H
+#define _ASM_RISCV_IO_H
+
+#include <asm-generic/io.h>
+
+#ifdef __KERNEL__
+
+#ifdef CONFIG_MMU
+
+extern void __iomem *ioremap(phys_addr_t offset, unsigned long size);
+
+/*
+ * ioremap_nocache     -   map bus memory into CPU space
+ * @offset:    bus address of the memory
+ * @size:      size of the resource to map
+ *
+ * ioremap_nocache performs a platform specific sequence of operations to
+ * make bus memory CPU accessible via the readb/readw/readl/writeb/
+ * writew/writel functions and the other mmio helpers. The returned
+ * address is not guaranteed to be usable directly as a virtual
+ * address.
+ *
+ * This version of ioremap ensures that the memory is marked uncachable
+ * on the CPU as well as honouring existing caching rules from things like
+ * the PCI bus. Note that there are other caches and buffers on many
+ * busses. In particular driver authors should read up on PCI writes.
+ *
+ * It's useful if some control registers are in such an area and
+ * write combining or read caching is not desirable.
+ *
+ * Must be freed with iounmap.
+ */
+static inline void __iomem *ioremap_nocache(
+	phys_addr_t offset, unsigned long size)
+{
+	return ioremap(offset, size);
+}
+
+/**
+ * ioremap_wc	-	map memory into CPU space write combined
+ * @offset:	bus address of the memory
+ * @size:	size of the resource to map
+ *
+ * This version of ioremap ensures that the memory is marked write combining.
+ * Write combining allows faster writes to some hardware devices.
+ *
+ * Must be freed with iounmap.
+ */
+static inline void __iomem *ioremap_wc(
+	phys_addr_t offset, unsigned long size)
+{
+	return ioremap(offset, size);
+}
+
+extern void iounmap(void __iomem *addr);
+
+#endif /* CONFIG_MMU */
+
+#endif /* __KERNEL__ */
+
+#endif /* _ASM_RISCV_IO_H */
diff --git a/arch/riscv/include/asm/irq.h b/arch/riscv/include/asm/irq.h
new file mode 100644
index 0000000..c81777c
--- /dev/null
+++ b/arch/riscv/include/asm/irq.h
@@ -0,0 +1,11 @@
+#ifndef _ASM_RISCV_IRQ_H
+#define _ASM_RISCV_IRQ_H
+
+#define NR_IRQS         8
+#define IRQ_IPI         5
+#define IRQ_HOST        6
+#define IRQ_TIMER       7
+
+#include <asm-generic/irq.h>
+
+#endif /* _ASM_RISCV_IRQ_H */
diff --git a/arch/riscv/include/asm/irqflags.h b/arch/riscv/include/asm/irqflags.h
new file mode 100644
index 0000000..4b76ffc
--- /dev/null
+++ b/arch/riscv/include/asm/irqflags.h
@@ -0,0 +1,49 @@
+#ifndef _ASM_RISCV_IRQFLAGS_H
+#define _ASM_RISCV_IRQFLAGS_H
+
+#include <asm/processor.h>
+#include <asm/csr.h>
+
+/* read interrupt enabled status */
+static inline unsigned long arch_local_save_flags(void)
+{
+	return csr_read(status);
+}
+
+/* unconditionally enable interrupts */
+static inline void arch_local_irq_enable(void)
+{
+	csr_set(status, SR_EI);
+}
+
+/* unconditionally disable interrupts */
+static inline void arch_local_irq_disable(void)
+{
+	csr_clear(status, SR_EI);
+}
+
+/* get status and disable interrupts */
+static inline unsigned long arch_local_irq_save(void)
+{
+	return csr_read_clear(status, SR_EI);
+}
+
+/* test flags */
+static inline int arch_irqs_disabled_flags(unsigned long flags)
+{
+	return !(flags & SR_EI);
+}
+
+/* test hardware interrupt enable bit */
+static inline int arch_irqs_disabled(void)
+{
+	return arch_irqs_disabled_flags(arch_local_save_flags());
+}
+
+/* set interrupt enabled status */
+static inline void arch_local_irq_restore(unsigned long flags)
+{
+	csr_set(status, flags & SR_EI);
+}
+
+#endif /* _ASM_RISCV_IRQFLAGS_H */
diff --git a/arch/riscv/include/asm/mmu.h b/arch/riscv/include/asm/mmu.h
new file mode 100644
index 0000000..36c2190
--- /dev/null
+++ b/arch/riscv/include/asm/mmu.h
@@ -0,0 +1,14 @@
+#ifndef __ASM_RISCV_MMU_H
+#define __ASM_RISCV_MMU_H
+
+#ifndef __ASSEMBLY__
+
+typedef struct {
+	void *vdso;
+} mm_context_t;
+
+#endif /* __ASSEMBLY__ */
+
+#include <asm-generic/memory_model.h>
+
+#endif /* __ASM_RISCV_MMU_H */
diff --git a/arch/riscv/include/asm/mmu_context.h b/arch/riscv/include/asm/mmu_context.h
new file mode 100644
index 0000000..aaa0b81
--- /dev/null
+++ b/arch/riscv/include/asm/mmu_context.h
@@ -0,0 +1,45 @@
+#ifndef _ASM_RISCV_MMU_CONTEXT_H
+#define _ASM_RISCV_MMU_CONTEXT_H
+
+#include <asm-generic/mm_hooks.h>
+
+#include <linux/mm.h>
+#include <linux/sched.h>
+
+static inline void enter_lazy_tlb(struct mm_struct *mm,
+	struct task_struct *task)
+{
+}
+
+/* Initialize context-related info for a new mm_struct */
+static inline int init_new_context(struct task_struct *task,
+	struct mm_struct *mm)
+{
+	return 0;
+}
+
+static inline void destroy_context(struct mm_struct *mm)
+{
+}
+
+static inline void switch_mm(struct mm_struct *prev,
+	struct mm_struct *next, struct task_struct *task)
+{
+	if (likely(prev != next)) {
+		csr_write(ptbr, __pa(next->pgd));
+		csr_write(fatc, 0);
+	}
+}
+
+static inline void activate_mm(struct mm_struct *prev,
+			       struct mm_struct *next)
+{
+	switch_mm(prev, next, NULL);
+}
+
+static inline void deactivate_mm(struct task_struct *task,
+	struct mm_struct *mm)
+{
+}
+
+#endif /* _ASM_RISCV_MMU_CONTEXT_H */
diff --git a/arch/riscv/include/asm/page.h b/arch/riscv/include/asm/page.h
new file mode 100644
index 0000000..e7e50d2
--- /dev/null
+++ b/arch/riscv/include/asm/page.h
@@ -0,0 +1,116 @@
+#ifndef _ASM_RISCV_PAGE_H
+#define _ASM_RISCV_PAGE_H
+
+#include <linux/pfn.h>
+#include <linux/const.h>
+
+#ifdef CONFIG_64BIT
+#define PAGE_SHIFT	(13)
+#else
+#define PAGE_SHIFT	(12)
+#endif /* CONFIG_64BIT */
+
+#define PAGE_SIZE	(_AC(1,UL) << PAGE_SHIFT)
+#define PAGE_MASK	(~(PAGE_SIZE - 1))
+
+#ifdef __KERNEL__
+
+/*
+ * PAGE_OFFSET -- the first address of the first page of memory.
+ * When not using MMU this corresponds to the first free page in
+ * physical memory (aligned on a page boundary).
+ */
+#ifdef CONFIG_64BIT
+#define PAGE_OFFSET		_AC(0xffffffff80000000,UL)
+#else
+#define PAGE_OFFSET		_AC(0xc0000000,UL)
+#endif
+
+#ifndef __ASSEMBLY__
+
+#define PAGE_UP(addr)	(((addr)+((PAGE_SIZE)-1))&(~((PAGE_SIZE)-1)))
+#define PAGE_DOWN(addr)	((addr)&(~((PAGE_SIZE)-1)))
+
+/* align addr on a size boundary - adjust address up/down if needed */
+#define _ALIGN_UP(addr, size)	(((addr)+((size)-1))&(~((size)-1)))
+#define _ALIGN_DOWN(addr, size)	((addr)&(~((size)-1)))
+
+/* align addr on a size boundary - adjust address up if needed */
+#define _ALIGN(addr, size)	_ALIGN_UP(addr, size)
+
+#define clear_page(pgaddr)			memset((pgaddr), 0, PAGE_SIZE)
+#define copy_page(to, from)			memcpy((to), (from), PAGE_SIZE)
+
+#define clear_user_page(pgaddr, vaddr, page)	memset((pgaddr), 0, PAGE_SIZE)
+#define copy_user_page(vto, vfrom, vaddr, topg) \
+			memcpy((vto), (vfrom), PAGE_SIZE)
+
+/*
+ * Use struct definitions to apply C type checking
+ */
+
+/* Page Global Directory entry */
+typedef struct {
+	unsigned long pgd;
+} pgd_t;
+
+/* Page Table entry */
+typedef struct {
+	unsigned long pte;
+} pte_t;
+
+typedef struct {
+	unsigned long pgprot;
+} pgprot_t;
+
+typedef struct page *pgtable_t;
+
+#define pte_val(x)	((x).pte)
+#define pgd_val(x)	((x).pgd)
+#define pgprot_val(x)	((x).pgprot)
+
+#define __pte(x)	((pte_t) { (x) })
+#define __pgd(x)	((pgd_t) { (x) })
+#define __pgprot(x)	((pgprot_t) { (x) })
+
+extern unsigned long max_low_pfn;
+extern unsigned long min_low_pfn;
+extern unsigned long max_pfn;
+
+#define __pa(x)		((unsigned long)(x) - PAGE_OFFSET)
+#define __va(x)		((void *)((unsigned long) (x) + PAGE_OFFSET))
+
+#define phys_to_pfn(phys)	(PFN_DOWN(phys))
+#define pfn_to_phys(pfn)	(PFN_PHYS(pfn))
+
+#define virt_to_pfn(vaddr)	(phys_to_pfn(__pa(vaddr)))
+#define pfn_to_virt(pfn)	(__va(pfn_to_phys(pfn)))
+
+#define virt_to_page(vaddr)	(pfn_to_page(virt_to_pfn(vaddr)))
+#define page_to_virt(page)	(pfn_to_virt(page_to_pfn(page)))
+
+#define page_to_phys(page)	(pfn_to_phys(page_to_pfn(page)))
+#define page_to_bus(page)	(page_to_phys(page))
+#define phys_to_page(paddr)	(pfn_to_page(phys_to_pfn(paddr)))
+
+#define pfn_valid(pfn)		(((pfn) >= min_low_pfn) && ((pfn) < max_low_pfn))
+
+#define ARCH_PFN_OFFSET		(0UL)
+
+#endif /* __ASSEMBLY__ */
+
+#define virt_addr_valid(vaddr)	(pfn_valid(virt_to_pfn(vaddr)))
+
+#endif /* __KERNEL__ */
+
+#define VM_DATA_DEFAULT_FLAGS	(VM_READ | VM_WRITE | VM_EXEC | \
+				 VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC)
+
+#include <asm-generic/memory_model.h>
+#include <asm-generic/getorder.h>
+
+/* vDSO support */
+/* We do define AT_SYSINFO_EHDR but don't use the gate mechanism */
+#define __HAVE_ARCH_GATE_AREA
+
+#endif /* _ASM_RISCV_PAGE_H */
diff --git a/arch/riscv/include/asm/pgalloc.h b/arch/riscv/include/asm/pgalloc.h
new file mode 100644
index 0000000..dfe467f
--- /dev/null
+++ b/arch/riscv/include/asm/pgalloc.h
@@ -0,0 +1,104 @@
+#ifndef _ASM_RISCV_PGALLOC_H
+#define _ASM_RISCV_PGALLOC_H
+
+#include <linux/mm.h>
+#include <asm/tlb.h>
+
+static inline void pmd_populate_kernel(struct mm_struct *mm,
+	pmd_t *pmd, pte_t *pte)
+{
+	set_pmd(pmd, __pmd(__pa(pte) | _PAGE_T | _PAGE_V));
+}
+
+static inline void pmd_populate(struct mm_struct *mm,
+	pmd_t *pmd, pgtable_t pte)
+{
+	set_pmd(pmd, __pmd(__pa(page_address(pte)) | _PAGE_T | _PAGE_V));
+}
+
+#ifndef __PAGETABLE_PMD_FOLDED
+static inline void pud_populate(struct mm_struct *mm, pud_t *pud, pmd_t *pmd)
+{
+	set_pud(pud, __pud(__pa(pmd) | _PAGE_T | _PAGE_V));
+}
+#endif /* __PAGETABLE_PMD_FOLDED */
+
+#define pmd_pgtable(pmd)	pmd_page(pmd)
+
+static inline pgd_t *pgd_alloc(struct mm_struct *mm)
+{
+	pgd_t *pgd;
+
+	pgd = (pgd_t *)__get_free_page(GFP_KERNEL);
+	if (likely(pgd != NULL)) {
+		memset(pgd, 0, USER_PTRS_PER_PGD * sizeof(pgd_t));
+		/* Copy kernel mappings */
+		memcpy(pgd + USER_PTRS_PER_PGD,
+			swapper_pg_dir + USER_PTRS_PER_PGD,
+			(PTRS_PER_PGD - USER_PTRS_PER_PGD) * sizeof(pgd_t));
+	}
+	return pgd;
+}
+
+static inline void pgd_free(struct mm_struct *mm, pgd_t *pgd)
+{
+	free_page((unsigned long)pgd);
+}
+
+#ifndef __PAGETABLE_PMD_FOLDED
+
+static inline pmd_t *pmd_alloc_one(struct mm_struct *mm, unsigned long addr)
+{
+	return (pmd_t *)__get_free_page(
+		GFP_KERNEL | __GFP_REPEAT | __GFP_ZERO);
+}
+
+static inline void pmd_free(struct mm_struct *mm, pmd_t *pmd)
+{
+	free_page((unsigned long)pmd);
+}
+
+#define __pmd_free_tlb(tlb, pmd, addr)  pmd_free((tlb)->mm, pmd)
+
+#endif /* __PAGETABLE_PMD_FOLDED */
+
+static inline pte_t *pte_alloc_one_kernel(struct mm_struct *mm,
+	unsigned long address)
+{
+	return (pte_t *)__get_free_page(
+		GFP_KERNEL | __GFP_REPEAT | __GFP_ZERO);
+}
+
+static inline struct page *pte_alloc_one(struct mm_struct *mm,
+	unsigned long address)
+{
+	struct page *pte;
+	pte = alloc_page(GFP_KERNEL | __GFP_REPEAT | __GFP_ZERO);
+	if (likely(pte != NULL)) {
+		pgtable_page_ctor(pte);
+	}
+	return pte;
+}
+
+static inline void pte_free_kernel(struct mm_struct *mm, pte_t *pte)
+{
+	free_page((unsigned long)pte);
+}
+
+static inline void pte_free(struct mm_struct *mm, pgtable_t pte)
+{
+	pgtable_page_dtor(pte);
+	__free_page(pte);
+}
+
+#define __pte_free_tlb(tlb, pte, buf)   \
+do {                                    \
+	pgtable_page_dtor(pte);         \
+	tlb_remove_page((tlb), pte);    \
+} while (0)
+
+static inline void check_pgt_cache(void)
+{
+}
+
+#endif /* _ASM_RISCV_PGALLOC_H */
diff --git a/arch/riscv/include/asm/pgtable-32.h b/arch/riscv/include/asm/pgtable-32.h
new file mode 100644
index 0000000..562cb3d
--- /dev/null
+++ b/arch/riscv/include/asm/pgtable-32.h
@@ -0,0 +1,11 @@
+#ifndef _ASM_RISCV_PGTABLE_32_H
+#define _ASM_RISCV_PGTABLE_32_H
+
+#include <asm-generic/pgtable-nopmd.h>
+
+/* Size of region mapped by a page global directory */
+#define PGDIR_SHIFT     33
+#define PGDIR_SIZE      (1UL << PGDIR_SHIFT)
+#define PGDIR_MASK      (~(PGDIR_SIZE - 1))
+
+#endif /* _ASM_RISCV_PGTABLE_32_H */
diff --git a/arch/riscv/include/asm/pgtable-64.h b/arch/riscv/include/asm/pgtable-64.h
new file mode 100644
index 0000000..45cbfd7
--- /dev/null
+++ b/arch/riscv/include/asm/pgtable-64.h
@@ -0,0 +1,64 @@
+#ifndef _ASM_RISCV_PGTABLE_64_H
+#define _ASM_RISCV_PGTABLE_64_H
+
+#define PGDIR_SHIFT     33
+/* Size of region mapped by a page global directory */
+#define PGDIR_SIZE      (1UL << PGDIR_SHIFT)
+#define PGDIR_MASK      (~(PGDIR_SIZE - 1))
+
+#define PMD_SHIFT       23
+/* Size of region mapped by a page middle directory */
+#define PMD_SIZE        (1UL << PMD_SHIFT)
+#define PMD_MASK        (~(PMD_SIZE - 1))
+
+/* Page Middle Directory entry */
+typedef struct {
+	unsigned long pmd;
+} pmd_t;
+
+#define pmd_val(x)      ((x).pmd)
+#define __pmd(x)        ((pmd_t) { (x) })
+
+#define PTRS_PER_PMD    (PAGE_SIZE / sizeof(pmd_t))
+
+static inline int pud_present(pud_t pud)
+{
+	return (pud_val(pud) & _PAGE_PRESENT);
+}
+
+static inline int pud_none(pud_t pud)
+{
+	return (pud_val(pud) == 0);
+}
+
+static inline int pud_bad(pud_t pud)
+{
+	return !pud_present(pud);
+}
+
+static inline void set_pud(pud_t *pudp, pud_t pud)
+{
+	*pudp = pud;
+}
+
+static inline void pud_clear(pud_t *pudp)
+{
+	set_pud(pudp, __pud(0));
+}
+
+static inline unsigned long pud_page_vaddr(pud_t pud)
+{
+	return (unsigned long)__va(pud_val(pud) & PTE_PFN_MASK);
+}
+
+#define pmd_index(addr) (((addr) >> PMD_SHIFT) & (PTRS_PER_PMD - 1))
+
+static inline pmd_t *pmd_offset(pud_t *pud, unsigned long addr)
+{
+	return (pmd_t *)pud_page_vaddr(*pud) + pmd_index(addr);
+}
+
+#define pmd_ERROR(e) \
+	printk("%s:%d: bad pmd %016lx.\n", __FILE__, __LINE__, pmd_val(e))
+
+#endif /* _ASM_RISCV_PGTABLE_64_H */
diff --git a/arch/riscv/include/asm/pgtable-bits.h b/arch/riscv/include/asm/pgtable-bits.h
new file mode 100644
index 0000000..7706936
--- /dev/null
+++ b/arch/riscv/include/asm/pgtable-bits.h
@@ -0,0 +1,43 @@
+#ifndef _ASM_RISCV_PGTABLE_BITS_H
+#define _ASM_RISCV_PGTABLE_BITS_H
+
+#define PTE_PFN_SHIFT   (PAGE_SHIFT)
+/* Extracts the PFN from a pgd/pud/pmd/pte */
+#define PTE_PFN_MASK    (PAGE_MASK)
+/*
+ * RV32Sv32 page table entry:
+ * | 31 22  | 21  12 | 11  9 | 8 | 7 | 6 | 5 | 4 | 3 | 2 | 1 | 0 |
+ *   PPN[1]   PPN[0]     --    SX  SW  SR  UX  UW  UR   G   T   V
+ *
+ * RV64Sv43 page table entry:
+ * | 63  33 | 32  23 | 22  13 | 12  9 | 8 | 7 | 6 | 5 | 4 | 3 | 2 | 1 | 0 |
+ *   PPN[2]   PPN[1]   PPN[0]     --   SX  SW  SR  UX  UW  UR   G   T   V
+ */
+
+#define _PAGE_V         (1 << 0) /* Valid */
+#define _PAGE_T         (1 << 1) /* Non-leaf entry */
+#define _PAGE_G         (1 << 2) /* Global */
+
+#define _PAGE_SR        (1 << 6) /* Supervisor read */
+#define _PAGE_SW        (1 << 7) /* Supervisor write */
+#define _PAGE_SX        (1 << 8) /* Supervisor execute */
+
+#define _PAGE_UR        (1 << 3) /* User read */
+#define _PAGE_UW        (1 << 4) /* User write */
+#define _PAGE_UX        (1 << 5) /* User execute */
+
+#define _PAGE_SOFT1     (1 <<  9) /* Reserved for software */
+#define _PAGE_SOFT2     (1 << 10) /* Reserved for software */
+#define _PAGE_SOFT3     (1 << 11) /* Reserved for software */
+#define _PAGE_SOFT4     (1 << 12) /* Reserved for software */
+
+#define _PAGE_PRESENT   _PAGE_V
+#define _PAGE_ACCESSED  _PAGE_SOFT1
+#define _PAGE_DIRTY     _PAGE_SOFT2
+#define _PAGE_FILE      _PAGE_DIRTY /* when !present: non-linear file mapping */
+
+/* Set of bits to retain in pte_modify() */
+#define _PAGE_CHG_MASK  (~(_PAGE_SR | _PAGE_SW | _PAGE_SX | \
+                           _PAGE_UR | _PAGE_UW | _PAGE_UX))
+
+#endif /* _ASM_RISCV_PGTABLE_BITS_H */
diff --git a/arch/riscv/include/asm/pgtable.h b/arch/riscv/include/asm/pgtable.h
new file mode 100644
index 0000000..970b688
--- /dev/null
+++ b/arch/riscv/include/asm/pgtable.h
@@ -0,0 +1,327 @@
+#ifndef _ASM_RISCV_PGTABLE_H
+#define _ASM_RISCV_PGTABLE_H
+
+#include <asm/pgtable-bits.h>
+
+#ifndef __ASSEMBLY__
+
+#ifdef CONFIG_MMU
+
+/* Page Upper Directory not used in RISC-V */
+#include <asm-generic/pgtable-nopud.h>
+#include <asm/page.h>
+#include <linux/mm_types.h>
+
+#ifdef CONFIG_32BIT
+#include <asm/pgtable-32.h>
+#endif /* CONFIG_32BIT */
+#ifdef CONFIG_64BIT
+#include <asm/pgtable-64.h>
+#endif /* CONFIG_64BIT */
+
+/* Number of entries in the page global directory */
+#define PTRS_PER_PGD    (PAGE_SIZE / sizeof(pgd_t))
+/* Number of entries in the page table */
+#define PTRS_PER_PTE    (PAGE_SIZE / sizeof(pte_t))
+
+/* Number of PGD entries that a user-mode program can use */
+#define USER_PTRS_PER_PGD   (TASK_SIZE / PGDIR_SIZE)
+#define FIRST_USER_ADDRESS  0
+
+/* Page protection bits */
+#define _PAGE_BASE      (_PAGE_ACCESSED | _PAGE_V)
+#define _PAGE_RD        (_PAGE_SR | _PAGE_UR)
+#define _PAGE_WR        (_PAGE_SW | _PAGE_UW)
+#define _PAGE_EX        (_PAGE_SX | _PAGE_UX)
+
+#define PAGE_KERNEL     __pgprot(_PAGE_BASE | _PAGE_SR | _PAGE_SW | _PAGE_SX | _PAGE_G)
+#define PAGE_NONE       __pgprot(0)
+
+#define PAGE_R          __pgprot(_PAGE_BASE | _PAGE_RD)
+#define PAGE_W          __pgprot(_PAGE_BASE | _PAGE_WR)
+#define PAGE_RW         __pgprot(_PAGE_BASE | _PAGE_RD | _PAGE_WR)
+#define PAGE_RX         __pgprot(_PAGE_BASE | _PAGE_RD | _PAGE_EX)
+#define PAGE_RWX        __pgprot(_PAGE_BASE | _PAGE_RD | _PAGE_WR | _PAGE_EX)
+
+static inline void pgtable_cache_init(void)
+{
+	/* No page table caches to initialize */
+}
+
+static inline int pmd_present(pmd_t pmd)
+{
+	return (pmd_val(pmd) & _PAGE_PRESENT);
+}
+
+static inline int pmd_none(pmd_t pmd)
+{
+	return (pmd_val(pmd) == 0);
+}
+
+static inline int pmd_bad(pmd_t pmd)
+{
+	return !pmd_present(pmd);
+}
+
+static inline void set_pmd(pmd_t *pmdp, pmd_t pmd)
+{
+	*pmdp = pmd;
+}
+
+static inline void pmd_clear(pmd_t *pmdp)
+{
+	set_pmd(pmdp, __pmd(0));
+}
+
+#define pte_unmap(pte) ((void)(pte))
+
+#define pgd_index(addr) (((addr) >> PGDIR_SHIFT) & (PTRS_PER_PGD - 1))
+
+/* Locate an entry in the page global directory */
+static inline pgd_t *pgd_offset(const struct mm_struct *mm, unsigned long addr)
+{
+	return mm->pgd + pgd_index(addr);
+}
+/* Locate an entry in the kernel page global directory */
+#define pgd_offset_k(addr)      pgd_offset(&init_mm, (addr))
+
+extern struct page *mem_map;
+
+static inline struct page *pmd_page(pmd_t pmd)
+{
+	return pfn_to_page(pmd_val(pmd) >> PTE_PFN_SHIFT);
+}
+
+static inline unsigned long pmd_page_vaddr(pmd_t pmd)
+{
+	return (unsigned long)__va(pmd_val(pmd) & PTE_PFN_MASK);
+}
+
+/* Yields the page frame number (PFN) of a page table entry */
+static inline unsigned long pte_pfn(pte_t pte)
+{
+	return (pte_val(pte) >> PTE_PFN_SHIFT);
+}
+
+#define pte_page(x)     pfn_to_page(pte_pfn(x))
+
+/* Constructs a page table entry */
+static inline pte_t pfn_pte(unsigned long pfn, pgprot_t prot)
+{
+	return __pte((pfn << PTE_PFN_SHIFT) | pgprot_val(prot));
+}
+
+static inline pte_t mk_pte(struct page *page, pgprot_t prot)
+{
+	return pfn_pte(page_to_pfn(page), prot);
+}
+
+#define pte_index(addr) (((addr) >> PAGE_SHIFT) & (PTRS_PER_PTE - 1)) 
+#define pte_offset_map(dir, addr) \
+	((pte_t *)(page_address(pmd_page(*(dir)))) + pte_index(addr))
+
+static inline pte_t *pte_offset_kernel(pmd_t *pmd, unsigned long addr)
+{
+	return (pte_t *)pmd_page_vaddr(*pmd) + pte_index(addr);
+}
+
+/*
+ * Encode and decode a swap entry
+ *
+ * Format of swap PTE:
+ */
+#define __swp_type(x)               ((x).val & 0x1f)
+#define __swp_offset(x)             ((x).val >> PTE_PFN_SHIFT)
+#define __swp_entry(type, offset)   \
+	((swp_entry_t) { ((type) & 0x1f) | ((offset) << PTE_PFN_SHIFT) })
+#define __pte_to_swp_entry(pte)     ((swp_entry_t) { pte_val(pte) })
+#define __swp_entry_to_pte(x)       ((pte_t) { (x).val })
+
+/*
+ * Encode and decode a non-linear file mapping entry
+ *
+ * Format of file PTE:
+ */
+#ifdef CONFIG_64BIT
+#define PTE_FILE_MAX_BITS       (64 - PTE_PFN_SHIFT)
+#else
+#define PTE_FILE_MAX_BITS       (32 - PTE_PFN_SHIFT)
+#endif /* CONFIG_64BIT */
+
+static inline pte_t pgoff_to_pte(unsigned long off)
+{
+	return __pte((off << PTE_PFN_SHIFT) | _PAGE_FILE);
+}
+
+static inline unsigned long pte_to_pgoff(pte_t pte)
+{
+	return (pte_val(pte) >> PTE_PFN_SHIFT);
+}
+
+/*
+ * Certain architectures need to do special things when PTEs within
+ * a page table are directly modified.  Thus, the following hook is
+ * made available.
+ */
+static inline void set_pte(pte_t *ptep, pte_t pteval)
+{
+	*ptep = pteval;
+}
+
+static inline void set_pte_at(struct mm_struct *mm,
+	unsigned long addr, pte_t *ptep, pte_t pteval)
+{
+	set_pte(ptep, pteval);
+}
+
+static inline void pte_clear(struct mm_struct *mm,
+	unsigned long addr, pte_t *ptep)
+{
+	set_pte_at(mm, addr, ptep, __pte(0));
+}
+
+static inline int pte_present(pte_t pte)
+{
+	return (pte_val(pte) & _PAGE_PRESENT);
+}
+
+static inline int pte_none(pte_t pte)
+{
+	return (pte_val(pte) == 0);
+}
+
+/* static inline int pte_read(pte_t pte) */
+
+static inline int pte_write(pte_t pte)
+{
+	return pte_val(pte) & _PAGE_WR;
+}
+
+/* static inline int pte_exec(pte_t pte) */
+
+static inline int pte_dirty(pte_t pte)
+{
+	return pte_val(pte) & _PAGE_DIRTY;
+}
+
+static inline int pte_file(pte_t pte)
+{
+	return pte_val(pte) & _PAGE_FILE;
+}
+
+static inline int pte_young(pte_t pte)
+{
+	return pte_val(pte) & _PAGE_ACCESSED;
+}
+
+/* static inline pte_t pte_rdprotect(pte_t pte) */
+
+static inline pte_t pte_wrprotect(pte_t pte)
+{
+	return __pte(pte_val(pte) & ~(_PAGE_WR));
+}
+
+/* static inline pte_t pte_mkread(pte_t pte) */
+
+static inline pte_t pte_mkwrite(pte_t pte)
+{
+	return __pte(pte_val(pte) | _PAGE_WR);
+}
+
+/* static inline pte_t pte_mkexec(pte_t pte) */
+
+static inline pte_t pte_mkdirty(pte_t pte)
+{
+	return __pte(pte_val(pte) | _PAGE_DIRTY);
+}
+
+static inline pte_t pte_mkclean(pte_t pte)
+{
+	return __pte(pte_val(pte) & ~(_PAGE_DIRTY));
+}
+
+static inline pte_t pte_mkyoung(pte_t pte)
+{
+	return __pte(pte_val(pte) & ~(_PAGE_ACCESSED));
+}
+
+static inline pte_t pte_mkold(pte_t pte)
+{
+	return __pte(pte_val(pte) | _PAGE_ACCESSED);
+}
+
+static inline int pte_special(pte_t pte)
+{
+	return 0;
+}
+
+/* 
+ * pte_mkspecial instead does a write protect. We only expect 
+ * do_anonymous_page to use this function to mark the empty_zero_page as
+ * non-writable.
+ */
+static inline pte_t pte_mkspecial(pte_t pte)
+{
+	return __pte(pte_val(pte) & ~(_PAGE_WR));
+}
+
+/* Modify page protection bits */
+static inline pte_t pte_modify(pte_t pte, pgprot_t newprot)
+{
+	return __pte((pte_val(pte) & _PAGE_CHG_MASK) | pgprot_val(newprot));
+}
+
+#define pgd_ERROR(e) \
+	printk("%s:%d: bad pgd %016lx.\n", __FILE__, __LINE__, pgd_val(e))
+
+/* MAP_PRIVATE permissions: force writes to copy the page */
+#define __P000	PAGE_NONE
+#define __P001	PAGE_R
+#define __P010	PAGE_NONE
+#define __P011	PAGE_R
+#define __P100	PAGE_RX
+#define __P101	PAGE_RX
+#define __P110	PAGE_RX
+#define __P111	PAGE_RX
+
+/* MAP_SHARED permissions */
+#define __S000	PAGE_NONE
+#define __S001	PAGE_R
+#define __S010	PAGE_W
+#define __S011	PAGE_RW
+#define __S100	PAGE_RX
+#define __S101	PAGE_RX
+#define __S110	PAGE_RWX
+#define __S111	PAGE_RWX
+
+extern unsigned long empty_zero_page[PTRS_PER_PTE];
+#define ZERO_PAGE(vaddr) (virt_to_page(empty_zero_page))
+
+
+/* Commit new configuration to MMU hardware */
+static inline void update_mmu_cache(struct vm_area_struct *vma,
+	unsigned long address, pte_t *ptep)
+{
+}
+
+#define io_remap_pfn_range(vma, vaddr, pfn, size, prot) \
+	remap_pfn_range(vma, vaddr, pfn, size, prot)
+
+#endif /* CONFIG_MMU */
+
+extern pgd_t swapper_pg_dir[PTRS_PER_PGD];
+extern void paging_init(void);
+
+#ifndef __PAGETABLE_PMD_FOLDED
+extern pmd_t ident_pm_dir[PTRS_PER_PMD];
+extern pmd_t kern_pm_dir[PTRS_PER_PMD];
+#endif /* __PAGETABLE_PMD_FOLDED */
+
+#include <asm-generic/pgtable.h>
+
+#endif /* !__ASSEMBLY__ */
+
+#define VMALLOC_START    _AC(0xfffffffff8000000,UL)
+#define VMALLOC_END      _AC(0xffffffffffffffff,UL)
+
+#endif /* _ASM_RISCV_PGTABLE_H */
diff --git a/arch/riscv/include/asm/processor.h b/arch/riscv/include/asm/processor.h
new file mode 100644
index 0000000..7bd2326
--- /dev/null
+++ b/arch/riscv/include/asm/processor.h
@@ -0,0 +1,86 @@
+#ifndef _ASM_RISCV_PROCESSOR_H
+#define _ASM_RISCV_PROCESSOR_H
+
+#include <linux/const.h>
+
+/*
+ * User space process size: 2GB (highest virtual address below the
+ * sign-extension hole).  This may be hardcoded into a few places,
+ * so don't change it unless you know what you are doing.
+ */
+#define TASK_SIZE		_AC(0x80000000,UL)
+
+/*
+ * This decides where the kernel will search for a free chunk of vm
+ * space during mmap's.
+ */
+#define TASK_UNMAPPED_BASE	PAGE_ALIGN(TASK_SIZE >> 1)
+
+#ifdef __KERNEL__
+#define STACK_TOP		TASK_SIZE
+#define STACK_TOP_MAX		STACK_TOP
+#endif /* __KERNEL__ */
+
+#ifndef __ASSEMBLY__
+
+struct task_struct;
+struct pt_regs;
+
+/*
+ * Default implementation of macro that returns current
+ * instruction pointer ("program counter").
+ */
+#define current_text_addr()	({ __label__ _l; _l: &&_l;})
+
+/* CPU-specific state of a task */
+struct thread_struct {
+	/* Callee-saved registers */
+	unsigned long ra;
+	unsigned long s[12];	/* s[0]: frame pointer */
+	unsigned long sp;	/* Kernel mode stack */
+};
+
+#define INIT_THREAD {					\
+	.sp = sizeof(init_stack) + (long)&init_stack,	\
+}
+
+/* Return saved (kernel) PC of a blocked thread. */
+#define thread_saved_pc(t)	((t)->thread.ra)
+#define thread_saved_sp(t)	((t)->thread.sp)
+#define thread_saved_fp(t)	((t)->thread.s[0])
+
+#define task_pt_regs(tsk) \
+	((struct pt_regs *)(task_stack_page(tsk) + THREAD_SIZE) - 1)
+
+#define KSTK_EIP(tsk)		(task_pt_regs(tsk)->epc)
+#define KSTK_ESP(tsk)		(task_pt_regs(tsk)->sp)
+
+
+/* Do necessary setup to start up a newly executed thread. */
+extern void start_thread(struct pt_regs *regs,
+			unsigned long pc, unsigned long sp);
+
+/* Free all resources held by a thread. */
+static inline void release_thread(struct task_struct *dead_task)
+{
+}
+
+/* Free current thread data structures, etc. */
+static inline void exit_thread(void)
+{
+}
+
+extern unsigned long get_wchan(struct task_struct *p);
+
+
+static inline void cpu_relax(void)
+{
+	int dummy;
+	/* In lieu of a halt instruction, induce a long-latency stall. */
+	__asm__ __volatile__ ("div %0, %0, zero" : "=r" (dummy));
+	barrier();
+}
+
+#endif /* __ASSEMBLY__ */
+
+#endif /* _ASM_RISCV_PROCESSOR_H */
diff --git a/arch/riscv/include/asm/ptrace.h b/arch/riscv/include/asm/ptrace.h
new file mode 100644
index 0000000..4d636b4
--- /dev/null
+++ b/arch/riscv/include/asm/ptrace.h
@@ -0,0 +1,75 @@
+#ifndef _ASM_RISCV_PTRACE_H
+#define _ASM_RISCV_PTRACE_H
+
+#include <asm/csr.h>
+
+#ifndef __ASSEMBLY__
+
+typedef struct pt_regs {
+	unsigned long epc;
+	unsigned long ra;
+	unsigned long s[12];
+	unsigned long sp;
+	unsigned long tp;
+	unsigned long v[2];
+	unsigned long a[8];
+	unsigned long t[5];
+	unsigned long gp;
+	/* PCRs */
+	unsigned long status;
+	unsigned long badvaddr;
+	unsigned long cause;
+	/* For restarting system calls */
+	unsigned long syscallno;
+} pt_regs;
+
+#define user_mode(regs) (((regs)->status & SR_PS) == 0)
+
+
+/* Helpers for working with the instruction pointer */
+#define GET_IP(regs) ((regs)->epc)
+#define SET_IP(regs, val) (GET_IP(regs) = (val))
+
+static inline unsigned long instruction_pointer(struct pt_regs *regs)
+{
+	return GET_IP(regs);
+}
+static inline void instruction_pointer_set(struct pt_regs *regs,
+                                           unsigned long val)
+{
+	SET_IP(regs, val);
+}
+
+#define profile_pc(regs) instruction_pointer(regs)
+
+/* Helpers for working with the user stack pointer */
+#define GET_USP(regs) ((regs)->sp)
+#define SET_USP(regs, val) (GET_USP(regs) = (val))
+
+static inline unsigned long user_stack_pointer(struct pt_regs *regs)
+{
+	return GET_USP(regs);
+}
+static inline void user_stack_pointer_set(struct pt_regs *regs,
+                                          unsigned long val)
+{
+	SET_USP(regs, val);
+}
+
+/* Helpers for working with the frame pointer */
+#define GET_FP(regs) ((regs)->s[0])
+#define SET_FP(regs, val) (GET_FP(regs) = (val))
+
+static inline unsigned long frame_pointer(struct pt_regs *regs)
+{
+	return GET_FP(regs);
+}
+static inline void frame_pointer_set(struct pt_regs *regs,
+                                     unsigned long val)
+{
+	SET_FP(regs, val);
+}
+
+#endif /* __ASSEMBLY__ */
+
+#endif /* _ASM_RISCV_PTRACE_H */
diff --git a/arch/riscv/include/asm/setup.h b/arch/riscv/include/asm/setup.h
new file mode 100644
index 0000000..4a3f3c3
--- /dev/null
+++ b/arch/riscv/include/asm/setup.h
@@ -0,0 +1,12 @@
+#ifndef _ASM_RISCV_SETUP_H
+#define _ASM_RISCV_SETUP_H
+
+#ifdef __KERNEL__
+
+#define MEMORY_SIZE ((unsigned long)(*((volatile u32 *)(0UL))) << 20)
+
+#endif /* __KERNEL__ */
+
+#include <asm-generic/setup.h>
+
+#endif /* _ASM_RISCV_SETUP_H */
diff --git a/arch/riscv/include/asm/sigcontext.h b/arch/riscv/include/asm/sigcontext.h
new file mode 100644
index 0000000..65413ad
--- /dev/null
+++ b/arch/riscv/include/asm/sigcontext.h
@@ -0,0 +1,20 @@
+#ifndef __ASM_RISCV_SIGCONTEXT_H
+#define __ASM_RISCV_SIGCONTEXT_H
+
+/* This struct is saved by setup_frame in signal.c, to keep the current
+ * context while a signal handler is executed. It is restored by sys_sigreturn.
+ */
+
+struct sigcontext {
+	unsigned long epc;
+	unsigned long ra;
+	unsigned long s[12];
+	unsigned long sp;
+	unsigned long tp;
+	unsigned long v[2];
+	unsigned long a[8];
+	unsigned long t[5];
+	unsigned long gp;
+};
+
+#endif /* __ASM_RISCV_SIGCONTEXT_H */
diff --git a/arch/riscv/include/asm/string.h b/arch/riscv/include/asm/string.h
new file mode 100644
index 0000000..943735b
--- /dev/null
+++ b/arch/riscv/include/asm/string.h
@@ -0,0 +1,17 @@
+#ifndef _ASM_RISCV_STRING_H
+#define _ASM_RISCV_STRING_H
+
+#ifdef __KERNEL__
+
+#include <linux/types.h>
+#include <linux/linkage.h>
+
+#define __HAVE_ARCH_MEMSET
+extern asmlinkage void *memset(void *, int, size_t);
+
+#define __HAVE_ARCH_MEMCPY
+extern asmlinkage void *memcpy(void *, const void *, size_t);
+
+#endif /* __KERNEL__ */
+
+#endif /* _ASM_RISCV_STRING_H */
diff --git a/arch/riscv/include/asm/syscalls.h b/arch/riscv/include/asm/syscalls.h
new file mode 100644
index 0000000..083f189
--- /dev/null
+++ b/arch/riscv/include/asm/syscalls.h
@@ -0,0 +1,12 @@
+#ifndef _ASM_RISCV_SYSCALLS_H
+#define _ASM_RISCV_SYSCALLS_H
+
+#include <linux/linkage.h>
+
+#include <asm-generic/syscalls.h>
+
+/* kernel/sys_riscv.c */
+asmlinkage long sys_sysriscv(unsigned long, unsigned long,
+	unsigned long, unsigned long);
+
+#endif /* _ASM_RISCV_SYSCALLS_H */
diff --git a/arch/riscv/include/asm/thread_info.h b/arch/riscv/include/asm/thread_info.h
new file mode 100644
index 0000000..cc91e0c
--- /dev/null
+++ b/arch/riscv/include/asm/thread_info.h
@@ -0,0 +1,94 @@
+#ifndef _ASM_RISCV_THREAD_INFO_H
+#define _ASM_RISCV_THREAD_INFO_H
+
+#ifdef __KERNEL__
+
+#include <asm/page.h>
+#include <linux/const.h>
+
+/* thread information allocation */
+#define THREAD_SIZE_ORDER 	(0)
+#define THREAD_SIZE 		(PAGE_SIZE << THREAD_SIZE_ORDER)
+
+#ifndef __ASSEMBLY__
+
+#include <asm/processor.h>
+#include <asm/csr.h>
+
+typedef unsigned long mm_segment_t;
+
+/*
+ * low level task data that entry.S needs immediate access to
+ * - this struct should fit entirely inside of one cache line
+ * - this struct resides at the bottom of the supervisor stack
+ * - if the members of this struct changes, the assembly constants
+ *   in asm-offsets.c must be updated accordingly
+ */
+struct thread_info {
+	struct task_struct	*task;		/* main task structure */
+	struct exec_domain	*exec_domain;	/* execution domain */
+	unsigned long		flags;		/* low level flags */
+	__u32			cpu;		/* current CPU */
+	int                     preempt_count;  /* 0 => preemptable, <0 => BUG */
+	mm_segment_t		addr_limit;
+	struct restart_block	restart_block;
+};
+
+/*
+ * macros/functions for gaining access to the thread information structure
+ *
+ * preempt_count needs to be 1 initially, until the scheduler is functional.
+ */
+#define INIT_THREAD_INFO(tsk)			\
+{						\
+	.task		= &tsk,			\
+	.exec_domain	= &default_exec_domain,	\
+	.flags		= 0,			\
+	.cpu		= 0,			\
+	.preempt_count	= INIT_PREEMPT_COUNT,	\
+	.addr_limit	= KERNEL_DS,		\
+	.restart_block	= {			\
+		.fn = do_no_restart_syscall,	\
+	},					\
+}
+
+#define init_thread_info	(init_thread_union.thread_info)
+#define init_stack		(init_thread_union.stack)
+
+/*
+ * Pointer to the thread_info struct of the current process
+ * Assumes that the kernel mode stack (thread_union) is THREAD_SIZE-aligned
+ */
+static inline struct thread_info *current_thread_info(void)
+{
+	register unsigned long sp __asm__ ("sp");
+	return (struct thread_info *)(sp & ~(THREAD_SIZE - 1));
+}
+
+#endif /* !__ASSEMBLY__ */
+
+/*
+ * thread information flags
+ * - these are process state flags that various assembly files may need to
+ *   access
+ * - pending work-to-be-done flags are in lowest half-word
+ * - other flags in upper half-word(s)
+ */
+#define TIF_SYSCALL_TRACE	0	/* syscall trace active */
+#define TIF_NOTIFY_RESUME	1	/* callback before returning to user */
+#define TIF_SIGPENDING		2	/* signal pending */
+#define TIF_NEED_RESCHED	3	/* rescheduling necessary */
+#define TIF_RESTORE_SIGMASK	4	/* restore signal mask in do_signal() */
+#define TIF_MEMDIE		5	/* is terminating due to OOM killer */
+
+#define _TIF_SYSCALL_TRACE	(1 << TIF_SYSCALL_TRACE)
+#define _TIF_NOTIFY_RESUME	(1 << TIF_NOTIFY_RESUME)
+#define _TIF_SIGPENDING		(1 << TIF_SIGPENDING)
+#define _TIF_NEED_RESCHED	(1 << TIF_NEED_RESCHED)
+
+#define _TIF_WORK_MASK \
+	(_TIF_NOTIFY_RESUME | _TIF_SIGPENDING | _TIF_NEED_RESCHED)
+
+#endif /* __KERNEL__ */
+
+#endif /* _ASM_RISCV_THREAD_INFO_H */
diff --git a/arch/riscv/include/asm/timex.h b/arch/riscv/include/asm/timex.h
new file mode 100644
index 0000000..2803310
--- /dev/null
+++ b/arch/riscv/include/asm/timex.h
@@ -0,0 +1,27 @@
+#ifndef _ASM_RISCV_TIMEX_H
+#define _ASM_RISCV_TIMEX_H
+
+#include <asm/param.h>
+
+#define CLOCK_TICK_RATE (HZ * 100UL)
+
+typedef unsigned long cycles_t;
+
+static inline cycles_t get_cycles(void)
+{
+	cycles_t n;
+	__asm__ __volatile__ (
+		"rdcycle %0"
+		: "=r" (n));
+	return n;
+}
+
+#define ARCH_HAS_READ_CURRENT_TIMER
+
+static inline int read_current_timer(unsigned long *timer_val)
+{
+	*timer_val = get_cycles();
+	return 0;
+}
+
+#endif /* _ASM_RISCV_TIMEX_H */
diff --git a/arch/riscv/include/asm/tlb.h b/arch/riscv/include/asm/tlb.h
new file mode 100644
index 0000000..3753e68
--- /dev/null
+++ b/arch/riscv/include/asm/tlb.h
@@ -0,0 +1,27 @@
+#ifndef _ASM_RISCV_TLB_H
+#define _ASM_RISCV_TLB_H
+
+#include <asm-generic/tlb.h>
+
+static inline void tlb_flush(struct mmu_gather *tlb)
+{
+	flush_tlb_mm(tlb->mm);
+}
+
+static inline void tlb_start_vma(struct mmu_gather *tlb,
+	struct vm_area_struct *vma)
+{
+}
+
+static inline void tlb_end_vma(struct mmu_gather *tlb,
+	struct vm_area_struct *vma)
+{
+}
+
+/* Remove TLB entry for PTE mapped at a given virtual address */
+static inline void __tlb_remove_tlb_entry(struct mmu_gather *tlb,
+	pte_t *ptep, unsigned long addr)
+{
+}
+
+#endif /* _ASM_RISCV_TLB_H */
diff --git a/arch/riscv/include/asm/tlbflush.h b/arch/riscv/include/asm/tlbflush.h
new file mode 100644
index 0000000..3504222
--- /dev/null
+++ b/arch/riscv/include/asm/tlbflush.h
@@ -0,0 +1,75 @@
+#ifndef _ASM_RISCV_TLBFLUSH_H
+#define _ASM_RISCV_TLBFLUSH_H
+
+#ifdef CONFIG_MMU
+
+#include <linux/mm.h>
+#include <linux/bug.h>
+#include <asm/csr.h>
+
+/* Flush all TLB entries */
+static inline void flush_tlb_all(void)
+{
+	csr_write(fatc, 0);
+}
+
+/* Flush the TLB entries of the specified mm context */
+static inline void flush_tlb_mm(struct mm_struct *mm)
+{
+	flush_tlb_all();
+}
+
+/* Flush one page */
+static inline void flush_tlb_page(struct vm_area_struct *vma,
+	unsigned long addr)
+{
+	flush_tlb_all();
+}
+
+/* Flush a range of pages */
+static inline void flush_tlb_range(struct vm_area_struct *vma,
+	unsigned long start, unsigned long end)
+{
+	flush_tlb_all();
+}
+
+/* Flush a range of kernel pages */
+static inline void flush_tlb_kernel_range(unsigned long start,
+	unsigned long end)
+{
+	flush_tlb_all();
+}
+
+#else /* !CONFIG_MMU */
+
+static inline void flush_tlb_all(void)
+{
+	BUG();
+}
+
+static inline void flush_tlb_mm(struct mm_struct *mm)
+{
+	BUG();
+}
+
+static inline void flush_tlb_page(struct vm_area_struct *vma,
+	unsigned long addr)
+{
+	BUG();
+}
+
+static inline void flush_tlb_range(struct vm_area_struct *vma,
+	unsigned long start, unsigned long end)
+{
+	BUG();
+}
+
+static inline void flush_tlb_kernel_range(unsigned long start,
+	unsigned long end)
+{
+	BUG();
+}
+
+#endif /* CONFIG_MMU */
+
+#endif /* _ASM_RISCV_TLBFLUSH_H */
diff --git a/arch/riscv/include/asm/uaccess.h b/arch/riscv/include/asm/uaccess.h
new file mode 100644
index 0000000..bd4007d
--- /dev/null
+++ b/arch/riscv/include/asm/uaccess.h
@@ -0,0 +1,341 @@
+#ifndef _ASM_RISCV_UACCESS_H
+#define _ASM_RISCV_UACCESS_H
+
+/*
+ * User space memory access functions
+ */
+#include <linux/errno.h>
+#include <linux/compiler.h>
+#include <linux/thread_info.h>
+
+/*
+ * The fs value determines whether argument validity checking should be
+ * performed or not.  If get_fs() == USER_DS, checking is performed, with
+ * get_fs() == KERNEL_DS, checking is bypassed.
+ *
+ * For historical reasons, these macros are grossly misnamed.
+ */
+
+#define KERNEL_DS	(~0UL)
+#define USER_DS		(TASK_SIZE)
+
+#define get_ds()	(KERNEL_DS)
+#define get_fs()	(current_thread_info()->addr_limit)
+
+static inline void set_fs(mm_segment_t fs)
+{
+	current_thread_info()->addr_limit = fs;
+}
+
+#define segment_eq(a, b) ((a) == (b))
+
+#define user_addr_max()	(get_fs())
+
+
+#define VERIFY_READ	0
+#define VERIFY_WRITE	1
+
+/**
+ * access_ok: - Checks if a user space pointer is valid
+ * @type: Type of access: %VERIFY_READ or %VERIFY_WRITE.  Note that
+ *        %VERIFY_WRITE is a superset of %VERIFY_READ - if it is safe
+ *        to write to a block, it is always safe to read from it.
+ * @addr: User space pointer to start of block to check
+ * @size: Size of block to check
+ *
+ * Context: User context only.  This function may sleep.
+ *
+ * Checks if a pointer to a block of memory in user space is valid.
+ *
+ * Returns true (nonzero) if the memory block may be valid, false (zero)
+ * if it is definitely invalid.
+ *
+ * Note that, depending on architecture, this function probably just
+ * checks that the pointer is in the user space range - after calling
+ * this function, memory access functions may still return -EFAULT.
+ */
+#define access_ok(type, addr, size) ({					\
+	__chk_user_ptr(addr);						\
+	likely(__access_ok((unsigned long __force)(addr), (size)));	\
+})
+
+/* Ensure that the range [addr, addr+size) is within the process's
+ * address space
+ */
+static inline int __access_ok(unsigned long addr, unsigned long size)
+{
+	const mm_segment_t fs = get_fs();
+	return (size <= fs) && (addr <= (fs - size));
+}
+
+/*
+ * The exception table consists of pairs of addresses: the first is the
+ * address of an instruction that is allowed to fault, and the second is
+ * the address at which the program should continue.  No registers are
+ * modified, so it is entirely up to the continuation code to figure out
+ * what to do.
+ *
+ * All the routines below use bits of fixup code that are out of line
+ * with the main instruction path.  This means when everything is well,
+ * we don't even have to jump over them.  Further, they do not intrude
+ * on our cache or tlb entries.
+ */
+
+struct exception_table_entry {
+	unsigned long insn, fixup;
+};
+
+extern int fixup_exception(struct pt_regs *);
+
+/*
+ * The "__xxx" versions of the user access functions do not verify the address
+ * space - it must have been done previously with a separate "access_ok()"
+ * call.
+ */
+
+#ifdef CONFIG_MMU
+#define __get_user_asm(insn, x, ptr, err)			\
+	__asm__ __volatile__ (					\
+		"1:\n"						\
+		"	" insn " %1, (%2)\n"			\
+		"2:\n"						\
+		"	.section .fixup,\"ax\"\n"		\
+		"	.balign 4\n"				\
+		"3:\n"						\
+		"	li %0, %3\n"				\
+		"	li %1, 0\n"				\
+		"	jump 2b\n"				\
+		"	.previous\n"				\
+		"	.section __ex_table,\"a\"\n"		\
+		"	.balign 8\n"				\
+		"	.quad 1b, 3b\n"				\
+		"	.previous"				\
+		: "+r" (err), "=&r" (x)				\
+		: "r" (ptr), "i" (-EFAULT))
+#else /* !CONFIG_MMU */
+#define __get_user_asm(insn, x, ptr, err)			\
+	__asm__ __volatile__ (					\
+		insn " %0, (%1)\n"				\
+		: "=r" (x)					\
+		: "r" (ptr))
+#endif /* CONFIG_MMU */
+
+/**
+ * __get_user: - Get a simple variable from user space, with less checking.
+ * @x:   Variable to store result.
+ * @ptr: Source address, in user space.
+ *
+ * Context: User context only.  This function may sleep.
+ *
+ * This macro copies a single simple variable from user space to kernel
+ * space.  It supports simple types like char and int, but not larger
+ * data types like structures or arrays.
+ *
+ * @ptr must have pointer-to-simple-variable type, and the result of
+ * dereferencing @ptr must be assignable to @x without a cast.
+ *
+ * Caller must check the pointer with access_ok() before calling this
+ * function.
+ *
+ * Returns zero on success, or -EFAULT on error.
+ * On error, the variable @x is set to zero.
+ */
+#define __get_user(x, ptr)					\
+({								\
+	register int __gu_err = 0;				\
+	const __typeof__(*(ptr)) __user *__gu_ptr = (ptr);	\
+	__chk_user_ptr(__gu_ptr);				\
+	switch (sizeof(*__gu_ptr)) {				\
+	case 1:							\
+		__get_user_asm("lb", (x), __gu_ptr, __gu_err);	\
+		break;						\
+	case 2:							\
+		__get_user_asm("lh", (x), __gu_ptr, __gu_err);	\
+		break;						\
+	case 4:							\
+		__get_user_asm("lw", (x), __gu_ptr, __gu_err);	\
+		break;						\
+	case 8:							\
+		__get_user_asm("ld", (x), __gu_ptr, __gu_err);	\
+		break;						\
+	default:						\
+		BUILD_BUG();					\
+	}							\
+	__gu_err;						\
+})
+
+/**
+ * get_user: - Get a simple variable from user space.
+ * @x:   Variable to store result.
+ * @ptr: Source address, in user space.
+ *
+ * Context: User context only.  This function may sleep.
+ *
+ * This macro copies a single simple variable from user space to kernel
+ * space.  It supports simple types like char and int, but not larger
+ * data types like structures or arrays.
+ *
+ * @ptr must have pointer-to-simple-variable type, and the result of
+ * dereferencing @ptr must be assignable to @x without a cast.
+ *
+ * Returns zero on success, or -EFAULT on error.
+ * On error, the variable @x is set to zero.
+ */
+#define get_user(x, ptr)					\
+({								\
+	const __typeof__(*(ptr)) __user *__p = (ptr);		\
+	might_fault();						\
+	access_ok(VERIFY_READ, __p, sizeof(*__p)) ?		\
+		__get_user((x), __p) :				\
+		((x) = 0, -EFAULT);				\
+})
+
+
+#ifdef CONFIG_MMU
+#define __put_user_asm(insn, x, ptr, err)			\
+	__asm__ __volatile__ (					\
+		"1:\n"						\
+		"	" insn " %1, (%2)\n"			\
+		"2:\n"						\
+		"	.section .fixup,\"ax\"\n"		\
+		"	.balign 4\n"				\
+		"3:\n"						\
+		"	li %0, %3\n"				\
+		"	jump 2b\n"				\
+		"	.previous\n"				\
+		"	.section __ex_table,\"a\"\n"		\
+		"	.balign 8\n"				\
+		"	.quad 1b, 3b\n"				\
+		"	.previous"				\
+		: "+r" (err)					\
+		: "r" (x), "r" (ptr), "i" (-EFAULT)		\
+		: "memory" )
+#else /* !CONFIG_MMU */
+#define __put_user_asm(insn, x, ptr, err)			\
+	__asm__ __volatile__ (					\
+		insn " %0, (%1)\n"				\
+		: /* no outputs */				\
+		: "r" (x), "r" (ptr)				\
+		: "memory" )
+#endif /* CONFIG_MMU */
+
+/**
+ * __put_user: - Write a simple value into user space, with less checking.
+ * @x:   Value to copy to user space.
+ * @ptr: Destination address, in user space.
+ *
+ * Context: User context only.  This function may sleep.
+ *
+ * This macro copies a single simple value from kernel space to user
+ * space.  It supports simple types like char and int, but not larger
+ * data types like structures or arrays.
+ *
+ * @ptr must have pointer-to-simple-variable type, and @x must be assignable
+ * to the result of dereferencing @ptr.
+ *
+ * Caller must check the pointer with access_ok() before calling this
+ * function.
+ *
+ * Returns zero on success, or -EFAULT on error.
+ */
+#define __put_user(x, ptr)					\
+({								\
+	register int __pu_err = 0;				\
+	__typeof__(*(ptr)) __user *__gu_ptr = (ptr);		\
+	__chk_user_ptr(__gu_ptr);				\
+	switch (sizeof(*__gu_ptr)) {				\
+	case 1:							\
+		__put_user_asm("sb", (x), __gu_ptr, __pu_err);	\
+		break;						\
+	case 2:							\
+		__put_user_asm("sh", (x), __gu_ptr, __pu_err);	\
+		break;						\
+	case 4:							\
+		__put_user_asm("sw", (x), __gu_ptr, __pu_err);	\
+		break;						\
+	case 8:							\
+		__put_user_asm("sd", (x), __gu_ptr, __pu_err);	\
+		break;						\
+	default:						\
+		BUILD_BUG();					\
+	}							\
+	__pu_err;						\
+})
+
+/**
+ * put_user: - Write a simple value into user space.
+ * @x:   Value to copy to user space.
+ * @ptr: Destination address, in user space.
+ *
+ * Context: User context only.  This function may sleep.
+ *
+ * This macro copies a single simple value from kernel space to user
+ * space.  It supports simple types like char and int, but not larger
+ * data types like structures or arrays.
+ *
+ * @ptr must have pointer-to-simple-variable type, and @x must be assignable
+ * to the result of dereferencing @ptr.
+ *
+ * Returns zero on success, or -EFAULT on error.
+ */
+#define put_user(x, ptr)					\
+({								\
+	__typeof__(*(ptr)) __user *__p = (ptr);			\
+	might_fault();						\
+	access_ok(VERIFY_WRITE, __p, sizeof(*__p)) ?		\
+		__put_user((x), __p) :				\
+		-EFAULT;					\
+})
+
+
+extern unsigned long __must_check __copy_user(void __user *to,
+	const void __user *from, unsigned long n);
+
+static inline long __must_check __copy_from_user(void *to,
+		const void __user *from, unsigned long n)
+{
+	return __copy_user(to, from, n);
+}
+
+static inline long __must_check __copy_to_user(void __user *to,
+		const void *from, unsigned long n)
+{
+	return __copy_user(to, from, n);
+}
+
+#define __copy_from_user_inatomic(to, from, n) \
+	__copy_from_user((to), (from), (n))
+#define __copy_to_user_inatomic(to, from, n) \
+	__copy_to_user((to), (from), (n))
+
+static inline long copy_from_user(void *to,
+		const void __user * from, unsigned long n)
+{
+	might_fault();
+	return access_ok(VERIFY_READ, from, n) ?
+		__copy_from_user(to, from, n) : n;
+}
+
+static inline long copy_to_user(void __user *to,
+		const void *from, unsigned long n)
+{
+	might_fault();
+	return access_ok(VERIFY_WRITE, to, n) ?
+		__copy_to_user(to, from, n) : n;
+}
+
+extern long strncpy_from_user(char *dest, const char __user *src, long count);
+
+extern long __must_check strlen_user(const char __user *str);
+extern long __must_check strnlen_user(const char __user *str, long n);
+
+extern unsigned long __must_check __clear_user(void __user *addr, unsigned long n);
+
+static inline unsigned long __must_check clear_user(void __user *to, unsigned long n)
+{
+	might_fault();
+	return access_ok(VERIFY_WRITE, to, n) ?
+		__clear_user(to, n) : n;
+}
+
+#endif /* _ASM_RISCV_UACCESS_H */
diff --git a/arch/riscv/include/asm/unistd.h b/arch/riscv/include/asm/unistd.h
new file mode 100644
index 0000000..a216ab3
--- /dev/null
+++ b/arch/riscv/include/asm/unistd.h
@@ -0,0 +1,29 @@
+#if !defined(_ASM_RISCV_UNISTD_H) || defined(__SYSCALL)
+#define _ASM_RISCV_UNISTD_H
+
+#define __ARCH_HAVE_MMU
+#define __ARCH_WANT_SYSCALL_NO_AT
+#define __ARCH_WANT_SYSCALL_DEPRECATED
+#define __ARCH_WANT_SYSCALL_OFF_T
+#define __ARCH_WANT_SYSCALL_NO_FLAGS
+
+#define __ARCH_WANT_SYS_EXECVE
+#define __ARCH_WANT_SYS_CLONE
+#define __ARCH_WANT_SYS_VFORK
+#define __ARCH_WANT_SYS_FORK
+
+#include <asm-generic/unistd.h>
+
+#define __NR_sysriscv  __NR_arch_specific_syscall
+#ifdef CONFIG_RV_SYSRISCV_ATOMIC
+__SYSCALL(__NR_sysriscv, sys_sysriscv)
+#endif
+
+#define __NR_ipc 1080
+#undef  __NR_syscalls
+#define __NR_syscalls (__NR_ipc + 1)
+
+#define RISCV_ATOMIC_CMPXCHG    1
+#define RISCV_ATOMIC_CMPXCHG64  2
+
+#endif /* _ASM_RISCV_UNISTD_H */
diff --git a/arch/riscv/include/asm/user.h b/arch/riscv/include/asm/user.h
new file mode 100644
index 0000000..29bab0a
--- /dev/null
+++ b/arch/riscv/include/asm/user.h
@@ -0,0 +1,19 @@
+#ifndef _ASM_RISCV_USER_H
+#define _ASM_RISCV_USER_H
+
+/* Mirror pt_regs from ptrace.h */
+
+typedef struct user_regs_struct {
+	unsigned long pc;
+	unsigned long ra;
+	unsigned long s[12];
+	unsigned long sp;
+	unsigned long tp;
+	unsigned long v[2];
+	unsigned long a[8];
+	unsigned long t[5];
+	unsigned long gp;
+	unsigned long status;
+} user_regs_struct;
+
+#endif /* _ASM_RISCV_USER_H */
diff --git a/arch/riscv/include/asm/vdso.h b/arch/riscv/include/asm/vdso.h
new file mode 100644
index 0000000..77c2ec3
--- /dev/null
+++ b/arch/riscv/include/asm/vdso.h
@@ -0,0 +1,15 @@
+#ifndef _ASM_RISCV_VDSO_H
+#define _ASM_RISCV_VDSO_H
+
+#include <linux/types.h>
+
+struct vdso_data {
+};
+
+#define VDSO_SYMBOL(base, name)					\
+({								\
+	extern const char __vdso_##name[];			\
+	(void __user *)((unsigned long)(base) + __vdso_##name);	\
+})
+
+#endif /* _ASM_RISCV_VDSO_H */
diff --git a/arch/riscv/include/asm/word-at-a-time.h b/arch/riscv/include/asm/word-at-a-time.h
new file mode 100644
index 0000000..c46ddb9
--- /dev/null
+++ b/arch/riscv/include/asm/word-at-a-time.h
@@ -0,0 +1,47 @@
+#ifndef _ASM_RISCV_WORD_AT_A_TIME_H
+#define _ASM_RISCV_WORD_AT_A_TIME_H
+
+#ifdef __RISCVEL
+/* Derived from arch/x86/include/asm/word-at-a-time.h */
+
+#include <linux/kernel.h>
+
+struct word_at_a_time {
+	const unsigned long one_bits, high_bits;
+};
+
+#define WORD_AT_A_TIME_CONSTANTS { REPEAT_BYTE(0x01), REPEAT_BYTE(0x80) }
+
+static inline unsigned long has_zero(unsigned long val,
+	unsigned long *bits, const struct word_at_a_time *c)
+{
+	unsigned long mask = ((val - c->one_bits) & ~val) & c->high_bits;
+	*bits = mask;
+	return mask;
+}
+
+static inline unsigned long prep_zero_mask(unsigned long val,
+	unsigned long bits, const struct word_at_a_time *c)
+{
+	return bits;
+}
+
+static inline unsigned long create_zero_mask(unsigned long bits)
+{
+	bits = (bits - 1) & ~bits;
+	return bits >> 7;
+}
+
+static inline unsigned long find_zero(unsigned long mask)
+{
+	return fls64(mask) >> 3;
+}
+
+/* The mask we created is directly usable as a bytemask */
+#define zero_bytemask(mask) (mask)
+
+#else /* !__RISCVEL */
+#include <asm-generic/word-at-a-time.h>
+#endif /* __RISCVEL */
+
+#endif /* _ASM_RISCV_WORD_AT_A_TIME_H */
diff --git a/arch/riscv/include/uapi/asm/Kbuild b/arch/riscv/include/uapi/asm/Kbuild
new file mode 100644
index 0000000..b15bf6b
--- /dev/null
+++ b/arch/riscv/include/uapi/asm/Kbuild
@@ -0,0 +1,2 @@
+# UAPI Header export list
+include include/uapi/asm-generic/Kbuild.asm
diff --git a/arch/riscv/initramfs.txt b/arch/riscv/initramfs.txt
new file mode 100644
index 0000000..8cd3e6a
--- /dev/null
+++ b/arch/riscv/initramfs.txt
@@ -0,0 +1,4 @@
+dir /dev 755 0 0
+nod /dev/console 644 0 0 c 5 1
+nod /dev/null 644 0 0 c 1 3
+slink /init /bin/busybox 755 0 0
diff --git a/arch/riscv/kernel/Makefile b/arch/riscv/kernel/Makefile
new file mode 100644
index 0000000..8fa6815
--- /dev/null
+++ b/arch/riscv/kernel/Makefile
@@ -0,0 +1,13 @@
+#
+# Makefile for the RISC-V Linux kernel
+#
+
+extra-y := head_$(BITS).o vmlinux.lds
+
+obj-y	:= cpu.o entry.o irq.o process.o ptrace.o reset.o setup.o \
+	   signal.o syscall_table.o sys_riscv.o time.o traps.o \
+	   stacktrace.o vdso.o vdso/
+
+obj-$(CONFIG_EARLY_PRINTK)      += early_printk.o
+
+clean:
diff --git a/arch/riscv/kernel/asm-offsets.c b/arch/riscv/kernel/asm-offsets.c
new file mode 100644
index 0000000..c78bd59
--- /dev/null
+++ b/arch/riscv/kernel/asm-offsets.c
@@ -0,0 +1,63 @@
+#include <linux/kbuild.h>
+#include <linux/sched.h>
+#include <asm/thread_info.h>
+#include <asm/ptrace.h>
+
+void asm_offsets(void)
+{
+	OFFSET(TASK_THREAD_INFO, task_struct, stack);
+	OFFSET(THREAD_RA, task_struct, thread.ra);
+	OFFSET(THREAD_S0, task_struct, thread.s[0]);
+	OFFSET(THREAD_S1, task_struct, thread.s[1]);
+	OFFSET(THREAD_S2, task_struct, thread.s[2]);
+	OFFSET(THREAD_S3, task_struct, thread.s[3]);
+	OFFSET(THREAD_S4, task_struct, thread.s[4]);
+	OFFSET(THREAD_S5, task_struct, thread.s[5]);
+	OFFSET(THREAD_S6, task_struct, thread.s[6]);
+	OFFSET(THREAD_S7, task_struct, thread.s[7]);
+	OFFSET(THREAD_S8, task_struct, thread.s[8]);
+	OFFSET(THREAD_S9, task_struct, thread.s[9]);
+	OFFSET(THREAD_S10, task_struct, thread.s[10]);
+	OFFSET(THREAD_S11, task_struct, thread.s[11]);
+	OFFSET(THREAD_SP, task_struct, thread.sp);
+	OFFSET(TI_FLAGS, thread_info, flags);
+
+	DEFINE(PT_SIZE, sizeof(struct pt_regs));
+	OFFSET(PT_EPC, pt_regs, epc);
+	OFFSET(PT_RA, pt_regs, ra);
+	OFFSET(PT_FP, pt_regs, s[0]);
+	OFFSET(PT_S0, pt_regs, s[0]);
+	OFFSET(PT_S1, pt_regs, s[1]);
+	OFFSET(PT_S2, pt_regs, s[2]);
+	OFFSET(PT_S3, pt_regs, s[3]);
+	OFFSET(PT_S4, pt_regs, s[4]);
+	OFFSET(PT_S5, pt_regs, s[5]);
+	OFFSET(PT_S6, pt_regs, s[6]);
+	OFFSET(PT_S7, pt_regs, s[7]);
+	OFFSET(PT_S8, pt_regs, s[8]);
+	OFFSET(PT_S9, pt_regs, s[9]);
+	OFFSET(PT_S10, pt_regs, s[10]);
+	OFFSET(PT_S11, pt_regs, s[11]);
+	OFFSET(PT_SP, pt_regs, sp);
+	OFFSET(PT_TP, pt_regs, tp);
+	OFFSET(PT_V0, pt_regs, v[0]);
+	OFFSET(PT_V1, pt_regs, v[1]);
+	OFFSET(PT_A0, pt_regs, a[0]);
+	OFFSET(PT_A1, pt_regs, a[1]);
+	OFFSET(PT_A2, pt_regs, a[2]);
+	OFFSET(PT_A3, pt_regs, a[3]);
+	OFFSET(PT_A4, pt_regs, a[4]);
+	OFFSET(PT_A5, pt_regs, a[5]);
+	OFFSET(PT_A6, pt_regs, a[6]);
+	OFFSET(PT_A7, pt_regs, a[7]);
+	OFFSET(PT_T0, pt_regs, t[0]);
+	OFFSET(PT_T1, pt_regs, t[1]);
+	OFFSET(PT_T2, pt_regs, t[2]);
+	OFFSET(PT_T3, pt_regs, t[3]);
+	OFFSET(PT_T4, pt_regs, t[4]);
+	OFFSET(PT_GP, pt_regs, gp);
+	OFFSET(PT_STATUS, pt_regs, status);
+	OFFSET(PT_BADVADDR, pt_regs, badvaddr);
+	OFFSET(PT_CAUSE, pt_regs, cause);
+	OFFSET(PT_SYSCALLNO, pt_regs, syscallno);
+}
diff --git a/arch/riscv/kernel/cpu.c b/arch/riscv/kernel/cpu.c
new file mode 100644
index 0000000..f6636342
--- /dev/null
+++ b/arch/riscv/kernel/cpu.c
@@ -0,0 +1,35 @@
+#include <linux/init.h>
+#include <linux/seq_file.h>
+
+#ifdef CONFIG_PROC_FS
+
+static void *c_start(struct seq_file *m, loff_t *pos)
+{
+	return *pos < 1 ? (void *)1 : NULL;
+}
+
+static void *c_next(struct seq_file *m, void *v, loff_t *pos)
+{
+	++*pos;
+	return NULL;
+}
+
+static void c_stop(struct seq_file *m, void *v)
+{
+
+}
+
+static int c_show(struct seq_file *m, void *v)
+{
+	seq_printf(m, "CPU info: PUNT!\n");
+	return 0;
+}
+
+const struct seq_operations cpuinfo_op = {
+	.start	= c_start,
+	.next	= c_next,
+	.stop	= c_stop,
+	.show	= c_show
+};
+
+#endif /* CONFIG_PROC_FS */
diff --git a/arch/riscv/kernel/early_printk.c b/arch/riscv/kernel/early_printk.c
new file mode 100644
index 0000000..425d3f2
--- /dev/null
+++ b/arch/riscv/kernel/early_printk.c
@@ -0,0 +1,44 @@
+#include <linux/console.h>
+#include <linux/init.h>
+
+#include <asm/setup.h>
+#include <asm/page.h>
+#include <asm/htif.h>
+
+#define HTIF_DEV_CONSOLE	(1U)
+
+static inline void __init early_htif_putc(unsigned char ch)
+{
+	/* FIXME: Device ID should not be hard-coded. */
+	htif_tohost(HTIF_DEV_CONSOLE, HTIF_CMD_WRITE, ch);
+}
+
+static void __init early_console_write(struct console *con,
+		const char *s, unsigned int n)
+{
+	for (; n > 0; n--) {
+		unsigned char ch;
+		ch = *s++;
+		if (ch == '\n')
+			early_htif_putc('\r');
+		early_htif_putc(ch);
+	}
+}
+
+static struct console early_console_dev __initdata = {
+	.name	= "early",
+	.write	= early_console_write,
+	.flags	= CON_PRINTBUFFER | CON_BOOT,
+	.index	= -1
+};
+
+static int __init setup_early_printk(char *str)
+{
+	if (early_console == NULL) {
+		early_console = &early_console_dev;
+		register_console(early_console);
+	}
+	return 0;
+}
+
+early_param("earlyprintk", setup_early_printk);
diff --git a/arch/riscv/kernel/entry.S b/arch/riscv/kernel/entry.S
new file mode 100644
index 0000000..3d9fc28
--- /dev/null
+++ b/arch/riscv/kernel/entry.S
@@ -0,0 +1,288 @@
+#include <linux/init.h>
+#include <linux/linkage.h>
+
+#include <asm/csr.h>
+#include <asm/thread_info.h>
+#include <asm/asm-offsets.h>
+
+	.altmacro
+	.macro SAVE_ALL
+	LOCAL _restore_kernel_sp
+	LOCAL _save_context
+
+	/* Save stack pointer */
+	csrw sup1, sp
+	/* Check if originated from user mode */
+	csrr sp, status
+	andi sp, sp, SR_PS
+	bnez sp, _restore_kernel_sp
+
+	/* Switch to kernel mode stack; load stack
+	   pointer from current->thread.sp */
+	csrr sp, sup0
+	ld sp, THREAD_SP(sp)
+	j _save_context
+
+_restore_kernel_sp:
+	csrr sp, sup1
+_save_context:
+	addi sp, sp, -(PT_SIZE)
+	sd x1,  PT_RA(sp)
+	sd x2,  PT_S0(sp)
+	sd x3,  PT_S1(sp)
+	sd x4,  PT_S2(sp)
+	sd x5,  PT_S3(sp)
+	sd x6,  PT_S4(sp)
+	sd x7,  PT_S5(sp)
+	sd x8,  PT_S6(sp)
+	sd x9,  PT_S7(sp)
+	sd x10, PT_S8(sp)
+	sd x11, PT_S9(sp)
+	sd x12, PT_S10(sp)
+	sd x13, PT_S11(sp)
+	sd x15, PT_TP(sp)
+	sd x16, PT_V0(sp)
+	sd x17, PT_V1(sp)
+	sd x18, PT_A0(sp)
+	sd x19, PT_A1(sp)
+	sd x20, PT_A2(sp)
+	sd x21, PT_A3(sp)
+	sd x22, PT_A4(sp)
+	sd x23, PT_A5(sp)
+	sd x24, PT_A6(sp)
+	sd x25, PT_A7(sp)
+	sd x26, PT_T0(sp)
+	sd x27, PT_T1(sp)
+	sd x28, PT_T2(sp)
+	sd x29, PT_T3(sp)
+	sd x30, PT_T4(sp)
+	sd x31, PT_GP(sp)
+
+	csrr s0, sup1
+	csrr s1, status
+	csrr s2, epc
+	csrr s3, badvaddr
+	csrr s4, cause
+	sd s0, PT_SP(sp)
+	sd s1, PT_STATUS(sp)
+	sd s2, PT_EPC(sp)
+	sd s3, PT_BADVADDR(sp)
+	sd s4, PT_CAUSE(sp)
+	.endm
+
+	.macro RESTORE_ALL
+	csrrc v1, status, SR_EI
+	ld v0, PT_STATUS(sp)
+	li s0, ~(SR_IM | SR_EI)
+	li s1, (SR_IM)
+	and v0, v0, s0
+	and v1, v1, s1
+	/* Retain current IM field */
+	or v0, v0, v1
+	csrw status, v0
+
+	/* Save unwound kernel stack pointer
+	   into current->thread.sp */
+	addi s0, sp, PT_SIZE
+	csrr v0, sup0
+	sd s0, THREAD_SP(v0)
+
+	ld v0, PT_EPC(sp)
+	csrw epc, v0
+
+	ld x1,  PT_RA(sp)
+	ld x2,  PT_S0(sp)
+	ld x3,  PT_S1(sp)
+	ld x4,  PT_S2(sp)
+	ld x5,  PT_S3(sp)
+	ld x6,  PT_S4(sp)
+	ld x7,  PT_S5(sp)
+	ld x8,  PT_S6(sp)
+	ld x9,  PT_S7(sp)
+	ld x10, PT_S8(sp)
+	ld x11, PT_S9(sp)
+	ld x12, PT_S10(sp)
+	ld x13, PT_S11(sp)
+	ld x15, PT_TP(sp)
+	ld x16, PT_V0(sp)
+	ld x17, PT_V1(sp)
+	ld x18, PT_A0(sp)
+	ld x19, PT_A1(sp)
+	ld x20, PT_A2(sp)
+	ld x21, PT_A3(sp)
+	ld x22, PT_A4(sp)
+	ld x23, PT_A5(sp)
+	ld x24, PT_A6(sp)
+	ld x25, PT_A7(sp)
+	ld x26, PT_T0(sp)
+	ld x27, PT_T1(sp)
+	ld x28, PT_T2(sp)
+	ld x29, PT_T3(sp)
+	ld x30, PT_T4(sp)
+	ld x31, PT_GP(sp)
+
+	ld x14, PT_SP(sp)
+	.endm
+
+ENTRY(handle_exception)
+	SAVE_ALL
+	csrr s0, cause
+	la gp, _gp
+	la ra, ret_from_exception
+	/* MSB of cause differentiates between
+	   interrupts and exceptions */
+	bge s0, zero, 1f
+
+	/* Handle interrupts */
+	slli a0, s0, 1
+	srli a0, a0, 1
+	move a1, sp
+	jump do_IRQ
+1:
+	/* Handle syscalls */
+	li s1, EXC_SYSCALL
+	beq s0, s1, handle_syscall
+
+	/* Handle other exceptions */
+	move  a0, sp /* pt_regs */
+1:
+	la s1, excp_vect_table
+	la s2, excp_vect_table_end
+	slli s0, s0, 3
+	add s1, s1, s0
+	/* Check if exception code lies within bounds */
+	bgeu s1, s2, 1f
+	ld s1, 0(s1)
+	jr s1
+1:
+	jump handle_fault_unknown
+
+handle_syscall:
+	/* System calls run with interrupts enabled */
+	csrs status, SR_EI
+	/* Advance EPC to avoid executing the original
+	   scall instruction on sret */
+	ld s0, PT_EPC(sp)
+	addi s0, s0, 0x4
+	sd s0, PT_EPC(sp)
+	la s0, sys_call_table
+	/* Syscall number held in v0 */
+	sd v0, PT_SYSCALLNO(sp) /* save in case of restart */
+	slli v0, v0, 3
+	add s0, s0, v0
+	ld s0, 0(s0)
+	jalr s0
+	/* Set user v0 to kernel v0 */
+	sd v0, PT_V0(sp)
+
+ret_from_exception:
+	ld s0, PT_STATUS(sp)
+	andi s0, s0, SR_PS
+	bnez s0, restore_all
+
+resume_userspace:
+	csrc status, SR_EI /* Disable interrupts to ensure that thread
+	                      info flags are checked atomically */
+	csrr s0, sup0
+	ld s0, TASK_THREAD_INFO(s0)
+	ld s0, TI_FLAGS(s0) /* current_thread_info->flags */
+	andi s1, s0, _TIF_WORK_MASK
+	bnez s1, work_pending
+
+restore_all:
+	RESTORE_ALL
+	sret
+
+work_pending:
+	/* Enter slow path for supplementary processing */
+	la ra, resume_userspace
+	andi s1, s0, _TIF_NEED_RESCHED
+	bnez s1, work_resched
+work_notifysig:
+	/* Handle pending signals and notify-resume requests */
+	csrs status, SR_EI /* Enable interrupts for do_notify_resume() */
+	move a0, sp /* pt_regs */
+	move a1, s0 /* current_thread_info->flags */
+	jump do_notify_resume
+work_resched:
+	jump schedule
+
+END(handle_exception)
+
+
+ENTRY(ret_from_fork)
+	la ra, restore_all
+	jump schedule_tail
+ENDPROC(ret_from_fork)
+
+ENTRY(ret_from_kernel_thread)
+	call schedule_tail
+	/* Call fn(arg) */
+	la ra, restore_all
+	move a0, s1
+	jr s0
+ENDPROC(ret_from_kernel_thread)
+
+
+/*
+ * Register context switch
+ * The callee-saved registers must be saved and restored.
+ * 
+ *   a0: previous task_struct (must be preserved across the switch)
+ *   a1: next task_struct
+ */
+ENTRY(__switch_to)
+	/* Save context into prev->thread */
+	sd ra,  THREAD_RA(a0)
+	sd s0,  THREAD_S0(a0)
+	sd s1,  THREAD_S1(a0)
+	sd s2,  THREAD_S2(a0)
+	sd s3,  THREAD_S3(a0)
+	sd s4,  THREAD_S4(a0)
+	sd s5,  THREAD_S5(a0)
+	sd s6,  THREAD_S6(a0)
+	sd s7,  THREAD_S7(a0)
+	sd s8,  THREAD_S8(a0)
+	sd s9,  THREAD_S9(a0)
+	sd s10, THREAD_S10(a0)
+	sd s11, THREAD_S11(a0)
+	sd sp,  THREAD_SP(a0)
+	/* Restore context from next->thread */
+	ld ra,  THREAD_RA(a1)
+	ld s0,  THREAD_S0(a1)
+	ld s1,  THREAD_S1(a1)
+	ld s2,  THREAD_S2(a1)
+	ld s3,  THREAD_S3(a1)
+	ld s4,  THREAD_S4(a1)
+	ld s5,  THREAD_S5(a1)
+	ld s6,  THREAD_S6(a1)
+	ld s7,  THREAD_S7(a1)
+	ld s8,  THREAD_S8(a1)
+	ld s9,  THREAD_S9(a1)
+	ld s10, THREAD_S10(a1)
+	ld s11, THREAD_S11(a1)
+	ld sp,  THREAD_SP(a1)
+	csrw sup0, a1 /* Next current pointer */
+	move v0, a0   /* Preserve reference */
+	ret
+ENDPROC(__switch_to)
+
+
+	.section ".rodata"
+	/* Exception vector table */
+ENTRY(excp_vect_table)
+	.quad handle_misaligned_insn
+	.quad do_page_fault
+	.quad handle_illegal_insn
+	.quad handle_privileged_insn
+	.quad handle_privileged_insn
+	.quad handle_fault_unknown
+	.quad 0 /* handle_syscall */
+	.quad handle_fault_unknown
+	.quad handle_misaligned_data
+	.quad handle_misaligned_data
+	.quad do_page_fault
+	.quad do_page_fault
+excp_vect_table_end:
+END(excp_vect_table)
+
diff --git a/arch/riscv/kernel/head_64.S b/arch/riscv/kernel/head_64.S
new file mode 100644
index 0000000..0e87b9d
--- /dev/null
+++ b/arch/riscv/kernel/head_64.S
@@ -0,0 +1,121 @@
+#include <linux/init.h>
+#include <linux/linkage.h>
+#include <asm/thread_info.h>
+#include <asm/page.h>
+#include <asm/pgtable.h>
+#include <asm/csr.h>
+
+#define __va(x) ((x) + PAGE_OFFSET)
+
+#define PGDIR_SHIFT 33
+#define PMDIR_SHIFT 23
+#define VPN_MASK    (0x3ff)
+#define PAGE_SUPV (_PAGE_SR | _PAGE_SW | _PAGE_SX)
+
+#define PGE_OFF(va) ((((va) >> PGDIR_SHIFT) & VPN_MASK) << 3)
+#define PME_OFF(va) ((((va) >> PMDIR_SHIFT) & VPN_MASK) << 3)
+
+
+__INIT
+ENTRY(_start)
+
+	/* Enable RV64 mode; temporarily disable virtual memory */
+	li s0, (SR_S64 | SR_U64)
+	li s1, (SR_VM | SR_IM | SR_EI)
+	csrs status, s0
+	csrc status, s1
+
+	/* Load the global pointer (before any other use of la) */
+	la gp, _gp
+
+	/* Clear the .bss segment */
+	la a0, __bss_start
+	li a1, 0
+	la a2, __bss_stop
+	sub a2, a2, a0
+	call memset
+
+	/* Set PTBR and flush TLB */
+	la s0, swapper_pg_dir
+	csrw ptbr, s0
+	csrw fatc, 0
+
+	/* Initialize provisional page tables */
+	la s1, ident_pm_dir
+	la s2, kern_pm_dir
+
+#if (PAGE_OFFSET & (PMDIR_SHIFT - 1))
+#error PAGE_OFFSET must be aligned on a 4 MiB superpage
+#endif
+
+	/* PGD entry for identity mapping */
+	ori s3, s1, (PAGE_SUPV | _PAGE_T | _PAGE_V)
+	sd s3, 0(s0)
+
+	/* PGD entry for kernel mapping */
+	ori s3, s2, (PAGE_SUPV | _PAGE_T | _PAGE_V)
+	li s4, PGE_OFF(PAGE_OFFSET)
+	add s0, s0, s4
+	sd s3, 0(s0)
+
+	/* PMD entries to cover the entire kernel virtual
+	   address space using 4 MiB superpages */
+	li s0, PME_OFF(VMALLOC_START)
+	add s0, s2, s0  /* End address of kern_pm_dir table */
+	li s3, PME_OFF(PAGE_OFFSET)
+	add s2, s2, s3  /* Address of first PTE in kern_pm_dir */
+	li s3, (PAGE_SUPV | _PAGE_G | _PAGE_V)
+	li s4, (1 << PMDIR_SHIFT)
+1:
+	sd s3, 0(s1)    /* Identity mapping */
+	sd s3, 0(s2)    /* Kernel mapping */
+	add s3, s3, s4  /* Increment PFN */
+	addi s1, s1, 0x8
+	addi s2, s2, 0x8
+	bltu s2, s0, 1b
+
+	/* Enable paging */
+	li s0, SR_VM
+	csrs status, s0
+
+	/* Relocate to kernel mapping */
+	li s0, PAGE_OFFSET
+	add gp, gp, s0
+
+	/* Initialize stack pointer */
+	la sp, __va(init_thread_union) + THREAD_SIZE
+	/* Initialize current thread_struct pointer */
+	la s0, __va(init_task)
+	csrw sup0, s0
+
+	la s0, __va(start_kernel)
+	jr s0
+
+END(_start)
+
+
+__PAGE_ALIGNED_BSS
+	/* Empty zero page */
+	.balign PAGE_SIZE
+ENTRY(empty_zero_page)
+	.fill (empty_zero_page + PAGE_SIZE) - ., 1, 0x00
+END(empty_zero_page)
+
+	/* Provisional PGD */
+	.balign PAGE_SIZE
+ENTRY(swapper_pg_dir)
+	.fill (swapper_pg_dir + PAGE_SIZE) - ., 1, 0x00
+END(swapper_pg_dir)
+
+	/* Provisional PMD for initial identity mapping */
+	.balign PAGE_SIZE
+ENTRY(ident_pm_dir)
+	.fill (ident_pm_dir + PAGE_SIZE) - ., 1, 0x00
+END(ident_pm_dir)
+
+	/* Provisional PMD for initial kernel mapping */
+	.balign PAGE_SIZE
+ENTRY(kern_pm_dir)
+	.fill (kern_pm_dir + PAGE_SIZE) - ., 1, 0x00
+END(kern_pm_dir)
+
diff --git a/arch/riscv/kernel/irq.c b/arch/riscv/kernel/irq.c
new file mode 100644
index 0000000..921a23e
--- /dev/null
+++ b/arch/riscv/kernel/irq.c
@@ -0,0 +1,42 @@
+#include <linux/interrupt.h>
+#include <linux/ftrace.h>
+#include <linux/seq_file.h>
+
+#include <asm/ptrace.h>
+
+asmlinkage void __irq_entry do_IRQ(unsigned int irq, struct pt_regs *regs)
+{
+	struct pt_regs *old_regs;
+
+	old_regs = set_irq_regs(regs);
+	irq_enter();
+	generic_handle_irq(irq);
+	irq_exit();
+	set_irq_regs(old_regs);
+}
+
+static void riscv_irq_mask(struct irq_data *d)
+{
+	csr_clear(status, SR_IM_MASK(d->irq));
+}
+
+static void riscv_irq_unmask(struct irq_data *d)
+{
+	csr_set(status, SR_IM_MASK(d->irq));
+}
+
+struct irq_chip riscv_irq_chip = {
+	.name = "riscv",
+	.irq_mask = riscv_irq_mask,
+	.irq_mask_ack = riscv_irq_mask,
+	.irq_unmask = riscv_irq_unmask,
+};
+
+void __init init_IRQ(void)
+{
+	unsigned int irq;
+	for (irq = 0; irq < NR_IRQS; irq++)
+	{
+		irq_set_chip_and_handler(irq, &riscv_irq_chip, handle_level_irq);
+	}
+}
diff --git a/arch/riscv/kernel/process.c b/arch/riscv/kernel/process.c
new file mode 100644
index 0000000..4d3b845
--- /dev/null
+++ b/arch/riscv/kernel/process.c
@@ -0,0 +1,96 @@
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/tick.h>
+#include <linux/ptrace.h>
+
+#include <asm/unistd.h>
+#include <asm/processor.h>
+#include <asm/csr.h>
+#include <asm/string.h>
+
+extern asmlinkage void ret_from_fork(void);
+extern asmlinkage void ret_from_kernel_thread(void);
+
+#if 0
+/*
+ * Default to the generic definition until the RISC-V specification
+ * incorporates architectural support an explicit sleep mode.
+ */
+void arch_cpu_idle(void)
+{
+	local_irq_enable();
+}
+#endif
+
+void show_regs(struct pt_regs *regs)
+{
+	show_regs_print_info(KERN_DEFAULT);
+
+	printk("epc: %016lx ra : %016lx s0 : %016lx\n",
+		regs->epc, regs->ra, regs->s[0]);
+	printk("s1 : %016lx s2 : %016lx s3 : %016lx\n",
+		regs->s[1], regs->s[2], regs->s[3]);
+	printk("s4 : %016lx s5 : %016lx s6 : %016lx\n",
+		regs->s[4], regs->s[5], regs->s[6]);
+	printk("s7 : %016lx s8 : %016lx s9 : %016lx\n",
+		regs->s[7], regs->s[8], regs->s[9]);
+	printk("s10: %016lx s11: %016lx sp : %016lx\n",
+		regs->s[10], regs->s[11], regs->sp);
+	printk("tp : %016lx v0 : %016lx v1 : %016lx\n",
+		regs->tp, regs->v[0], regs->v[1]);
+	printk("a0 : %016lx a1 : %016lx a2 : %016lx\n",
+		regs->a[0], regs->a[1], regs->a[2]);
+	printk("a3 : %016lx a4 : %016lx a5 : %016lx\n",
+		regs->a[3], regs->a[4], regs->a[5]);
+	printk("a6 : %016lx a7 : %016lx t0 : %016lx\n",
+		regs->a[6], regs->a[7], regs->t[0]);
+	printk("t1 : %016lx t2 : %016lx t3 : %016lx\n",
+		regs->t[1], regs->t[2], regs->t[3]);
+	printk("t4 : %016lx gp : %016lx\n",
+		regs->t[4], regs->gp);
+
+	printk("status: %016lx badvaddr: %016lx cause: %016lx\n",
+		regs->status, regs->badvaddr, regs->cause);
+}
+
+void start_thread(struct pt_regs *regs, unsigned long pc, 
+	unsigned long sp)
+{
+	/* Remove supervisor privileges */
+	regs->status &= ~(SR_PS);
+	regs->epc = pc;
+	regs->sp = sp;
+}
+
+void flush_thread(void)
+{
+}
+
+int copy_thread(unsigned long clone_flags, unsigned long usp,
+	unsigned long arg, struct task_struct *p)
+{
+	struct pt_regs *childregs = task_pt_regs(p);
+
+	/* p->thread holds context to be restored by __switch_to() */
+	if (unlikely(p->flags & PF_KTHREAD)) {
+		/* Kernel thread */
+		const register unsigned long gp __asm__ ("gp");
+		memset(childregs, 0, sizeof(struct pt_regs));
+		childregs->gp = gp;
+		childregs->status = (/*SR_IM |*/ SR_VM | SR_S64 | SR_U64 | SR_EF | SR_PEI | SR_PS | SR_S);
+
+		p->thread.ra = (unsigned long)ret_from_kernel_thread;
+		p->thread.s[0] = usp; /* fn */
+		p->thread.s[1] = arg;
+	} else {
+		*childregs = *(current_pt_regs());
+		if (usp) /* User fork */
+			childregs->sp = usp;
+		if (clone_flags & CLONE_SETTLS)
+			childregs->tp = childregs->a[5];
+		childregs->v[0] = 0; /* Return value of fork() */
+		p->thread.ra = (unsigned long)ret_from_fork;
+	}
+	p->thread.sp = (unsigned long)childregs; /* kernel sp */
+	return 0;
+}
diff --git a/arch/riscv/kernel/ptrace.c b/arch/riscv/kernel/ptrace.c
new file mode 100644
index 0000000..56828c4
--- /dev/null
+++ b/arch/riscv/kernel/ptrace.c
@@ -0,0 +1,25 @@
+#include <linux/ptrace.h>
+#include <linux/elf.h>
+#include <linux/regset.h>
+
+static const struct user_regset_view user_riscv_native_view = {
+	.name = "riscv",
+	.e_machine = EM_RISCV,
+	.regsets = NULL,
+	.n = 0,
+};
+
+const struct user_regset_view *task_user_regset_view(struct task_struct *task)
+{
+	return &user_riscv_native_view;
+}
+
+void ptrace_disable(struct task_struct *child)
+{
+}
+
+long arch_ptrace(struct task_struct *child, long request,
+                 unsigned long addr, unsigned long data)
+{
+	return 0;
+}
diff --git a/arch/riscv/kernel/reset.c b/arch/riscv/kernel/reset.c
new file mode 100644
index 0000000..5f55369
--- /dev/null
+++ b/arch/riscv/kernel/reset.c
@@ -0,0 +1,17 @@
+#include <linux/reboot.h>
+#include <linux/export.h>
+
+void (*pm_power_off)(void);
+EXPORT_SYMBOL(pm_power_off);
+
+void machine_restart(char *cmd)
+{
+}
+
+void machine_halt(void)
+{
+}
+
+void machine_power_off(void)
+{
+}
diff --git a/arch/riscv/kernel/setup.c b/arch/riscv/kernel/setup.c
new file mode 100644
index 0000000..1095ea6
--- /dev/null
+++ b/arch/riscv/kernel/setup.c
@@ -0,0 +1,96 @@
+#include <linux/init.h>
+#include <linux/mm.h>
+#include <linux/bootmem.h>
+#include <linux/sched.h>
+#include <linux/initrd.h>
+
+#include <asm/setup.h>
+#include <asm/sections.h>
+#include <asm/pgtable.h>
+
+static char __initdata command_line[COMMAND_LINE_SIZE];
+#ifdef CONFIG_CMDLINE_BOOL
+static char __initdata builtin_cmdline[COMMAND_LINE_SIZE] = CONFIG_CMDLINE;
+#endif /* CONFIG_CMDLINE_BOOL */
+
+#ifdef CONFIG_BLK_DEV_INITRD
+static void __init setup_initrd(void)
+{
+	extern char __initramfs_start[];
+	extern unsigned long __initramfs_size;
+	unsigned long size;
+
+	if (__initramfs_size > 0) {
+		initrd_start = (unsigned long)(&__initramfs_start);
+		initrd_end = initrd_start + __initramfs_size;
+	}
+
+	if (initrd_start >= initrd_end) {
+		printk(KERN_INFO "initrd not found or empty");
+		goto disable;
+	}
+	if (__pa(initrd_end) > PFN_PHYS(max_low_pfn)) {
+		printk(KERN_ERR "initrd extends beyond end of memory");
+		goto disable;
+	}
+
+	size =  initrd_end - initrd_start;
+	reserve_bootmem(__pa(initrd_start), size, BOOTMEM_DEFAULT);
+	initrd_below_start_ok = 1;
+
+	printk(KERN_INFO "Initial ramdisk at: 0x%p (%lu bytes)\n",
+		(void *)(initrd_start), size);
+	return;
+disable:
+	printk(KERN_CONT " - disabling initrd\n");
+	initrd_start = 0;
+	initrd_end = 0;
+}
+#endif /* CONFIG_BLK_DEV_INITRD */
+
+static void __init setup_bootmem(void)
+{
+	unsigned long start_pfn, end_pfn;
+	unsigned long mem_size, bootmap_size;
+
+	mem_size = MEMORY_SIZE;
+	printk(KERN_INFO "Detected 0x%lx bytes of physical memory\n", mem_size);
+	end_pfn = PFN_DOWN(min(VMALLOC_START - PAGE_OFFSET, mem_size));
+
+	/* First page after kernel image */
+	start_pfn = PFN_UP(__pa(&_end));
+
+	bootmap_size = init_bootmem(start_pfn, end_pfn);
+	free_bootmem(PFN_PHYS(start_pfn), (end_pfn - start_pfn) << PAGE_SHIFT);
+	reserve_bootmem(PFN_PHYS(start_pfn), bootmap_size, BOOTMEM_DEFAULT);
+
+#ifdef CONFIG_BLK_DEV_INITRD
+	setup_initrd();
+#endif /* CONFIG_BLK_DEV_INITRD */
+}
+
+void __init setup_arch(char **cmdline_p)
+{
+#ifdef CONFIG_CMDLINE_BOOL
+#ifdef CONFIG_CMDLINE_OVERRIDE
+	strlcpy(boot_command_line, builtin_cmdline, COMMAND_LINE_SIZE);
+#else
+	if (builtin_cmdline[0] != '\0') {
+		/* Append bootloader command line to built-in */
+		strlcat(builtin_cmdline, " ", COMMAND_LINE_SIZE);
+		strlcat(builtin_cmdline, boot_command_line, COMMAND_LINE_SIZE);
+		strlcpy(boot_command_line, builtin_cmdline, COMMAND_LINE_SIZE);
+	}
+#endif /* CONFIG_CMDLINE_OVERRIDE */
+#endif /* CONFIG_CMDLINE_BOOL */
+	strlcpy(command_line, boot_command_line, COMMAND_LINE_SIZE);
+	*cmdline_p = command_line;
+
+	init_mm.start_code = (unsigned long) _stext;
+	init_mm.end_code   = (unsigned long) _etext;
+	init_mm.end_data   = (unsigned long) _edata;
+	init_mm.brk        = (unsigned long) _end;
+
+	setup_bootmem();
+	paging_init();
+}
diff --git a/arch/riscv/kernel/signal.c b/arch/riscv/kernel/signal.c
new file mode 100644
index 0000000..f894cb8
--- /dev/null
+++ b/arch/riscv/kernel/signal.c
@@ -0,0 +1,266 @@
+#include <linux/signal.h>
+#include <linux/uaccess.h>
+#include <linux/syscalls.h>
+#include <linux/tracehook.h>
+#include <linux/linkage.h>
+
+#include <asm/ucontext.h>
+#include <asm/vdso.h>
+#include <asm/csr.h>
+
+#define DEBUG_SIG 0
+
+struct rt_sigframe {
+	struct siginfo info;
+	struct ucontext uc;
+};
+
+static int restore_sigcontext(struct pt_regs *regs,
+	struct sigcontext __user *sc)
+{
+	int err = 0;
+	unsigned int i;
+
+	err |= __get_user(regs->epc, &sc->epc);
+	err |= __get_user(regs->ra, &sc->ra);
+	for (i = 0; i < (sizeof(regs->s) / sizeof(unsigned long)); i++) {
+		err |= __get_user(regs->s[i], &sc->s[i]);
+	}
+	err |= __get_user(regs->sp, &sc->sp);
+	err |= __get_user(regs->tp, &sc->tp);
+	for (i = 0; i < (sizeof(regs->v) / sizeof(unsigned long)); i++) {
+		err |= __get_user(regs->v[i], &sc->v[i]);
+	}
+	for (i = 0; i < (sizeof(regs->a) / sizeof(unsigned long)); i++) {
+		err |= __get_user(regs->a[i], &sc->a[i]);
+	}
+	for (i = 0; i < (sizeof(regs->t) / sizeof(unsigned long)); i++) {
+		err |= __get_user(regs->t[i], &sc->t[i]);
+	}
+	err |= __get_user(regs->gp, &sc->gp);
+
+	/* Disable sys_rt_sigreturn() restarting */
+	regs->syscallno = ~0UL;
+	return err;
+}
+
+SYSCALL_DEFINE0(rt_sigreturn)
+{
+	struct pt_regs *regs = current_pt_regs();
+	struct rt_sigframe __user *frame;
+	struct task_struct *task;
+	sigset_t set;
+
+	/* Always make any pending restarted system calls return -EINTR */
+	current_thread_info()->restart_block.fn = do_no_restart_syscall;
+
+	frame = (struct rt_sigframe __user *)regs->sp;
+
+	if (!access_ok(VERIFY_READ, frame, sizeof(*frame)))
+		goto badframe;
+
+	if (__copy_from_user(&set, &frame->uc.uc_sigmask, sizeof(set)))
+		goto badframe;
+
+	set_current_blocked(&set);
+
+	if (restore_sigcontext(regs, &frame->uc.uc_mcontext))
+		goto badframe;
+
+	if (restore_altstack(&frame->uc.uc_stack))
+		goto badframe;
+
+	return regs->v[0];
+
+badframe:
+	task = current;
+	if (show_unhandled_signals) {
+		pr_info_ratelimited("%s[%d]: bad frame in %s: "
+			"frame=%p pc=%p sp=%p\n",
+			task->comm, task_pid_nr(task), __func__,
+			frame, (void *)regs->epc, (void *)regs->sp);
+	}
+	force_sig(SIGSEGV, task);
+	return 0;
+}
+
+static int setup_sigcontext(struct sigcontext __user *sc,
+	struct pt_regs *regs)
+{
+	int err = 0;
+	unsigned int i;
+
+	err |= __put_user(regs->epc, &sc->epc);
+	err |= __put_user(regs->ra, &sc->ra);
+	for (i = 0; i < (sizeof(regs->s) / sizeof(unsigned long)); i++) {
+		err |= __put_user(regs->s[i], &sc->s[i]);
+	}
+	err |= __put_user(regs->sp, &sc->sp);
+	err |= __put_user(regs->tp, &sc->tp);
+	for (i = 0; i < (sizeof(regs->v) / sizeof(unsigned long)); i++) {
+		err |= __put_user(regs->v[i], &sc->v[i]);
+	}
+	for (i = 0; i < (sizeof(regs->a) / sizeof(unsigned long)); i++) {
+		err |= __put_user(regs->a[i], &sc->a[i]);
+	}
+	for (i = 0; i < (sizeof(regs->t) / sizeof(unsigned long)); i++) {
+		err |= __put_user(regs->t[i], &sc->t[i]);
+	}
+	err |= __put_user(regs->gp, &sc->gp);
+
+	return err;
+}
+
+static inline void __user *get_sigframe(struct ksignal *ksig,
+	struct pt_regs *regs, size_t framesize)
+{
+	unsigned long sp;
+	/* Default to using normal stack */
+	sp = regs->sp;
+
+	/*
+	 * If we are on the alternate signal stack and would overflow it, don't.
+	 * Return an always-bogus address instead so we will die with SIGSEGV.
+	 */
+	if (on_sig_stack(sp) && !likely(on_sig_stack(sp - framesize)))
+		return (void __user __force *)(-1UL);
+
+	/* This is the X/Open sanctioned signal stack switching. */
+	sp = sigsp(sp, ksig) - framesize;
+
+	/* Align the stack frame. */
+	sp &= ~0xfUL;
+
+	return (void __user *)sp;
+}
+
+
+static int setup_rt_frame(struct ksignal *ksig, sigset_t *set,
+	struct pt_regs *regs)
+{
+	struct rt_sigframe __user *frame;
+	int err = 0;
+
+	frame = get_sigframe(ksig, regs, sizeof(*frame));
+	if (!access_ok(VERIFY_WRITE, frame, sizeof(*frame)))
+		return -EFAULT;
+
+	err |= copy_siginfo_to_user(&frame->info, &ksig->info);
+
+	/* Create the ucontext. */
+	err |= __put_user(0, &frame->uc.uc_flags);
+	err |= __put_user(NULL, &frame->uc.uc_link);
+	err |= __save_altstack(&frame->uc.uc_stack, regs->sp);
+	err |= setup_sigcontext(&frame->uc.uc_mcontext, regs);
+	err |= __copy_to_user(&frame->uc.uc_sigmask, set, sizeof(*set));
+	if (err)
+		return -EFAULT;
+
+	/* Set up to return from userspace. */
+	regs->ra = (unsigned long)VDSO_SYMBOL(
+		current->mm->context.vdso, rt_sigreturn);
+
+	/*
+	 * Set up registers for signal handler.
+	 * Registers that we don't modify keep the value they had from
+	 * user-space at the time we took the signal.
+	 * We always pass siginfo and mcontext, regardless of SA_SIGINFO,
+	 * since some things rely on this (e.g. glibc's debug/segfault.c).
+	 */
+	regs->epc = (unsigned long)ksig->ka.sa.sa_handler;
+	regs->sp = (unsigned long)frame;
+	regs->a[0] = ksig->sig;                     /* a0: signal number */
+	regs->a[1] = (unsigned long)(&frame->info); /* a1: siginfo pointer */
+	regs->a[2] = (unsigned long)(&frame->uc);   /* a2: ucontext pointer */
+
+#if DEBUG_SIG
+	pr_info("SIG deliver (%s:%d): sig=%d pc=%p ra=%p sp=%p\n",
+		current->comm, task_pid_nr(current), ksig->sig,
+		(void *)regs->epc, (void *)regs->ra, frame);
+#endif
+
+	return 0;
+}
+
+static void handle_signal(struct ksignal *ksig, struct pt_regs *regs)
+{
+	sigset_t *oldset = sigmask_to_save();
+	int ret;
+
+	/* Are we from a system call? */
+	if (regs->cause == EXC_SYSCALL) {
+		/* If so, check system call restarting.. */
+		switch (regs->v[0]) {
+		case -ERESTART_RESTARTBLOCK:
+		case -ERESTARTNOHAND:
+			regs->v[0] = -EINTR;
+			break;
+
+		case -ERESTARTSYS:
+			if (!(ksig->ka.sa.sa_flags & SA_RESTART)) {
+				regs->v[0] = -EINTR;
+				break;
+			}
+			/* fallthrough */
+		case -ERESTARTNOINTR:
+			regs->v[0] = regs->syscallno;
+			regs->epc -= 0x4;
+			break;
+		}
+	}
+
+	/* Set up the stack frame */
+	ret = setup_rt_frame(ksig, oldset, regs);
+
+	signal_setup_done(ret, ksig, 0);
+}
+
+static void do_signal(struct pt_regs *regs)
+{
+	struct ksignal ksig;
+
+	if (get_signal(&ksig)) {
+		/* Actually deliver the signal */
+		handle_signal(&ksig, regs);
+		return;
+	}
+
+	/* Did we come from a system call? */
+	if (regs->cause == EXC_SYSCALL) {
+		/* Restart the system call - no handlers present */
+		switch (regs->v[0]) {
+		case -ERESTARTNOHAND:
+		case -ERESTARTSYS:
+		case -ERESTARTNOINTR:
+			regs->v[0] = regs->syscallno;
+			regs->epc -= 0x4;
+			break;
+		case -ERESTART_RESTARTBLOCK:
+			regs->v[0] = __NR_restart_syscall;
+			regs->epc -= 0x4;
+			break;
+		}
+	}
+
+	/* If there is no signal to deliver, we just put the saved
+	   sigmask back. */
+	restore_saved_sigmask();
+}
+
+/*
+ * notification of userspace execution resumption
+ * - triggered by the _TIF_WORK_MASK flags
+ */
+asmlinkage void do_notify_resume(struct pt_regs *regs,
+	unsigned long thread_info_flags)
+{
+	/* Handle pending signal delivery */
+	if (thread_info_flags & _TIF_SIGPENDING) {
+		do_signal(regs);
+	}
+
+	if (thread_info_flags & _TIF_NOTIFY_RESUME) {
+		clear_thread_flag(TIF_NOTIFY_RESUME);
+		tracehook_notify_resume(regs);
+	}
+}
diff --git a/arch/riscv/kernel/stacktrace.c b/arch/riscv/kernel/stacktrace.c
new file mode 100644
index 0000000..4652c95
--- /dev/null
+++ b/arch/riscv/kernel/stacktrace.c
@@ -0,0 +1,163 @@
+#include <linux/export.h>
+#include <linux/kallsyms.h>
+#include <linux/sched.h>
+#include <linux/stacktrace.h>
+
+#ifdef CONFIG_FRAME_POINTER
+
+struct stackframe {
+	unsigned long fp;
+	unsigned long ra;
+};
+
+static void notrace walk_stackframe(struct task_struct *task,
+	struct pt_regs *regs, bool (*fn)(unsigned long, void *), void *arg)
+{
+	unsigned long fp, sp, pc;
+
+	if (regs) {
+		fp = GET_FP(regs);
+		sp = GET_USP(regs);
+		pc = GET_IP(regs);
+	} else if (task == NULL || task == current) {
+		const register unsigned long current_sp __asm__ ("sp");
+		fp = (unsigned long)__builtin_frame_address(0);
+		sp = current_sp;
+		pc = (unsigned long)walk_stackframe;
+	} else {
+		/* task blocked in __switch_to */
+		fp = task->thread.s[0];
+		sp = task->thread.sp;
+		pc = task->thread.ra;
+	}
+
+	for (;;) {
+		unsigned long low, high;
+		struct stackframe *frame;
+
+		if (unlikely(!__kernel_text_address(pc) || fn(pc, arg)))
+			break;
+
+		/* Validate frame pointer */
+		low = sp + sizeof(struct stackframe);
+		high = ALIGN(sp, THREAD_SIZE);
+		if (unlikely(fp < low || fp > high || fp & 0x7))
+			break;
+		/* Unwind stack frame */
+		frame = (struct stackframe *)fp - 1;
+		sp = fp;
+		fp = frame->fp;
+		pc = frame->ra - 0x4;
+	}
+}
+
+#else /* !CONFIG_FRAME_POINTER */
+
+static void notrace walk_stackframe(struct task_struct *task,
+	struct pt_regs *regs, bool (*fn)(unsigned long, void *), void *arg)
+{
+	unsigned long sp, pc;
+	unsigned long *ksp;
+
+	if (regs) {
+		sp = GET_USP(regs);
+		pc = GET_IP(regs);
+	} else if (task == NULL || task == current) {
+		const register unsigned long current_sp __asm__ ("sp");
+		sp = current_sp;
+		pc = (unsigned long)walk_stackframe;
+	} else {
+		/* task blocked in __switch_to */
+		sp = task->thread.sp;
+		pc = task->thread.ra;
+	}
+
+	if (unlikely(sp & 0x7))
+		return;
+
+	ksp = (unsigned long *)sp;
+	while (!kstack_end(ksp)) {
+		if (__kernel_text_address(pc) && unlikely(fn(pc, arg))) {
+			break;
+		}
+		pc = (*ksp++) - 0x4;
+	}
+}
+
+#endif /* CONFIG_FRAME_POINTER */
+
+
+static bool print_trace_address(unsigned long pc, void *arg)
+{
+	print_ip_sym(pc);
+	return false;
+}
+
+void show_stack(struct task_struct *task, unsigned long *sp)
+{
+	printk("Call Trace:\n");
+	walk_stackframe(task, NULL, print_trace_address, NULL);
+}
+
+
+static bool save_wchan(unsigned long pc, void *arg)
+{
+	if (!in_sched_functions(pc)) {
+		unsigned long *p = arg;
+		*p = pc;
+		return true;
+	}
+	return false;
+}
+
+unsigned long get_wchan(struct task_struct *task)
+{
+	unsigned long pc;
+	pc = 0;
+	if (likely(task && task != current && task->state != TASK_RUNNING)) {
+		walk_stackframe(task, NULL, save_wchan, &pc);
+	}
+	return pc;
+}
+
+
+#ifdef CONFIG_STACKTRACE
+
+static bool __save_trace(unsigned long pc, void *arg, bool nosched)
+{
+	struct stack_trace *trace = arg;
+
+	if (unlikely(nosched && in_sched_functions(pc)))
+		return false;
+	if (unlikely(trace->skip > 0)) {
+		trace->skip--;
+		return false;
+	}
+
+	trace->entries[trace->nr_entries++] = pc;
+	return (trace->nr_entries >= trace->max_entries);
+}
+
+static bool save_trace(unsigned long pc, void *arg)
+{
+	return __save_trace(pc, arg, false);
+}
+
+/*
+ * Save stack-backtrace addresses into a stack_trace buffer.
+ */
+void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
+{
+	walk_stackframe(tsk, NULL, save_trace, trace);
+	if (trace->nr_entries < trace->max_entries)
+		trace->entries[trace->nr_entries++] = ULONG_MAX;
+}
+EXPORT_SYMBOL_GPL(save_stack_trace_tsk);
+
+void save_stack_trace(struct stack_trace *trace)
+{
+	save_stack_trace_tsk(NULL, trace);
+}
+EXPORT_SYMBOL_GPL(save_stack_trace);
+
+#endif /* CONFIG_STACKTRACE */
diff --git a/arch/riscv/kernel/sys_riscv.c b/arch/riscv/kernel/sys_riscv.c
new file mode 100644
index 0000000..000d034
--- /dev/null
+++ b/arch/riscv/kernel/sys_riscv.c
@@ -0,0 +1,56 @@
+#include <linux/syscalls.h>
+#include <asm/unistd.h>
+
+SYSCALL_DEFINE6(mmap, unsigned long, addr, unsigned long, len,
+	unsigned long, prot, unsigned long, flags,
+	unsigned long, fd, off_t, offset)
+{
+	if (unlikely(offset & (~PAGE_MASK)))
+		return -EINVAL;
+	return sys_mmap_pgoff(addr, len, prot, flags, fd, offset >> PAGE_SHIFT);
+}
+
+#ifdef CONFIG_RV_SYSRISCV_ATOMIC
+SYSCALL_DEFINE4(sysriscv, unsigned long, cmd, unsigned long, arg1,
+	unsigned long, arg2, unsigned long, arg3)
+{
+	unsigned long flags;
+	unsigned long prev;
+	unsigned int *ptr;
+	unsigned int err;
+
+	switch (cmd) {
+	case RISCV_ATOMIC_CMPXCHG:
+		ptr = (unsigned int *)arg1;
+		if (!access_ok(VERIFY_WRITE, ptr, sizeof(unsigned int)))
+			return -EFAULT;
+
+		preempt_disable();
+		raw_local_irq_save(flags);
+		err = __get_user(prev, ptr);
+		if (likely(!err && prev == arg2))
+			err = __put_user(arg3, ptr);
+		raw_local_irq_restore(flags);
+		preempt_enable();
+
+		return unlikely(err) ? err : prev;
+
+	case RISCV_ATOMIC_CMPXCHG64:
+		ptr = (unsigned int *)arg1;
+		if (!access_ok(VERIFY_WRITE, ptr, sizeof(unsigned long)))
+			return -EFAULT;
+
+		preempt_disable();
+		raw_local_irq_save(flags);
+		err = __get_user(prev, ptr);
+		if (likely(!err && prev == arg2))
+			err = __put_user(arg3, ptr);
+		raw_local_irq_restore(flags);
+		preempt_enable();
+
+		return unlikely(err) ? err : prev;
+	}
+
+	return -EINVAL;
+}
+#endif /* CONFIG_RV_SYSRISCV_ATOMIC */
diff --git a/arch/riscv/kernel/syscall_table.c b/arch/riscv/kernel/syscall_table.c
new file mode 100644
index 0000000..badab2e
--- /dev/null
+++ b/arch/riscv/kernel/syscall_table.c
@@ -0,0 +1,10 @@
+#include <linux/syscalls.h>
+
+#include <asm/syscalls.h>
+
+#undef __SYSCALL
+#define __SYSCALL(nr, call) [nr] = (call),
+
+void *sys_call_table[__NR_syscalls] = {
+#include <asm/unistd.h>
+};
diff --git a/arch/riscv/kernel/time.c b/arch/riscv/kernel/time.c
new file mode 100644
index 0000000..808d4f4
--- /dev/null
+++ b/arch/riscv/kernel/time.c
@@ -0,0 +1,87 @@
+#include <linux/clocksource.h>
+#include <linux/clockchips.h>
+#include <linux/interrupt.h>
+#include <linux/irq.h>
+
+#include <asm/irq.h>
+#include <asm/csr.h>
+
+static int riscv_timer_set_next_event(unsigned long delta,
+	struct clock_event_device *evdev)
+{
+	/* Set comparator */
+	csr_write(compare, csr_read(count) + delta);
+	return 0;
+}
+
+static void riscv_timer_set_mode(enum clock_event_mode mode,
+	struct clock_event_device *evdev)
+{
+	switch (mode) {
+	case CLOCK_EVT_MODE_ONESHOT:
+	case CLOCK_EVT_MODE_UNUSED:
+	case CLOCK_EVT_MODE_SHUTDOWN:
+	case CLOCK_EVT_MODE_RESUME:
+		break;
+	case CLOCK_EVT_MODE_PERIODIC:
+	default:
+		BUG();
+	}
+}
+
+static struct clock_event_device riscv_clockevent = {
+	.name = "riscv_timer_clockevent",
+	.features = CLOCK_EVT_FEAT_ONESHOT,
+	.rating = 300,
+	.set_next_event = riscv_timer_set_next_event,
+	.set_mode = riscv_timer_set_mode,
+};
+
+static irqreturn_t timer_interrupt(int irq, void *dev_id)
+{
+	struct clock_event_device *evdev;
+
+	evdev = dev_id;
+	evdev->event_handler(evdev);
+	return IRQ_HANDLED;
+}
+
+static struct irqaction timer_irq = {
+	.handler = timer_interrupt,
+	.flags = IRQF_DISABLED | IRQF_TIMER,
+	.name = "timer",
+	.dev_id = &riscv_clockevent,
+};
+
+
+static cycle_t riscv_rdcycle(struct clocksource *cs)
+{
+	return csr_read(cycle);
+}
+
+static struct clocksource riscv_clocksource = {
+	.name = "riscv_clocksource",
+	.rating = 300,
+	.read = riscv_rdcycle,
+#ifdef CONFIG_64BITS
+	.mask = CLOCKSOURCE_MASK(64),
+#else
+	.mask = CLOCKSOURCE_MASK(32),
+#endif /* CONFIG_64BITS */
+	.flags = CLOCK_SOURCE_IS_CONTINUOUS,
+};
+
+
+void __init time_init(void)
+{
+	u32 freq;
+	freq = 100000000UL;
+
+	csr_write(count, 0);
+
+	clocksource_register_hz(&riscv_clocksource, freq);
+	setup_irq(IRQ_TIMER, &timer_irq);
+	riscv_clockevent.cpumask = cpumask_of(0);
+	clockevents_config_and_register(&riscv_clockevent,
+		freq, 100, 0xffffffff);
+}
diff --git a/arch/riscv/kernel/traps.c b/arch/riscv/kernel/traps.c
new file mode 100644
index 0000000..feaa97f
--- /dev/null
+++ b/arch/riscv/kernel/traps.c
@@ -0,0 +1,127 @@
+#include <linux/kernel.h>
+#include <linux/export.h>
+#include <linux/syscalls.h>
+#include <linux/kdebug.h>
+#include <linux/init.h>
+
+#include <asm/processor.h>
+#include <asm/ptrace.h>
+#include <asm/csr.h>
+
+extern asmlinkage void handle_exception(void);
+
+void die(const char *str, struct pt_regs *regs, long err)
+{
+	int ret;
+
+	oops_enter();
+	console_verbose();
+	ret = notify_die(DIE_OOPS, str, regs, err, 0, SIGSEGV);
+	oops_exit();
+
+	if (in_interrupt())
+		panic("Fatal exception in interrupt");
+	if (panic_on_oops)
+		panic("Fatal exception");
+	if (ret != NOTIFY_STOP)
+		do_exit(SIGSEGV);
+}
+
+
+asmlinkage void handle_fault_unknown(struct pt_regs *regs)
+{
+	siginfo_t info;
+
+	if (user_mode(regs)) {
+		/* Send a SIGILL */
+		info.si_signo = SIGILL;
+		info.si_errno = 0;
+		info.si_code = ILL_ILLTRP;
+		info.si_addr = (void *)(regs->epc);
+		force_sig_info(SIGILL, &info, current);
+	} else { /* Kernel mode */
+		panic("unknown exception %ld: epc=0x%016lx badvaddr=0x%016lx",
+			regs->cause, regs->epc, regs->badvaddr);
+	}
+}
+
+static void __handle_misaligned_addr(struct pt_regs *regs,
+	unsigned long addr)
+{
+	siginfo_t info;
+
+	if (user_mode(regs)) {
+		/* Send a SIGBUS */
+		info.si_signo = SIGBUS;
+		info.si_errno = 0;
+		info.si_code = BUS_ADRALN;
+		info.si_addr = (void *)addr;
+		force_sig_info(SIGBUS, &info, current);
+	} else { /* Kernel mode */
+		die("SIGBUS", regs, 0);
+	}
+}
+
+asmlinkage void handle_misaligned_insn(struct pt_regs *regs)
+{
+	__handle_misaligned_addr(regs, regs->epc);
+}
+
+asmlinkage void handle_misaligned_data(struct pt_regs *regs)
+{
+	__handle_misaligned_addr(regs, regs->badvaddr);
+}
+
+asmlinkage void handle_break(struct pt_regs *regs)
+{
+	siginfo_t info;
+
+	info.si_signo = SIGTRAP;
+	info.si_errno = 0;
+	info.si_code = TRAP_BRKPT;
+	info.si_addr = (void *)(regs->epc);
+	force_sig_info(SIGTRAP, &info, current);
+
+	regs->epc += 0x4;
+}
+
+asmlinkage void handle_privileged_insn(struct pt_regs *regs)
+{
+	siginfo_t info;
+
+	if (user_mode(regs)) {
+		/* Send a SIGILL */
+		info.si_signo = SIGILL;
+		info.si_errno = 0;
+		info.si_code = ILL_PRVOPC;
+		info.si_addr = (void *)(regs->epc);
+		force_sig_info(SIGILL, &info, current);
+	} else { /* Kernel mode */
+		die("SIGILL", regs, 0);
+	}
+
+}
+
+asmlinkage void handle_illegal_insn(struct pt_regs *regs)
+{
+	siginfo_t info;
+
+	if (user_mode(regs)) {
+		/* Send a SIGILL */
+		info.si_signo = SIGILL;
+		info.si_errno = 0;
+		info.si_code = ILL_ILLOPC;
+		info.si_addr = (void *)(regs->epc);
+		force_sig_info(SIGILL, &info, current);
+	} else { /* Kernel mode */
+		die("SIGILL", regs, 0);
+	}
+}
+
+void __init trap_init(void)
+{
+	/* Clear the IPI exception that started the processor */
+	csr_write(clear_ipi, 0);
+	/* Set the exception vector address */
+	csr_write(evec, &handle_exception);
+}
diff --git a/arch/riscv/kernel/vdso.c b/arch/riscv/kernel/vdso.c
new file mode 100644
index 0000000..015af7d
--- /dev/null
+++ b/arch/riscv/kernel/vdso.c
@@ -0,0 +1,106 @@
+#include <linux/mm.h>
+#include <linux/slab.h>
+#include <linux/binfmts.h>
+#include <linux/err.h>
+
+#include <asm/vdso.h>
+
+extern char vdso_start[], vdso_end[];
+
+static unsigned int vdso_pages;
+static struct page **vdso_pagelist;
+
+/*
+ * The vDSO data page.
+ */
+static union {
+	struct vdso_data	data;
+	u8			page[PAGE_SIZE];
+} vdso_data_store __page_aligned_data;
+struct vdso_data *vdso_data = &vdso_data_store.data;
+
+static int __init vdso_init(void)
+{
+	unsigned int i;
+
+	vdso_pages = (vdso_end - vdso_start) >> PAGE_SHIFT;
+	vdso_pagelist = kzalloc(sizeof(struct page *) * (vdso_pages + 1), GFP_KERNEL);
+	if (unlikely(vdso_pagelist == NULL)) {
+		pr_err("vdso: pagelist allocation failed\n");
+		return -ENOMEM;
+	}
+
+	for (i = 0; i < vdso_pages; i++) {
+		struct page *pg;
+		pg = virt_to_page(vdso_start + (i << PAGE_SHIFT));
+		ClearPageReserved(pg);
+		vdso_pagelist[i] = pg;
+	}
+	vdso_pagelist[i] = virt_to_page(vdso_data);
+
+	return 0;
+}
+arch_initcall(vdso_init);
+
+int arch_setup_additional_pages(struct linux_binprm *bprm,
+	int uses_interp)
+{
+	struct mm_struct *mm = current->mm;
+	unsigned long vdso_base, vdso_len;
+	int ret;
+
+	vdso_len = (vdso_pages + 1) << PAGE_SHIFT;
+
+	down_write(&mm->mmap_sem);
+	vdso_base = get_unmapped_area(NULL, 0, vdso_len, 0, 0);
+	if (unlikely(IS_ERR_VALUE(vdso_base))) {
+		ret = vdso_base;
+		goto end;
+	}
+
+	/*
+	 * Put vDSO base into mm struct. We need to do this before calling
+	 * install_special_mapping or the perf counter mmap tracking code
+	 * will fail to recognise it as a vDSO (since arch_vma_name fails).
+	 */
+	mm->context.vdso = (void *)vdso_base;
+
+	ret = install_special_mapping(mm, vdso_base, vdso_len,
+		(VM_READ | VM_EXEC | VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC),
+		vdso_pagelist);
+
+	if (unlikely(ret)) {
+		mm->context.vdso = NULL;
+	}
+
+end:
+	up_write(&mm->mmap_sem);
+	return ret;
+}
+
+const char *arch_vma_name(struct vm_area_struct *vma)
+{
+	if (vma->vm_mm && (vma->vm_start == (long)vma->vm_mm->context.vdso)) {
+		return "[vdso]";
+	}
+	return NULL;
+}
+
+/*
+ * Function stubs to prevent linker errors when AT_SYSINFO_EHDR is defined
+ */
+
+int in_gate_area_no_mm(unsigned long addr)
+{
+	return 0;
+}
+
+int in_gate_area(struct mm_struct *mm, unsigned long addr)
+{
+	return 0;
+}
+
+struct vm_area_struct *get_gate_vma(struct mm_struct *mm)
+{
+	return NULL;
+}
diff --git a/arch/riscv/kernel/vdso/Makefile b/arch/riscv/kernel/vdso/Makefile
new file mode 100644
index 0000000..05f7ae0
--- /dev/null
+++ b/arch/riscv/kernel/vdso/Makefile
@@ -0,0 +1,61 @@
+# Derived from arch/{arm64,tile}/kernel/vdso/Makefile
+
+obj-vdso := sigreturn.o
+
+# Build rules
+targets := $(obj-vdso) vdso.so vdso.so.dbg
+obj-vdso := $(addprefix $(obj)/, $(obj-vdso))
+
+#ccflags-y := -shared -fno-common -fno-builtin
+#ccflags-y += -nostdlib -Wl,-soname=linux-vdso.so.1 \
+		$(call cc-ldoption, -Wl$(comma)--hash-style=sysv)
+
+CFLAGS_vdso.so = $(c_flags)
+CFLAGS_vdso.so.dbg = -shared -s -Wl,-soname=linux-vdso.so.1 \
+	$(call cc-ldoption, -Wl$(comma)--hash-style=sysv)
+CFLAGS_vdso_syms.o = -r
+
+obj-y += vdso.o
+
+# We also create a special relocatable object that should mirror the symbol
+# table and layout of the linked DSO.  With ld -R we can then refer to
+# these symbols in the kernel code rather than hand-coded addresses.
+extra-y += vdso.lds vdso-syms.o
+$(obj)/built-in.o: $(obj)/vdso-syms.o
+$(obj)/built-in.o: ld_flags += -R $(obj)/vdso-syms.o
+
+CPPFLAGS_vdso.lds += -P -C -U$(ARCH)
+
+# Force dependency
+$(obj)/vdso.o : $(obj)/vdso.so
+
+# Link rule for the *.so file; *.lds must be first
+$(obj)/vdso.so.dbg: $(src)/vdso.lds $(obj-vdso)
+	$(call if_changed,vdsold)
+$(obj)/vdso-syms.o: $(src)/vdso.lds $(obj-vdso)
+	$(call if_changed,vdsold)
+
+# Strip rule for the *.so file
+$(obj)/%.so: OBJCOPYFLAGS := -S
+$(obj)/%.so: $(obj)/%.so.dbg FORCE
+	$(call if_changed,objcopy)
+
+# Assembly rules for the *.S files
+$(obj-vdso): %.o: %.S
+	$(call if_changed_dep,vdsoas)
+
+# Actual build commands
+quiet_cmd_vdsold = VDSOLD  $@
+      cmd_vdsold = $(CC) -nostdlib $(CFLAGS_$(@F)) -Wl,-n -Wl,-T $^ -o $@
+quiet_cmd_vdsoas = VDSOAS  $@
+      cmd_vdsoas = $(CC) $(a_flags) -c -o $@ $<
+
+# Install commands for the unstripped file
+quiet_cmd_vdso_install = INSTALL $@
+      cmd_vdso_install = cp $(obj)/$@.dbg $(MODLIB)/vdso/$@
+
+vdso.so: $(obj)/vdso.so.dbg
+	@mkdir -p $(MODLIB)/vdso
+	$(call cmd,vdso_install)
+
+vdso_install: vdso.so
diff --git a/arch/riscv/kernel/vdso/sigreturn.S b/arch/riscv/kernel/vdso/sigreturn.S
new file mode 100644
index 0000000..c61e511
--- /dev/null
+++ b/arch/riscv/kernel/vdso/sigreturn.S
@@ -0,0 +1,11 @@
+#include <linux/linkage.h>
+#include <asm/unistd.h>
+
+	.text
+ENTRY(__vdso_rt_sigreturn)
+	.cfi_startproc
+	.cfi_signal_frame
+	li v0, __NR_rt_sigreturn
+	scall
+	.cfi_endproc
+ENDPROC(__vdso_rt_sigreturn)
diff --git a/arch/riscv/kernel/vdso/vdso.S b/arch/riscv/kernel/vdso/vdso.S
new file mode 100644
index 0000000..2ee47c2
--- /dev/null
+++ b/arch/riscv/kernel/vdso/vdso.S
@@ -0,0 +1,14 @@
+#include <linux/init.h>
+#include <linux/linkage.h>
+#include <asm/page.h>
+
+	__PAGE_ALIGNED_DATA
+
+	.globl vdso_start, vdso_end
+	.balign PAGE_SIZE
+vdso_start:
+	.incbin "arch/riscv/kernel/vdso/vdso.so"
+	.balign PAGE_SIZE
+vdso_end:
+
+	.previous
diff --git a/arch/riscv/kernel/vdso/vdso.lds.S b/arch/riscv/kernel/vdso/vdso.lds.S
new file mode 100644
index 0000000..dd82fbf
--- /dev/null
+++ b/arch/riscv/kernel/vdso/vdso.lds.S
@@ -0,0 +1,63 @@
+OUTPUT_ARCH(riscv)
+
+SECTIONS
+{
+	. = SIZEOF_HEADERS;
+
+	.hash		: { *(.hash) }			:text
+	.gnu.hash	: { *(.gnu.hash) }
+	.dynsym		: { *(.dynsym) }
+	.dynstr		: { *(.dynstr) }
+	.gnu.version	: { *(.gnu.version) }
+	.gnu.version_d	: { *(.gnu.version_d) }
+	.gnu.version_r	: { *(.gnu.version_r) }
+
+	.note		: { *(.note.*) }		:text	:note
+	.dynamic	: { *(.dynamic) }		:text	:dynamic
+
+	.eh_frame_hdr	: { *(.eh_frame_hdr) }		:text	:eh_frame_hdr
+	.eh_frame	: { KEEP (*(.eh_frame)) }	:text
+
+	.rodata		: { *(.rodata .rodata.* .gnu.linkonce.r.*) }
+
+	/*
+	 * This linker script is used both with -r and with -shared.
+	 * For the layouts to match, we need to skip more than enough
+	 * space for the dynamic symbol table, etc. If this amount is
+	 * insufficient, ld -shared will error; simply increase it here.
+	 */
+	. = 0x800;
+	.text		: { *(.text .text.*) }		:text
+
+	.data		: {
+		*(.got.plt) *(.got)
+		*(.data .data.* .gnu.linkonce.d.*)
+		*(.dynbss)
+		*(.bss .bss.* .gnu.linkonce.b.*)
+	}
+}
+
+/*
+ * We must supply the ELF program headers explicitly to get just one
+ * PT_LOAD segment, and set the flags explicitly to make segments read-only.
+ */
+PHDRS
+{
+	text		PT_LOAD		FLAGS(5) FILEHDR PHDRS; /* PF_R|PF_X */
+	dynamic		PT_DYNAMIC	FLAGS(4);		/* PF_R */
+	note		PT_NOTE		FLAGS(4);		/* PF_R */
+	eh_frame_hdr	PT_GNU_EH_FRAME;
+}
+
+/*
+ * This controls what symbols we export from the DSO.
+ */
+VERSION
+{
+	LINUX_2.6 {
+	global:
+		__vdso_rt_sigreturn;
+	local: *;
+	};
+}
+
diff --git a/arch/riscv/kernel/vmlinux.lds.S b/arch/riscv/kernel/vmlinux.lds.S
new file mode 100644
index 0000000..df20b9e
--- /dev/null
+++ b/arch/riscv/kernel/vmlinux.lds.S
@@ -0,0 +1,64 @@
+#define LOAD_OFFSET PAGE_OFFSET
+#include <asm/vmlinux.lds.h>
+#include <asm/page.h>
+#include <asm/thread_info.h>
+
+OUTPUT_ARCH(riscv)
+ENTRY(_start)
+
+jiffies = jiffies_64;
+
+SECTIONS
+{
+	/* Beginning of code and text segment */
+	. = LOAD_OFFSET + 0x2000;
+	_start = 0x2000;
+	__init_begin = .;
+	HEAD_TEXT_SECTION
+	INIT_TEXT_SECTION(PAGE_SIZE)
+	INIT_DATA_SECTION(16)
+	__init_end = .;
+
+	.text : AT(ADDR(.text) - LOAD_OFFSET) {
+		_text = .;
+		_stext = .;
+		TEXT_TEXT
+		SCHED_TEXT
+		LOCK_TEXT
+		KPROBES_TEXT
+		ENTRY_TEXT
+		IRQENTRY_TEXT
+		*(.fixup)
+		_etext = .;
+	}
+
+	/* Start of data section */
+	_sdata = .;
+	RO_DATA_SECTION(PAGE_SIZE)
+	RW_DATA_SECTION(0x40, PAGE_SIZE, THREAD_SIZE)
+	.sdata : {
+		_gp = . + 0x800;
+		*(.sdata*)
+	}
+	.srodata : {
+		*(.srodata*)
+	}
+	/* End of data section */
+	_edata = .;
+
+	BSS_SECTION(0x20, 0, 0x20)
+
+	EXCEPTION_TABLE(0x10)
+	NOTES
+
+	.rel.dyn : {
+		*(.rel.dyn*)
+	}
+
+	_end = .;
+
+	STABS_DEBUG
+	DWARF_DEBUG
+
+	DISCARDS
+}
diff --git a/arch/riscv/lib/Makefile b/arch/riscv/lib/Makefile
new file mode 100644
index 0000000..a5014d3
--- /dev/null
+++ b/arch/riscv/lib/Makefile
@@ -0,0 +1 @@
+lib-y	:= delay.o memcpy.o memset.o uaccess.o
diff --git a/arch/riscv/lib/delay.c b/arch/riscv/lib/delay.c
new file mode 100644
index 0000000..a4ac09c
--- /dev/null
+++ b/arch/riscv/lib/delay.c
@@ -0,0 +1,21 @@
+#include <linux/delay.h>
+
+#include <asm/timex.h>
+
+#define LOOPS_PER_JIFFY 1337
+
+inline void __const_udelay(unsigned long xloops)
+{
+	unsigned long loops;
+	loops = xloops * LOOPS_PER_JIFFY * CONFIG_HZ;
+	__delay(loops >> 32);
+}
+
+inline void __delay(unsigned long loops)
+{
+	cycles_t start, now;
+	start = get_cycles();
+	do {
+		now = get_cycles();
+	} while ((now - start) < loops);
+}
diff --git a/arch/riscv/lib/memcpy.S b/arch/riscv/lib/memcpy.S
new file mode 100644
index 0000000..86783b1
--- /dev/null
+++ b/arch/riscv/lib/memcpy.S
@@ -0,0 +1,92 @@
+#include <linux/linkage.h>
+
+/* void *memcpy(void *, const void *, size_t) */
+
+#ifdef CONFIG_64BIT
+
+ENTRY(memcpy)
+	move v0, a0  /* Initialize return value */
+
+	/* Defer to byte-oriented copy for small sizes */
+	sltiu a3, a2, 128
+	bnez a3, 4f
+	/* Use word-oriented copy only if low-order bits match */
+	andi a3, a0, 0x7
+	andi a4, a1, 0x7
+	bne a3, a4, 4f
+
+	beqz a3, 2f  /* Skip if already aligned */
+	/* Round to nearest double word-aligned address
+	   greater than or equal to start address */
+	andi a3, a1, ~(0x7)
+	addi a3, a3, 0x8
+	/* Handle initial misalignment */
+	sub a4, a3, a1
+1:
+	lb a5, 0(a1)
+	addi a1, a1, 1
+	sb a5, 0(a0)
+	addi a0, a0, 1
+	bltu a1, a3, 1b
+	sub a2, a2, a4  /* Update count */
+
+2:
+	andi a4, a2, ~(0x7f)
+	beqz a4, 4f
+	add a3, a1, a4
+3:
+	ld a4, 0x00(a1)
+	ld a5, 0x08(a1)
+	ld a6, 0x10(a1)
+	ld a7, 0x18(a1)
+	ld t0, 0x20(a1)
+	ld t1, 0x28(a1)
+	ld t2, 0x30(a1)
+	ld t3, 0x38(a1)
+	ld t4, 0x40(a1)
+	ld v1, 0x48(a1)
+	sd a4, 0x00(a0)
+	sd a5, 0x08(a0)
+	sd a6, 0x10(a0)
+	sd a7, 0x18(a0)
+	sd t0, 0x20(a0)
+	sd t1, 0x28(a0)
+	sd t2, 0x30(a0)
+	sd t3, 0x38(a0)
+	sd t4, 0x40(a0)
+	sd v1, 0x48(a0)
+	ld a4, 0x50(a1)
+	ld a5, 0x58(a1)
+	ld a6, 0x60(a1)
+	ld a7, 0x68(a1)
+	ld t0, 0x70(a1)
+	ld t1, 0x78(a1)
+	addi a1, a1, 0x80
+	sd a4, 0x50(a0)
+	sd a5, 0x58(a0)
+	sd a6, 0x60(a0)
+	sd a7, 0x68(a0)
+	sd t0, 0x70(a0)
+	sd t1, 0x78(a0)
+	addi a0, a0, 0x80
+	bltu a1, a3, 3b
+	andi a2, a2, 0x7f  /* Update count */
+
+4:
+	/* Handle trailing misalignment */
+	beqz a2, 6f
+	add a3, a1, a2
+5:
+	lb a4, 0(a1)
+	addi a1, a1, 1
+	sb a4, 0(a0)
+	addi a0, a0, 1
+	bltu a1, a3, 5b
+6:
+	ret
+END(memcpy)
+
+#else
+#error RV32 memcpy unimplemented
+#endif /* CONFIG_64BIT */
+
diff --git a/arch/riscv/lib/memset.S b/arch/riscv/lib/memset.S
new file mode 100644
index 0000000..2d8cc50
--- /dev/null
+++ b/arch/riscv/lib/memset.S
@@ -0,0 +1,107 @@
+#include <linux/linkage.h>
+
+/* void *memset(void *, int, size_t) */
+
+#ifdef CONFIG_64BIT
+
+ENTRY(memset)
+	move v0, a0  /* Initialize return value */
+
+	/* Defer to byte-oriented fill for small sizes */
+	sltiu a3, a2, 16
+	bnez a3, 4f
+
+	/* Round to nearest double word-aligned address
+	   greater than or equal to start address */
+	addi a3, a0, 0x7
+	andi a3, a3, ~(0x7)
+	beq a3, a0, 2f  /* Skip if already aligned */
+	/* Handle initial misalignment */
+	sub a4, a3, a0
+1:
+	sb a1, 0(a0)
+	addi a0, a0, 1
+	bltu a0, a3, 1b
+	sub a2, a2, a4  /* Update count */
+
+2: /* Duff's device with 32 double-word stores per iteration */
+	/* Broadcast value into all 8 bytes */
+	andi a1, a1, 0xff
+	slli a3, a1, 8
+	or a1, a3, a1
+	slli a3, a1, 16
+	or a1, a3, a1
+	slli a3, a1, 32
+	or a1, a3, a1
+
+	/* Calculate end address */
+	andi a4, a2, ~(0x7)
+	add a3, a0, a4
+
+	andi a4, a4, 0xf8   /* Calculate remainder */
+	beqz a4, 3f         /* Shortcut if no remainder */
+	sub a4, zero, a4
+	addi a4, a4, 0x100  /* Calculate initial offset */
+
+	/* Adjust start address with offset */
+	sub a0, a0, a4
+
+	/* Jump into loop body */
+	/* Assumes 32-bit instruction lengths */
+	la a5, 3f
+	srli a4, a4, 1
+	add a5, a5, a4
+	jr a5
+3:
+	sd a1, 0x00(a0)
+	sd a1, 0x08(a0)
+	sd a1, 0x10(a0)
+	sd a1, 0x18(a0)
+	sd a1, 0x20(a0)
+	sd a1, 0x28(a0)
+	sd a1, 0x30(a0)
+	sd a1, 0x38(a0)
+	sd a1, 0x40(a0)
+	sd a1, 0x48(a0)
+	sd a1, 0x50(a0)
+	sd a1, 0x58(a0)
+	sd a1, 0x60(a0)
+	sd a1, 0x68(a0)
+	sd a1, 0x70(a0)
+	sd a1, 0x78(a0)
+	sd a1, 0x80(a0)
+	sd a1, 0x88(a0)
+	sd a1, 0x90(a0)
+	sd a1, 0x98(a0)
+	sd a1, 0xa0(a0)
+	sd a1, 0xa8(a0)
+	sd a1, 0xb0(a0)
+	sd a1, 0xb8(a0)
+	sd a1, 0xc0(a0)
+	sd a1, 0xc8(a0)
+	sd a1, 0xd0(a0)
+	sd a1, 0xd8(a0)
+	sd a1, 0xe0(a0)
+	sd a1, 0xe8(a0)
+	sd a1, 0xf0(a0)
+	sd a1, 0xf8(a0)
+	addi a0, a0, 0x100
+	bltu a0, a3, 3b
+	andi a2, a2, 0x7  /* Update count */
+
+4:
+	/* Handle trailing misalignment */
+	beqz a2, 6f
+	add a3, a0, a2
+5:
+	sb a1, 0(a0)
+	addi a0, a0, 1
+	bltu a0, a3, 5b
+6:
+	ret
+END(memset)
+
+#else
+#error RV32 memset unimplemented
+#endif /* CONFIG_64BIT */
+
diff --git a/arch/riscv/lib/uaccess.S b/arch/riscv/lib/uaccess.S
new file mode 100644
index 0000000..4e0ed4a
--- /dev/null
+++ b/arch/riscv/lib/uaccess.S
@@ -0,0 +1,93 @@
+#include <linux/linkage.h>
+
+	.altmacro
+	.macro fixup op reg addr lbl
+	LOCAL _epc
+_epc:
+	\op \reg, \addr
+	.section __ex_table,"a"
+	.balign 8
+	.quad _epc, \lbl
+	.previous
+	.endm
+
+ENTRY(__copy_user)
+	add v1, a1, a2
+	/* Use word-oriented copy only if low-order bits match */
+	andi t0, a0, 0x7
+	andi t1, a1, 0x7
+	bne t0, t1, 2f
+
+	addi t0, a1, 7
+	andi t1, v1, ~0x7
+	andi t0, t0, ~0x7
+	/* v1: terminal address of source region
+	 * t0: lowest doubleword-aligned address in source
+	 * t1: highest doubleword-aligned address in source
+	 */
+	bgeu t0, t1, 2f
+	bltu a1, t0, 3f
+1:
+	fixup ld, t2, (a1), 10f
+	fixup sd, t2, (a0), 10f
+	addi a1, a1, 8
+	addi a0, a0, 8
+	bltu a1, t1, 1b
+2:
+	li v0, 0
+	bltu a1, v1, 4f
+	ret
+3: /* Edge case: unalignment */
+	fixup lbu, t2, (a1), 10f
+	fixup sb, t2, (a0), 10f
+	addi a1, a1, 1
+	addi a0, a0, 1
+	bltu a1, t0, 3b
+	jump 1b
+4: /* Edge case: remainder */
+	fixup lbu, t2, (a1), 10f
+	fixup sb, t2, (a0), 10f
+	addi a1, a1, 1
+	addi a0, a0, 1
+	bltu a1, v1, 4b
+	ret
+ENDPROC(__copy_user)
+
+
+ENTRY(__clear_user)
+	add v1, a0, a1
+	addi t0, a0, 7
+	andi t1, v1, ~0x7
+	andi t0, t0, ~0x7
+	/* v1: terminal address of target region
+	 * t0: lowest doubleword-aligned address in target region
+	 * t1: highest doubleword-aligned address in target region
+	 */
+	bgeu t0, t1, 2f
+	bltu a0, t0, 3f
+1:
+	fixup sd, zero, (a0), 10f
+	addi a0, a0, 8
+	bltu a0, t1, 1b
+2:
+	li v0, 0
+	bltu a0, v1, 4f
+	ret
+3: /* Edge case: unalignment */
+	fixup sb, zero, (a0), 10f
+	addi a0, a0, 1
+	bltu a0, t0, 3b
+	jump 1b
+4: /* Edge case: remainder */
+	fixup sb, zero, (a0), 10f
+	addi a0, a0, 1
+	bltu a0, v1, 4b
+	ret
+ENDPROC(__clear_user)
+
+	.section .fixup,"ax"
+	.balign 4
+10:
+	sub v0, v1, a0
+	ret
+	.previous
diff --git a/arch/riscv/mm/Makefile b/arch/riscv/mm/Makefile
new file mode 100644
index 0000000..36ebe6f
--- /dev/null
+++ b/arch/riscv/mm/Makefile
@@ -0,0 +1 @@
+obj-y := init.o fault.o extable.o ioremap.o
diff --git a/arch/riscv/mm/extable.c b/arch/riscv/mm/extable.c
new file mode 100644
index 0000000..48767f2
--- /dev/null
+++ b/arch/riscv/mm/extable.c
@@ -0,0 +1,14 @@
+#include <linux/module.h>
+#include <linux/uaccess.h>
+
+int fixup_exception(struct pt_regs *regs)
+{
+	const struct exception_table_entry *fixup;
+
+	fixup = search_exception_tables(regs->epc);
+	if (fixup) {
+		regs->epc = fixup->fixup;
+		return 1;
+	}
+	return 0;
+}
diff --git a/arch/riscv/mm/fault.c b/arch/riscv/mm/fault.c
new file mode 100644
index 0000000..37c3216
--- /dev/null
+++ b/arch/riscv/mm/fault.c
@@ -0,0 +1,219 @@
+#include <linux/mm.h>
+#include <linux/kernel.h>
+#include <linux/interrupt.h>
+#include <linux/perf_event.h>
+#include <linux/signal.h>
+
+#include <asm/pgalloc.h>
+#include <asm/ptrace.h>
+#include <asm/uaccess.h>
+
+int show_unhandled_signals = 1;
+
+extern void die(char *, struct pt_regs *, long);
+
+asmlinkage void do_page_fault(struct pt_regs *regs)
+{
+	struct task_struct *tsk;
+	struct vm_area_struct *vma;
+	struct mm_struct *mm;
+	unsigned long addr, epc, cause, fault;
+	unsigned int write, flags;
+	siginfo_t info;
+
+	cause = regs->cause;
+	write = (cause == EXC_STORE_ACCESS);
+	flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE
+		| (write ? FAULT_FLAG_WRITE : 0);
+	epc = regs->epc;
+	addr = (cause == EXC_INST_ACCESS) ? epc : regs->badvaddr;
+
+	info.si_code = SEGV_MAPERR;
+
+	tsk = current;
+	mm = tsk->mm;
+
+	/*
+	 * Fault-in kernel-space virtual memory on-demand.
+	 * The 'reference' page table is init_mm.pgd.
+	 *
+	 * NOTE! We MUST NOT take any locks for this case. We may
+	 * be in an interrupt or a critical region, and should
+	 * only copy the information from the master page table,
+	 * nothing more.
+	 */
+	if (unlikely((addr >= VMALLOC_START) && (addr <= VMALLOC_END)))
+		goto vmalloc_fault;
+
+	 /* Enable interrupts if they were previously enabled in the
+	    parent context */
+	if (likely(regs->status & SR_PEI))
+		local_irq_enable();
+
+	/* Do not take the fault if within an interrupt
+	   or if lacking a user context */
+	if (!mm || in_atomic())
+		goto no_context;
+
+	if (user_mode(regs))
+		flags |= FAULT_FLAG_USER;
+
+retry:
+	down_read(&mm->mmap_sem);
+	vma = find_vma(mm, addr);
+	if (unlikely(!vma))
+		goto bad_area;
+	if (likely(vma->vm_start <= addr))
+		goto good_area;
+	if (unlikely(!(vma->vm_flags & VM_GROWSDOWN)))
+		goto bad_area;
+	if (unlikely(expand_stack(vma, addr)))
+		goto bad_area;
+
+good_area:
+	info.si_code = SEGV_ACCERR;
+
+	if (unlikely(write && (!(vma->vm_flags & VM_WRITE)))) {
+		goto bad_area;
+	}
+	if (unlikely((cause == EXC_INST_ACCESS)
+		&& (!(vma->vm_flags & VM_EXEC)))) {
+		goto bad_area;
+	}
+
+	/*
+	 * If for any reason at all we could not handle the fault,
+	 * make sure we exit gracefully rather than endlessly redo
+	 * the fault.
+	 */
+	fault = handle_mm_fault(mm, vma, addr, flags);
+
+	if ((fault & VM_FAULT_RETRY) && fatal_signal_pending(tsk))
+		return;
+
+
+	perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, regs, addr);
+	if (unlikely(fault & VM_FAULT_ERROR)) {
+		if (fault & VM_FAULT_OOM) {
+			goto out_of_memory;
+		} else if (fault & VM_FAULT_SIGBUS) {
+			goto do_sigbus;
+		}
+		BUG();
+	}
+
+	if (flags & FAULT_FLAG_ALLOW_RETRY) {
+		if (fault & VM_FAULT_MAJOR) {
+			perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1, regs, addr);
+			tsk->maj_flt++;
+		} else {
+			perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MIN, 1, regs, addr);
+			tsk->min_flt++;
+		}
+		if (fault & VM_FAULT_RETRY) {
+			flags &= ~(FAULT_FLAG_ALLOW_RETRY);
+//			flags |= FAULT_FLAG_TRIED;
+
+			/*
+			 * No need to up_read(&mm->mmap_sem) as we would
+			 * have already released it in __lock_page_or_retry
+			 * in mm/filemap.c.
+			 */
+			goto retry;
+		}
+	}
+
+	up_read(&mm->mmap_sem);
+	return;
+
+bad_area:
+	up_read(&mm->mmap_sem);
+	/* User mode accesses cause a SIGSEGV */
+	if (user_mode(regs)) {
+		info.si_signo = SIGSEGV;
+		info.si_errno = 0;
+		/* info.si_code has been set above */
+		info.si_addr = (void __user *)addr;
+		force_sig_info(SIGSEGV, &info, tsk);
+		return;
+	}
+
+no_context:
+	/* Are we prepared to handle this fault as an exception? */
+	if (fixup_exception(regs)) {
+		return;
+	}
+	printk(KERN_ALERT "Unable to handle kernel paging request at "
+		"virtual address 0x%016lx, epc=0x%016lx", addr, epc);
+	die("Oops", regs, 0);
+
+out_of_memory:
+	up_read(&mm->mmap_sem);
+	if (!user_mode(regs))
+		goto no_context;
+	pagefault_out_of_memory();
+	return;
+
+do_sigbus:
+	up_read(&mm->mmap_sem);
+	/* Send a SIGBUS regardless of kernel or user mode */
+	info.si_signo = SIGBUS;
+	info.si_errno = 0;
+	info.si_code = BUS_ADRERR;
+	info.si_addr = (void __user *)addr;
+	force_sig_info(SIGBUS, &info, current);
+	if (!user_mode(regs))
+		goto no_context;
+	return;
+
+vmalloc_fault:
+	{
+		pgd_t *pgd, *pgd_k;
+		pud_t *pud, *pud_k;
+		pmd_t *pmd, *pmd_k;
+		pte_t *pte_k;
+		int index;
+
+	        if (user_mode(regs))
+			goto bad_area;
+
+		/*
+		 * Synchronize this task's top level page-table
+		 * with the 'reference' page table.
+		 *
+		 * Do _not_ use "tsk->active_mm->pgd" here.
+		 * We might be inside an interrupt in the middle
+		 * of a task switch.
+		 */
+		index = pgd_index(addr);
+		pgd = (pgd_t *)__va(csr_read(ptbr)) + index;
+		pgd_k = init_mm.pgd + index;
+
+		if (!pgd_present(*pgd_k))
+			goto no_context;
+		set_pgd(pgd, *pgd_k);
+
+		pud = pud_offset(pgd, addr);
+		pud_k = pud_offset(pgd_k, addr);
+		if (!pud_present(*pud_k))
+			goto no_context;
+
+		/* Since the vmalloc area is global, it is unnecessary
+		   to copy individual PTEs */
+		pmd = pmd_offset(pud, addr);
+		pmd_k = pmd_offset(pud_k, addr);
+		if (!pmd_present(*pmd_k))
+			goto no_context;
+		set_pmd(pmd, *pmd_k);
+
+		/* Make sure the actual PTE exists as well to
+		 * catch kernel vmalloc-area accesses to non-mapped
+		 * addresses. If we don't do this, this will just
+		 * silently loop forever.
+		 */
+		pte_k = pte_offset_kernel(pmd_k, addr);
+		if (!pte_present(*pte_k))
+			goto no_context;
+		return;
+	}
+}
diff --git a/arch/riscv/mm/init.c b/arch/riscv/mm/init.c
new file mode 100644
index 0000000..48f21d0
--- /dev/null
+++ b/arch/riscv/mm/init.c
@@ -0,0 +1,96 @@
+#include <linux/init.h>
+#include <linux/mm.h>
+#include <linux/bootmem.h>
+#include <linux/initrd.h>
+#include <linux/memblock.h>
+#include <linux/swap.h>
+
+#include <asm/tlbflush.h>
+#include <asm/sections.h>
+#include <asm/pgtable.h>
+#include <asm/io.h>
+
+#ifdef CONFIG_64BIT
+static void __init pagetable_init(void)
+{
+	/* Remove identity mapping to catch NULL pointer dereferences */
+	swapper_pg_dir[0] = __pgd(0);
+}
+#else
+static void __init pagetable_init(void)
+{
+}
+#endif /* CONFIG_64BIT */
+
+#ifdef CONFIG_NUMA
+static void __init zone_sizes_init(void)
+{
+	unsigned long zones_size[MAX_NR_ZONES];
+	int nid;
+
+	memset(zones_size, 0, sizeof(zones_size));
+
+	for_each_online_node(nid) {
+		pg_data_t *pgdat;
+		unsigned long start_pfn, end_pfn;
+
+		pgdat = NODE_DATA(nid);
+		start_pfn = pgdat->bdata->node_min_pfn;
+		end_pfn = pgdat->bdata->node_low_pfn;
+		memblock_add_node(start_pfn,
+			PFN_PHYS(end_pfn - start_pfn), nid);
+	}
+
+	zones_size[ZONE_NORMAL] = max_low_pfn;
+	free_area_init_nodes(zones_size);
+}
+#else
+static void __init zone_sizes_init(void)
+{
+	unsigned long zones_size[MAX_NR_ZONES];
+
+	memset(zones_size, 0, sizeof(zones_size));
+	memblock_add_node(0, PFN_PHYS(max_low_pfn), 0);
+	zones_size[ZONE_NORMAL] = max_low_pfn;
+	free_area_init_nodes(zones_size);
+}
+#endif /* CONFIG_NUMA */
+
+void setup_zero_page(void)
+{
+	memset((void *)empty_zero_page, 0, PAGE_SIZE);
+}
+
+void __init paging_init(void)
+{
+	setup_zero_page();
+	pagetable_init();
+	flush_tlb_all();
+	zone_sizes_init();
+}
+
+void __init mem_init(void)
+{
+#ifdef CONFIG_FLATMEM
+	BUG_ON(!mem_map);
+#endif /* CONFIG_FLATMEM */
+
+	set_max_mapnr(max_low_pfn);
+	high_memory = (void *)(__va(PFN_PHYS(max_low_pfn)));
+	free_all_bootmem();
+
+	mem_init_print_info(NULL);
+}
+
+void free_initmem(void)
+{
+	free_initmem_default(0);
+}
+
+#ifdef CONFIG_BLK_DEV_INITRD
+void free_initrd_mem(unsigned long start, unsigned long end)
+{
+//	free_reserved_area(start, end, 0, "initrd");
+}
+#endif /* CONFIG_BLK_DEV_INITRD */
+
diff --git a/arch/riscv/mm/ioremap.c b/arch/riscv/mm/ioremap.c
new file mode 100644
index 0000000..362da4b
--- /dev/null
+++ b/arch/riscv/mm/ioremap.c
@@ -0,0 +1,81 @@
+#include <linux/export.h>
+#include <linux/mm.h>
+#include <linux/vmalloc.h>
+#include <linux/io.h>
+
+#include <asm/pgtable.h>
+
+/*
+ * Remap an arbitrary physical address space into the kernel virtual
+ * address space. Needed when the kernel wants to access high addresses
+ * directly.
+ *
+ * NOTE! We need to allow non-page-aligned mappings too: we will obviously
+ * have to convert them into an offset in a page-aligned mapping, but the
+ * caller shouldn't need to know that small detail.
+ */
+static void __iomem *__ioremap_caller(phys_addr_t addr, size_t size,
+	pgprot_t prot, void *caller)
+{
+	phys_addr_t last_addr;
+	unsigned long offset, vaddr;
+	struct vm_struct *area;
+
+	/* Disallow wrap-around or zero size */
+	last_addr = addr + size - 1;
+	if (!size || last_addr < addr) {
+		return NULL;
+	}
+
+	/* Page-align mappings */
+	offset = addr & (~PAGE_MASK);
+	addr &= PAGE_MASK;
+	size = PAGE_ALIGN(size + offset);
+
+	area = get_vm_area_caller(size, VM_IOREMAP, caller);
+	if (!area) {
+		return NULL;
+	}
+	vaddr = (unsigned long)area->addr;
+
+	if (ioremap_page_range(vaddr, vaddr + size, addr, prot)) {
+		free_vm_area(area);
+		return NULL;
+	}
+
+	return (void __iomem *)(vaddr + offset);
+}
+
+/*
+ * ioremap     -   map bus memory into CPU space
+ * @offset:    bus address of the memory
+ * @size:      size of the resource to map
+ *
+ * ioremap performs a platform specific sequence of operations to
+ * make bus memory CPU accessible via the readb/readw/readl/writeb/
+ * writew/writel functions and the other mmio helpers. The returned
+ * address is not guaranteed to be usable directly as a virtual
+ * address.
+ *
+ * Must be freed with iounmap.
+ */
+void __iomem *ioremap(phys_addr_t offset, unsigned long size)
+{
+	return __ioremap_caller(offset, size, PAGE_KERNEL,
+		__builtin_return_address(0));
+}
+EXPORT_SYMBOL(ioremap);
+
+
+/**
+ * iounmap - Free a IO remapping
+ * @addr: virtual address from ioremap_*
+ *
+ * Caller must ensure there is only one unmapping for the same pointer.
+ */
+void iounmap(void __iomem *addr)
+{
+	vunmap((void *)((unsigned long)addr & PAGE_MASK));
+}
+EXPORT_SYMBOL(iounmap);
+
